{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828e8adc02ee8908",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "# Homework Prompt Design\n",
    "\n",
    "In the last lab we saw that there are different ways to get to the goal of the homework is to apply DoE to guage the effectiveness of different approaches. I.e.,  evaluate different algorithms/approaches that perform classification, and leveraging. **Design of Experiments**. \n",
    "\n",
    "\n",
    "This homework consists the following 4 main parts, 1 facultative exercise to get to know a useful templating language, and 1 bonus exercise. Note the course staff reserves the right to provide corrections to this notebook and/or corresponding code.\n",
    "\n",
    "**N.B.**, this homework is both about using different techniques, and applying DoE. Its purpose is *not* to obtain a State-of-the-Art result, but rather to get to know different methods, understand their respective merrits, and applying them properly.\n",
    "\n",
    "## Submitting the Homework to Ilias\n",
    "**N.B.** To submit this homework, you must render this notebook as a PDF, run the following command in the commandline. Make sure to test this command;\n",
    "\n",
    "```bash\n",
    "jupyter-nbconvert --to pdfviahtml  homework-reference.ipynb --TagRemovePreprocessor.remove_input_tags='{\"hide-cell\",\"hide-student-submission\"}'  --TagRemovePreprocessor.remove_all_outputs_tags='{\"remove-output\"}'         \n",
    "```\n",
    "\n",
    "Before submitting make sure your notebook adheres to the following:\n",
    "\n",
    "1. None of the cells that are tagged as `keep-output` or `hide-cell` are deleted, these are key for the review of your code.\n",
    "2. You have verified that your submission PDF contains all your complete answers, note that;\n",
    "   * cells annotated with `hide-cell` will have their input removed,\n",
    "   * cells annotated with `remove-output` will have their output removed,\n",
    "   * cells annotated with `hide-student-submission` will have their input removed, e.g., this cell\n",
    "   \n",
    "3. Any cells you have added are either: properly annotated with `keep-output` or `hide-cell`, or are manually cleaned.\n",
    "\n",
    "> ⚠️ The course staff reserves the right to withold awarding (partial) points to any of the (sub)exercises if your submitted PDF and notebook do not adhere to these requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a4b24275176c83",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e028ac06b9be99",
   "metadata": {
    "tags": [
     "keep-output"
    ]
   },
   "source": [
    "# Homework 2 Submission\n",
    "\n",
    "| **Detail**      | **Description**  |\n",
    "|-----------------|------------------|\n",
    "| **Name**        | Chenrui Fan      |\n",
    "| **Student No.** | 23-125-818       |\n",
    "| **Year**        | 2024             |\n",
    "| **Course**      | MSGAI            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30aa0f715bb80f2",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "# Before we get started\n",
    "\n",
    "This notebook seems long, but *most of the code* provides a starting point for the objective of this homework; *basic prompt-design and DoE*.\n",
    "Read each exercise carefully, you might find some hints here and there in the provided code!\n",
    "\n",
    "## Homework Overview\n",
    "\n",
    "This homework consists of the following three parts, each consisting of some implementation, and design of experiment. We provide skeleton code to perform the experiments, but you may wish to deviate from it. We recommend doing the exercises in the provided order.\n",
    "\n",
    "1. Zero-shot / Instruction based prediction.\n",
    "2. Few-shot / Example based prediction.\n",
    "3. Fine-Tuning / Learning based prediction.\n",
    "\n",
    "Each exercise consists of;\n",
    "1. A minor implementation of the main concept (see above, except for the `Fine-Tuning / Learning exercise`).\n",
    "2. Design-of-Experiments. We provide a (mostly filled out) example in Exercise 3 that you may wish to use in Exercises 1 and 2.\n",
    "3. Analysis of the DoE results, using ANOVA analysis, herein you need to check the model assumptions.\n",
    "\n",
    "Additionally, there is ONE bonus exercise (2.1.3), worth a maximum of $10$ points, which we recommend tackling last.\n",
    "3. (Bonus) Classification based prediction / Anything you want. Note, contact the TA before starting this BONUS. This BONUS will be of max. 10 points instead of the Semantic Few-Shot Prompting bonus in exercise 2. You can use the results / insights from this also in your project work.\n",
    "\n",
    "**N.B.** You can get a maximum of $60$ points in total, **with an additional maximum of $10$ bonus points**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2112c6c3dc4ff10",
   "metadata": {
    "tags": [
     "remove-output",
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: 4.0.0: No such file or directory\n",
      "Collecting nbconvert==6.5.4\n",
      "  Using cached nbconvert-6.5.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: lxml in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert==6.5.4) (4.12.3)\n",
      "Requirement already satisfied: bleach in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert==6.5.4) (0.4)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (0.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (2.1.5)\n",
      "Collecting mistune<2,>=0.8.1 (from nbconvert==6.5.4)\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (5.10.3)\n",
      "Requirement already satisfied: packaging in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (24.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (2.17.2)\n",
      "Requirement already satisfied: tinycss2 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert==6.5.4) (5.14.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert==6.5.4) (4.2.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/fcr/.local/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert==6.5.4) (8.6.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/fcr/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert==6.5.4) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/fcr/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert==6.5.4) (4.21.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/fcr/.local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert==6.5.4) (2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from bleach->nbconvert==6.5.4) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/fcr/.local/lib/python3.10/site-packages (from bleach->nbconvert==6.5.4) (0.5.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert==6.5.4) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert==6.5.4) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert==6.5.4) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert==6.5.4) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert==6.5.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert==6.5.4) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert==6.5.4) (6.4)\n",
      "Using cached nbconvert-6.5.4-py3-none-any.whl (563 kB)\n",
      "Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mistune, nbconvert\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 3.0.2\n",
      "    Uninstalling mistune-3.0.2:\n",
      "      Successfully uninstalled mistune-3.0.2\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 7.16.3\n",
      "    Uninstalling nbconvert-7.16.3:\n",
      "      Successfully uninstalled nbconvert-7.16.3\n",
      "Successfully installed mistune-0.8.4 nbconvert-6.5.4\n",
      "Collecting lxml_html_clean==0.3.1\n",
      "  Downloading lxml_html_clean-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: lxml in /home/fcr/.local/lib/python3.10/site-packages (from lxml_html_clean==0.3.1) (5.2.1)\n",
      "Downloading lxml_html_clean-0.3.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.3.1\n",
      "Collecting notebook-as-pdf==0.5.0\n",
      "  Downloading notebook_as_pdf-0.5.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nbconvert in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from notebook-as-pdf==0.5.0) (6.5.4)\n",
      "Collecting pyppeteer (from notebook-as-pdf==0.5.0)\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting PyPDF2 (from notebook-as-pdf==0.5.0)\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: lxml in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (4.12.3)\n",
      "Requirement already satisfied: bleach in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (0.4)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (0.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (2.1.5)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (5.10.3)\n",
      "Requirement already satisfied: packaging in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (24.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (2.17.2)\n",
      "Requirement already satisfied: tinycss2 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert->notebook-as-pdf==0.5.0) (5.14.2)\n",
      "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer->notebook-as-pdf==0.5.0)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: certifi>=2023 in /home/fcr/.local/lib/python3.10/site-packages (from pyppeteer->notebook-as-pdf==0.5.0) (2024.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from pyppeteer->notebook-as-pdf==0.5.0) (7.0.1)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer->notebook-as-pdf==0.5.0)\n",
      "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /home/fcr/.local/lib/python3.10/site-packages (from pyppeteer->notebook-as-pdf==0.5.0) (4.66.5)\n",
      "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer->notebook-as-pdf==0.5.0)\n",
      "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer->notebook-as-pdf==0.5.0)\n",
      "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from importlib-metadata>=1.4->pyppeteer->notebook-as-pdf==0.5.0) (3.17.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert->notebook-as-pdf==0.5.0) (4.2.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/fcr/.local/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert->notebook-as-pdf==0.5.0) (8.6.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/fcr/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->notebook-as-pdf==0.5.0) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/fcr/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->notebook-as-pdf==0.5.0) (4.21.1)\n",
      "Requirement already satisfied: typing-extensions in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer->notebook-as-pdf==0.5.0) (4.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/fcr/.local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->notebook-as-pdf==0.5.0) (2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from bleach->nbconvert->notebook-as-pdf==0.5.0) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/fcr/.local/lib/python3.10/site-packages (from bleach->nbconvert->notebook-as-pdf==0.5.0) (0.5.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->notebook-as-pdf==0.5.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->notebook-as-pdf==0.5.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->notebook-as-pdf==0.5.0) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->notebook-as-pdf==0.5.0) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->notebook-as-pdf==0.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->notebook-as-pdf==0.5.0) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->notebook-as-pdf==0.5.0) (6.4)\n",
      "Downloading notebook_as_pdf-0.5.0-py3-none-any.whl (6.5 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
      "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "Installing collected packages: appdirs, websockets, urllib3, PyPDF2, pyee, pyppeteer, notebook-as-pdf\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 11.0.3\n",
      "    Uninstalling websockets-11.0.3:\n",
      "      Successfully uninstalled websockets-11.0.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightning-cloud 0.5.70 requires protobuf, which is not installed.\n",
      "lightning-cloud 0.5.70 requires pyjwt, which is not installed.\n",
      "wandb 0.18.3 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyPDF2-3.0.1 appdirs-1.4.4 notebook-as-pdf-0.5.0 pyee-11.1.1 pyppeteer-2.0.0 urllib3-1.26.20 websockets-10.4\n",
      "Collecting bitsandbytes~=0.42.0\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: scipy in /home/fcr/.local/lib/python3.10/site-packages (from bitsandbytes~=0.42.0) (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /home/fcr/.local/lib/python3.10/site-packages (from scipy->bitsandbytes~=0.42.0) (1.24.4)\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0\n",
      "Collecting configparser~=7.1.0\n",
      "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: configparser\n",
      "Successfully installed configparser-7.1.0\n",
      "/bin/bash: line 1: 4.0.0: No such file or directory\n",
      "Collecting flake8-import-order~=0.18.2\n",
      "  Downloading flake8_import_order-0.18.2-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pycodestyle (from flake8-import-order~=0.18.2)\n",
      "  Downloading pycodestyle-2.12.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: setuptools in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from flake8-import-order~=0.18.2) (75.1.0)\n",
      "Downloading flake8_import_order-0.18.2-py2.py3-none-any.whl (15 kB)\n",
      "Downloading pycodestyle-2.12.1-py2.py3-none-any.whl (31 kB)\n",
      "Installing collected packages: pycodestyle, flake8-import-order\n",
      "Successfully installed flake8-import-order-0.18.2 pycodestyle-2.12.1\n",
      "Requirement already satisfied: fqdn~=1.5.1 in /home/fcr/.local/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: isoduration~=20.11.0 in /home/fcr/.local/lib/python3.10/site-packages (20.11.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/fcr/.local/lib/python3.10/site-packages (from isoduration~=20.11.0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /home/fcr/.local/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration~=20.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/fcr/.local/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration~=20.11.0) (2.9.0.20240316)\n",
      "Requirement already satisfied: six>=1.5 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from python-dateutil>=2.7.0->arrow>=0.15.0->isoduration~=20.11.0) (1.16.0)\n",
      "Collecting jinja2schema~=0.1.4\n",
      "  Downloading jinja2schema-0.1.4.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.2 in /home/fcr/.local/lib/python3.10/site-packages (from jinja2schema~=0.1.4) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fcr/.local/lib/python3.10/site-packages (from Jinja2>=2.2->jinja2schema~=0.1.4) (2.1.5)\n",
      "Building wheels for collected packages: jinja2schema\n",
      "  Building wheel for jinja2schema (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jinja2schema: filename=jinja2schema-0.1.4-py3-none-any.whl size=23674 sha256=e3bb319f6caa639ab417f4afc1e0784d18927c59d435ec417a9d4804a39f8b4a\n",
      "  Stored in directory: /home/fcr/.cache/pip/wheels/fe/0d/f5/5823bf49b00174613295ff2511f42cd728ac9cbe1f8ae7d750\n",
      "Successfully built jinja2schema\n",
      "Installing collected packages: jinja2schema\n",
      "Successfully installed jinja2schema-0.1.4\n",
      "Collecting jsonpointer~=3.0.0\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: jsonpointer\n",
      "  Attempting uninstall: jsonpointer\n",
      "    Found existing installation: jsonpointer 2.4\n",
      "    Uninstalling jsonpointer-2.4:\n",
      "      Successfully uninstalled jsonpointer-2.4\n",
      "Successfully installed jsonpointer-3.0.0\n",
      "/bin/bash: line 1: 2.0.0: No such file or directory\n",
      "/bin/bash: line 1: 1.0.0: No such file or directory\n",
      "Collecting pretty-jupyter==2.0.7\n",
      "  Using cached pretty_jupyter-2.0.7-py3-none-any.whl.metadata (45 kB)\n",
      "Requirement already satisfied: click in /home/fcr/.local/lib/python3.10/site-packages (from pretty-jupyter==2.0.7) (8.1.7)\n",
      "Requirement already satisfied: ipython>=7.1 in /home/fcr/.local/lib/python3.10/site-packages (from pretty-jupyter==2.0.7) (8.22.2)\n",
      "Requirement already satisfied: nbconvert<7.0,>=6.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from pretty-jupyter==2.0.7) (6.5.4)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/fcr/.local/lib/python3.10/site-packages (from pretty-jupyter==2.0.7) (3.1.3)\n",
      "Collecting ipython-genutils>=0.1 (from pretty-jupyter==2.0.7)\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
      "Requirement already satisfied: pyyaml>=5 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from pretty-jupyter==2.0.7) (6.0.1)\n",
      "Collecting cerberus>=1.1 (from pretty-jupyter==2.0.7)\n",
      "  Using cached Cerberus-1.3.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: decorator in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (5.14.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/fcr/.local/lib/python3.10/site-packages (from ipython>=7.1->pretty-jupyter==2.0.7) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fcr/.local/lib/python3.10/site-packages (from jinja2>=3.0->pretty-jupyter==2.0.7) (2.1.5)\n",
      "Requirement already satisfied: lxml in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (4.12.3)\n",
      "Requirement already satisfied: bleach in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.3.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (5.10.3)\n",
      "Requirement already satisfied: packaging in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (24.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /home/fcr/.local/lib/python3.10/site-packages (from nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (1.2.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/fcr/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.1->pretty-jupyter==2.0.7) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (4.2.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/fcr/.local/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (8.6.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/fcr/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/fcr/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (4.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/fcr/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.1->pretty-jupyter==2.0.7) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/fcr/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.1->pretty-jupyter==2.0.7) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/fcr/.local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from bleach->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/fcr/.local/lib/python3.10/site-packages (from bleach->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.5.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/fcr/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.1->pretty-jupyter==2.0.7) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/fcr/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.1->pretty-jupyter==2.0.7) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/fcr/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.1->pretty-jupyter==2.0.7) (0.2.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/fcr/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/fcr/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<7.0,>=6.0->pretty-jupyter==2.0.7) (6.4)\n",
      "Using cached pretty_jupyter-2.0.7-py3-none-any.whl (3.2 MB)\n",
      "Using cached Cerberus-1.3.5-py3-none-any.whl (30 kB)\n",
      "Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ipython-genutils, cerberus, pretty-jupyter\n",
      "Successfully installed cerberus-1.3.5 ipython-genutils-0.2.0 pretty-jupyter-2.0.7\n",
      "/bin/bash: line 1: 6.0.0: No such file or directory\n",
      "Collecting pyDOE3~=1.0.4\n",
      "  Downloading pydoe3-1.0.4-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy in /home/fcr/.local/lib/python3.10/site-packages (from pyDOE3~=1.0.4) (1.24.4)\n",
      "Requirement already satisfied: scipy in /home/fcr/.local/lib/python3.10/site-packages (from pyDOE3~=1.0.4) (1.14.1)\n",
      "Downloading pydoe3-1.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pyDOE3\n",
      "Successfully installed pyDOE3-1.0.4\n",
      "Collecting researchpy~=0.3.6\n",
      "  Downloading researchpy-0.3.6-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: scipy in /home/fcr/.local/lib/python3.10/site-packages (from researchpy~=0.3.6) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/fcr/.local/lib/python3.10/site-packages (from researchpy~=0.3.6) (1.24.4)\n",
      "Requirement already satisfied: pandas in /home/fcr/.local/lib/python3.10/site-packages (from researchpy~=0.3.6) (2.2.3)\n",
      "Collecting statsmodels (from researchpy~=0.3.6)\n",
      "  Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting patsy (from researchpy~=0.3.6)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/fcr/.local/lib/python3.10/site-packages (from pandas->researchpy~=0.3.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/fcr/.local/lib/python3.10/site-packages (from pandas->researchpy~=0.3.6) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/fcr/.local/lib/python3.10/site-packages (from pandas->researchpy~=0.3.6) (2024.1)\n",
      "Requirement already satisfied: six in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from patsy->researchpy~=0.3.6) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/fcr/.local/lib/python3.10/site-packages (from statsmodels->researchpy~=0.3.6) (24.0)\n",
      "Downloading researchpy-0.3.6-py3-none-any.whl (34 kB)\n",
      "Using cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: patsy, statsmodels, researchpy\n",
      "Successfully installed patsy-0.5.6 researchpy-0.3.6 statsmodels-0.14.4\n",
      "Collecting seaborn~=0.13.2\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/fcr/.local/lib/python3.10/site-packages (from seaborn~=0.13.2) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/fcr/.local/lib/python3.10/site-packages (from seaborn~=0.13.2) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/fcr/.local/lib/python3.10/site-packages (from seaborn~=0.13.2) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fcr/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/fcr/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn~=0.13.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/fcr/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn~=0.13.2) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn~=0.13.2) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Collecting sentence-transformers~=3.2.0\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /home/fcr/.local/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/fcr/.local/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (0.24.6)\n",
      "Requirement already satisfied: Pillow in /home/fcr/.local/lib/python3.10/site-packages (from sentence-transformers~=3.2.0) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/fcr/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/fcr/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/fcr/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/fcr/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers~=3.2.0) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/fcr/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers~=3.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/fcr/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers~=3.2.0) (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/fcr/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers~=3.2.0) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/fcr/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers~=3.2.0) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/fcr/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers~=3.2.0) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers~=3.2.0) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from scikit-learn->sentence-transformers~=3.2.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/fcr/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers~=3.2.0) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fcr/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers~=3.2.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/fcr/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fcr/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fcr/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers~=3.2.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/fcr/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers~=3.2.0) (1.3.0)\n",
      "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.2.1\n",
      "/bin/bash: line 1: 1.0.0: No such file or directory\n",
      "Collecting tabulate~=0.9.0\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Requirement already satisfied: uri-template==1.3.0 in /home/fcr/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Collecting webcolors==24.8.0\n",
      "  Using cached webcolors-24.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached webcolors-24.8.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: webcolors\n",
      "  Attempting uninstall: webcolors\n",
      "    Found existing installation: webcolors 1.13\n",
      "    Uninstalling webcolors-1.13:\n",
      "      Successfully uninstalled webcolors-1.13\n",
      "Successfully installed webcolors-24.8.0\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (same as the env file, so you may wish to skip this if running locally / with persistent conda environment)\n",
    "!pip install python>=3.10,<4.0.0\n",
    "!pip install nbconvert==6.5.4        \n",
    "!pip install lxml_html_clean==0.3.1  \n",
    "!pip install notebook-as-pdf==0.5.0  \n",
    "!pip install bitsandbytes~=0.42.0\n",
    "!pip install configparser~=7.1.0\n",
    "!pip install datasets>=3.0.1,<4.0.0\n",
    "!pip install flake8-import-order~=0.18.2\n",
    "!pip install fqdn~=1.5.1\n",
    "!pip install isoduration~=20.11.0\n",
    "!pip install jinja2schema~=0.1.4\n",
    "!pip install jsonpointer~=3.0.0\n",
    "!pip install jupyter~=1.1.1,<2.0.0\n",
    "!pip install peft>=0.13.2,<1.0.0\n",
    "!pip install pretty-jupyter==2.0.7\n",
    "!pip install protobuf~=5.28.2,<6.0.0\n",
    "!pip install pyDOE3~=1.0.4\n",
    "!pip install researchpy~=0.3.6\n",
    "!pip install seaborn~=0.13.2\n",
    "!pip install sentence-transformers~=3.2.0\n",
    "!pip install sentencepiece~=0.2.0,<1.0.0\n",
    "!pip install tabulate~=0.9.0\n",
    "!pip install uri-template==1.3.0\n",
    "!pip install webcolors==24.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6016d948465358a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:39.991412Z",
     "start_time": "2024-10-17T18:57:38.272656Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Imports used in most of the exercises\n",
    "import contextlib\n",
    "import io\n",
    "import json\n",
    "\n",
    "import textwrap\n",
    "import time\n",
    "import unittest\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from importlib import metadata\n",
    "from itertools import chain\n",
    "from os import PathLike\n",
    "from functools import partial\n",
    "from typing import Dict, List, Tuple, Union, Dict, Any\n",
    "from typing import Optional, Type\n",
    "from unittest import TextTestRunner, defaultTestLoader\n",
    "\n",
    "import datasets\n",
    "import jinja2\n",
    "import jinja2schema\n",
    "import peft\n",
    "import torch\n",
    "import transformers\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4c0909905289ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:40.029695Z",
     "start_time": "2024-10-17T18:57:39.996363Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2>System Configuration</h2>\n",
       "    <table>\n",
       "        <tr><td><strong>PyTorch version:</strong></td><td>2.4.1</td></tr>\n",
       "        <tr><td><strong>Device:</strong></td><td>cuda (Backend: cuda)</td></tr>\n",
       "        <tr><td><strong>CUDA/ROCm version:</strong></td><td>12.1</td></tr>\n",
       "        <tr><td><strong>GPU count:</strong></td><td>1</td></tr>\n",
       "        <tr><td><strong>GPU name:</strong></td><td>NVIDIA GeForce RTX 4090</td></tr>\n",
       "        <tr><td><strong>Hugging Face Transformers version:</strong></td><td>4.45.2</td></tr>\n",
       "        <tr><td><strong>BitsAndBytes version:</strong></td><td>0.42.0</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_available_device() -> Tuple[torch.device, str]:\n",
    "    \"\"\"Helper method to find best possible hardware to run\n",
    "    Returns:\n",
    "        torch.device used to run experiments.\n",
    "        str representation of backend.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\"), \"cuda\"\n",
    "\n",
    "    # Check if ROCm is available\n",
    "    if torch.version.hip is not None and torch.backends.mps.is_available():\n",
    "        return torch.device(\"rocm\"), \"rocm\"\n",
    "\n",
    "    # Check if MPS (Apple Silicon) is available\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('cpu'), \"mps\"\n",
    "\n",
    "    # Fall back to CPU\n",
    "    return torch.device(\"cpu\"), \"cpu\"\n",
    "\n",
    "\n",
    "def display_dataset_description(name: str, dataset: datasets.DatasetDict) -> None:\n",
    "    \"\"\"Helper method to display information about splits in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        name (str): Dataset name that was loaded. \n",
    "        dataset (datasets.DatasetDict): Dataset dict with different splits that were loaded \n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    split_info = []\n",
    "    for k, ds in dataset.items():\n",
    "        split_info.append(f\"<tr><td><strong>{k.capitalize()} Samples:</strong></td><td>{len(ds)}</td></tr>\")\n",
    "    html_content = f\"\"\"\n",
    "    <h2>Dataset info</h2>\n",
    "    <table>\n",
    "        <tr><td><strong>Dataset Name:</strong></td><td>{name}</td></tr>\n",
    "        {\"<br>\".join(split_info)}\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the output in the notebook\n",
    "    display(HTML(html_content))\n",
    "\n",
    "def get_installed_version(package_name) -> str:\n",
    "    with warnings.catch_warnings():\n",
    "        # Supress warnings from packages that have missing attributes that metadata will complain about.\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        distribution = metadata.Distribution()\n",
    "        try:\n",
    "            return distribution.from_name(package_name).version\n",
    "        except metadata.PackageNotFoundError:\n",
    "            return \"Not installed\"\n",
    "\n",
    "\n",
    "def display_configuration() -> None:\n",
    "    # Check device info\n",
    "    device, backend = get_available_device()\n",
    "\n",
    "    # Torch version\n",
    "    torch_version = torch.__version__\n",
    "\n",
    "    # HuggingFace Transformers version\n",
    "    transformers_ver = transformers.__version__\n",
    "\n",
    "    # BitsAndBytes version (if available)\n",
    "    bitsandbytes_version = get_installed_version(\"bitsandbytes\")\n",
    "\n",
    "    # Check for GPU-specific details if CUDA or ROCm is available\n",
    "    if device.type == \"cuda\":\n",
    "        cuda_device_count = torch.cuda.device_count()\n",
    "        cuda_device_name = torch.cuda.get_device_name(0)\n",
    "        cuda_version = torch.version.cuda\n",
    "    elif device.type == \"rocm\":\n",
    "        cuda_device_count = torch.cuda.device_count()\n",
    "        cuda_device_name = torch.cuda.get_device_name(0)\n",
    "        cuda_version = torch.version.hip\n",
    "    else:\n",
    "        cuda_device_count = 0\n",
    "        cuda_device_name = \"N/A\"\n",
    "        cuda_version = \"N/A\"\n",
    "\n",
    "    # Prepare HTML formatted output for better display in a notebook\n",
    "    html_content = f\"\"\"\n",
    "    <h2>System Configuration</h2>\n",
    "    <table>\n",
    "        <tr><td><strong>PyTorch version:</strong></td><td>{torch_version}</td></tr>\n",
    "        <tr><td><strong>Device:</strong></td><td>{device} (Backend: {backend})</td></tr>\n",
    "        <tr><td><strong>CUDA/ROCm version:</strong></td><td>{cuda_version}</td></tr>\n",
    "        <tr><td><strong>GPU count:</strong></td><td>{cuda_device_count}</td></tr>\n",
    "        <tr><td><strong>GPU name:</strong></td><td>{cuda_device_name}</td></tr>\n",
    "        <tr><td><strong>Hugging Face Transformers version:</strong></td><td>{transformers_ver}</td></tr>\n",
    "        <tr><td><strong>BitsAndBytes version:</strong></td><td>{bitsandbytes_version}</td></tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the output in the notebook\n",
    "    display(HTML(html_content))\n",
    "\n",
    "\n",
    "# Call the display_configuration() function in your Jupyter notebook to show the configuration\n",
    "display_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87474e446657d1",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "## 0. Preparation\n",
    "\n",
    "In order to prepare, we will load the model and dataset that we will be using, namely the `standfordnlp/imbd` sentiment dataset, and the `google/flan-T5-small` model.\n",
    "\n",
    "You likely only need to run these setup cells once before running your code, but you might want to use the functions we provide here for certain DoE variables concerning:\n",
    "\n",
    "* Precision (`torch.float16`, `torch.float32`, `torch.bfloat16`)\n",
    "* Quantization (E.g., `bits_and_bytes_config != None`)\n",
    "* Device (E.g., `cpu` and `cuda`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc2af99aeff350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:59:00.911995Z",
     "start_time": "2024-10-17T18:59:00.903703Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def get_model(\n",
    "        model_name: Union[str, PathLike],\n",
    "        model_type: Type[transformers.GenerationMixin] = T5ForConditionalGeneration,\n",
    "        torch_dtype: torch.dtype = torch.float16,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        bits_and_bytes_config: Optional[transformers.BitsAndBytesConfig] = None\n",
    ") -> Tuple[transformers.PreTrainedModel, transformers.PreTrainedTokenizer, Union[transformers.PreTrainedTokenizerFast, transformers.PreTrainedTokenizer]]:\n",
    "    \"\"\"Example method to instantiate a model and get a model with optional quantization (using bitsandbytes).\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Model name (huggingface name), or relative/absolute path to a pretrained model.\n",
    "        model_type (Type[transformers.PreTrainedModel]): Type of pretrained model, used to instantiate the model you wan to load.\n",
    "        torch_dtype (torch.dtype, torch.float16): Precision to load the model with. See also the BitsAndBytes documentation.\n",
    "        device (torch.device, 'cpu'): Device to run the model on.\n",
    "        bits_and_bytes_config (BitsAndBytesConfig, optional): Configuration for bitsandbytes model quantization / mixed-precisions (consider this one of your factors)\n",
    "            N.B. for fine-tuning, make sure the optimizer you want to use is available for the defined precision.\n",
    "        \n",
    "    Returns:\n",
    "        transformers.PreTrainedModel: Model instance with provided configuraiton.\n",
    "        transformers.PreTrainedTokenizer: Tokenizer instance with provided configuration.\n",
    "        transformers.PreTrainedTokenizerFast: Fast tokenizer if avilable, othersiwe a normal python based optimizer\n",
    "    \n",
    "    Notes:\n",
    "        For using the BitsAndBytes quantization configuration, an Nvidia GPU is required. For this you might want to make \n",
    "        use of the Google Collab L4 / K40 GPUs (free-tier).    \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    model: transformers.PreTrainedModel = model_type.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        quantization_config=bits_and_bytes_config,\n",
    "        device_map=device,\n",
    "        torch_dtype=torch_dtype,\n",
    "    )\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "    )\n",
    "    fast_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        use_fast=True\n",
    "    )\n",
    "     \n",
    "    return model, tokenizer, fast_tokenizer\n",
    "\n",
    "def get_dataset(\n",
    "        data_name: str,\n",
    "        splits: List[str]\n",
    ") -> Tuple[datasets.Dataset, ...]:\n",
    "    \"\"\"Helper method to load huggingface dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_name (str): Dataset name to load from huggingface. \n",
    "        splits (List[str]): List of splits to load and return. \n",
    "\n",
    "    Returns:\n",
    "        Tuple containing the dataset splits.\n",
    "    \"\"\"\n",
    "    # Load dataset, and assign splits to variables\n",
    "    dataset: datasets.DatasetDict = datasets.load_dataset(data_name)\n",
    "    return tuple(dataset[split] for split in splits)\n",
    "\n",
    "def simple_truncate_text(row, max_length=50, tokenizer: transformers.PreTrainedTokenizerFast = None):\n",
    "    \"\"\"Example of a simple truncation method text, based on token count.\n",
    "    \n",
    "    You might want to perform 'smarter' truncation / summarization as a level, instead of simply cutting of after `max_length` tokens.\n",
    "    \n",
    "    Examples:\n",
    "        You might want to partially-apply the function, to provide a different tokenizer:\n",
    "        ```python3\n",
    "        from functools import partial\n",
    "        some_other_tokenizer = transformers.AutoTokenizer.from_pretrained('your_fave_tokenizer')\n",
    "        partial_simple_truncate = partial(simple_truncate_text, tokenizer=some_other_tokenizer)\n",
    "        ```\n",
    "    Args:\n",
    "        row (datasets....): Single instance or row of dataset.\n",
    "    \n",
    "    Keyword Args:\n",
    "        max_length (int, 150): the maximum length of text to be processed. Defaults to 150.\n",
    "        tokenizer (transformers.PreTrainedTokenizer, `fast_tokenizer`): the tokenizer to use. Defaults to `fast_tokenizer`.\n",
    "    \n",
    "    Notes:\n",
    "        This function requires all cells above to be run.\n",
    "    \"\"\"\n",
    "    token_representation = tokenizer.batch_encode_plus(row['text'], max_length=max_length, truncation=True)['input_ids']\n",
    "    text_representation = tokenizer.batch_decode(token_representation, skip_special_tokens=True)\n",
    "    row['text'] = text_representation\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259cdbad45c06320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:41.586814Z",
     "start_time": "2024-10-17T18:57:40.060042Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6a8bb7674c4ac7914d5e6bc5c18945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70a1dbb233446589e5fbacf03232325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79e950582e04129872a699992c4cbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182ce096265d432caa2c9965733f4e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee76e1425c8149ceb15c4d8b9b376a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bf655c917c4d03ad383b4f3f02a83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53861338085d44c986ef9c197a1777bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tokenizer for flan family\n",
    "family: str = \"google/flan-t5\"\n",
    "# For the Lab we will use a small model, just to provide some insight into usability.\n",
    "model: str = f\"small\"\n",
    "model_name: str = f\"{family}-{model}\"\n",
    "\n",
    "tokenizer: T5Tokenizer\n",
    "fast_tokenizer: T5TokenizerFast\n",
    "model: T5ForConditionalGeneration\n",
    "\n",
    "# NOTE, you might need to change this for different model Families\n",
    "#   as T5 family specifically is a encoder-decoder whereas most text gen. models are\n",
    "#   of type AutoModelForCausalLM.\n",
    "model_type: Type[transformers.GenerationMixin] = transformers.AutoModelForSeq2SeqLM\n",
    "# model_type: Type[transformers.GenerationMixin] = transformers.AutoModelForCausalLM\n",
    "device, backend = get_available_device()\n",
    "model, tokenizer, fast_tokenizer = get_model(\n",
    "    model_name=model_name,\n",
    "    model_type=model_type,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=device,\n",
    ")\n",
    "# Set the model to Evaluation to prevent creating a computational graph\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fc8a578e46a5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.796132Z",
     "start_time": "2024-10-17T18:57:41.603123Z"
    },
    "tags": [
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b7ff05c81c4e25b89da2436f283bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9968af4854d469f912b5a676efb5f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f079be3857d24ee4b5c895b2817d65a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b72971f6aeb4dce8feb4a492936c391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a052657a473d4af28dcd343132f6496f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198f38d3a4404ecdafc9b299f13c77ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7338d0147a07416db3d0bf40b306f4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Text  | Label   |\n",
       "|:-----:|:-------:|\n",
       "|i completely agree with jamrom4.. this w... | 0 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_name: str = 'stanfordnlp/imdb'\n",
    "splits = ['train', 'test', 'unsupervised']\n",
    "train_set, test_set, *_ = get_dataset(data_name, splits=splits)\n",
    "text, label = f\"{train_set[1239]['text'][:40]}...\", train_set[0]['label']\n",
    "display(\n",
    "    Markdown(\n",
    "f\"\"\"\n",
    "| Text  | Label   |\n",
    "|:-----:|:-------:|\n",
    "|{text} | {label} |\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292f54f98fcec96",
   "metadata": {},
   "source": [
    "## (Optional) Becoming a Jinja Ninja!\n",
    "\n",
    "As a starting point for data-manipulation, here are some exercises to get used with Jinja! We recommend looking into Jinja templating, with variables and for loops.\n",
    "As you will see, Jinja is a very flexible templating engine, that allows you to wrangle the IMDb dataset that we will use into the correct format for your experiments.\n",
    "\n",
    "In the following exercises you can see how you can:\n",
    "\n",
    "1. Render parameters in a Jinja Template\n",
    "2. Render lists in a Jinja Template\n",
    "3. Render `zip`ped list in a Jinja Template\n",
    "\n",
    "> N.B. use the test methods to see what is expected / the expected return statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1838a551c4edde2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.862812Z",
     "start_time": "2024-10-17T18:57:44.857041Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is: Your name :)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(example_template\u001b[38;5;241m.\u001b[39mrender(MY_NAME\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour name :)\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Implement a template that uses variables `course` `professor` and `ta`\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Would render `I follow MSGAIs 2024/2025 taught by Prof. L. Y. Chen, and can contact Ir. J. M. Galjaard for questions.`\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m VAR_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[43mtextwrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdedent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# YOUR CODE GOES HERE\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# END OF YOUR CODE\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m variables_template \u001b[38;5;241m=\u001b[39m jinja2\u001b[38;5;241m.\u001b[39mTemplate(\n\u001b[1;32m     18\u001b[0m     VAR_TEMPLATE   \n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m variables \u001b[38;5;241m=\u001b[39m jinja2schema\u001b[38;5;241m.\u001b[39minfer(VAR_TEMPLATE)\n",
      "File \u001b[0;32m~/anaconda3/envs/msgai/lib/python3.10/textwrap.py:438\u001b[0m, in \u001b[0;36mdedent\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Look for the longest leading string of spaces and tabs common to\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# all lines.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m margin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43m_whitespace_only_re\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m indents \u001b[38;5;241m=\u001b[39m _leading_whitespace_re\u001b[38;5;241m.\u001b[39mfindall(text)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indent \u001b[38;5;129;01min\u001b[39;00m indents:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "example_template = jinja2.Template(\n",
    "    textwrap.dedent(\n",
    "        \"\"\"\\\n",
    "        Hello my name is: {{ MY_NAME }}\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "print(example_template.render(MY_NAME=\"Your name :)\"))\n",
    "\n",
    "# Implement a template that uses variables `course` `professor` and `ta`\n",
    "# Would render `I follow MSGAIs 2024/2025 taught by Prof. L. Y. Chen, and can contact Ir. J. M. Galjaard for questions.`\n",
    "VAR_TEMPLATE = textwrap.dedent(\n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    ")\n",
    "variables_template = jinja2.Template(\n",
    "    VAR_TEMPLATE   \n",
    ")\n",
    "variables = jinja2schema.infer(VAR_TEMPLATE)\n",
    "assert set(variables.keys()) == {'course', 'professor', 'ta'}, 'Not all variables are used'\n",
    "\n",
    "# As example\n",
    "print(variables_template.render(course ='MSGAIS', professor='Lydia', ta='Jeroen'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efb1eca7a2b70333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.909692Z",
     "start_time": "2024-10-17T18:57:44.905181Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to implement:\n",
      "* Basic prompting\n",
      "* Few-shot Learning\n",
      "* Fine-Tuning\n",
      "* Bonus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Implement a template that uses a variable `exercises` that contains a list of strings.\n",
    "#  it should render as a Markdown list\n",
    "# HINT: use a jinja for-loop\n",
    "list_expected = \"\"\"I need to implement:\n",
    " * Basic prompting\n",
    " * Few-shot Learning\n",
    " * Fine-Tuning\n",
    " * Bonus\"\"\"\n",
    "LIST_TEMPLATE = textwrap.dedent(\n",
    "    \"\"\"\\\n",
    "    I need to implement:{% for exercise in exercises %}\n",
    "    * {{ exercise }}{% endfor %}\n",
    "    \"\"\"\n",
    ")\n",
    "list_template = jinja2.Template(\n",
    "    LIST_TEMPLATE\n",
    ")\n",
    "variables = jinja2schema.infer(LIST_TEMPLATE)\n",
    "assert 'exercises' in set(variables.keys()), 'Exercise variables is not used!'\n",
    "print(list_template.render(exercises=['Basic prompting', 'Few-shot Learning', 'Fine-Tuning', 'Bonus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bef041258f923cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.957926Z",
     "start_time": "2024-10-17T18:57:44.954115Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Implement a template that uses a variable `points_exercises` that contains a list of tuples.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# HINT: use a jinja for-loop and variable unrolling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m zip_expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mI need to implement:\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m* (20) Basic prompting\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m* (20) Few-shot Learning\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m* (20) Fine-Tuning\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m* (10) Bonus\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m ZIP_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[43mtextwrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdedent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# YOUR CODE GOES HERE\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# END OF YOUR CODE\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m zip_template \u001b[38;5;241m=\u001b[39m jinja2\u001b[38;5;241m.\u001b[39mTemplate(\n\u001b[1;32m     15\u001b[0m     ZIP_TEMPLATE\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m variables \u001b[38;5;241m=\u001b[39m jinja2schema\u001b[38;5;241m.\u001b[39minfer(ZIP_TEMPLATE)\n",
      "File \u001b[0;32m~/anaconda3/envs/msgai/lib/python3.10/textwrap.py:438\u001b[0m, in \u001b[0;36mdedent\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Look for the longest leading string of spaces and tabs common to\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# all lines.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m margin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43m_whitespace_only_re\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m indents \u001b[38;5;241m=\u001b[39m _leading_whitespace_re\u001b[38;5;241m.\u001b[39mfindall(text)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indent \u001b[38;5;129;01min\u001b[39;00m indents:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Implement a template that uses a variable `points_exercises` that contains a list of tuples.\n",
    "# HINT: use a jinja for-loop and variable unrolling\n",
    "zip_expected = \"\"\"I need to implement:\n",
    "* (20) Basic prompting\n",
    "* (20) Few-shot Learning\n",
    "* (20) Fine-Tuning\n",
    "* (10) Bonus\"\"\"\n",
    "\n",
    "ZIP_TEMPLATE = textwrap.dedent(\n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    ")\n",
    "zip_template = jinja2.Template(\n",
    "    ZIP_TEMPLATE\n",
    ")\n",
    "variables = jinja2schema.infer(ZIP_TEMPLATE)\n",
    "assert set(variables.keys()) == {'points_exercises'}, 'Exercise variables is not used!'\n",
    "print(zip_template.render(points_exercises=[(20, 'Basic prompting'), ( 20, 'Few-shot Learning'), (20, 'Fine-Tuning'), (10, 'Bonus')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83315bec1160669c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:45.016502Z",
     "start_time": "2024-10-17T18:57:45.010507Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exercise 0.1 Optional exercise result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m======================================================================\n",
      "ERROR: test_1_variable (__main__.TestJinjaNinja)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8029/3247579533.py\", line 11, in test_1_variable\n",
      "    result = variables_template.render(course=course, professor=professor, ta=ta)\n",
      "NameError: name 'variables_template' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_3_list_zipped (__main__.TestJinjaNinja)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_8029/3247579533.py\", line 33, in test_3_list_zipped\n",
      "    result = zip_template.render(points_exercises=list(zip(self.points, self.exercises)))\n",
      "NameError: name 'zip_template' is not defined. Did you mean: 'list_template'?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do not edit the following code.\n",
    "class TestJinjaNinja(unittest.TestCase):\n",
    "    exercises = ['Basic prompting', 'Few-shot Learning', 'Fine-Tuning', 'Bonus']\n",
    "    points = [20, 20, 20, 10]\n",
    "    def test_1_variable(self):\n",
    "        \n",
    "        check_against = \"I follow MSGAIs 2024/2025 taught by Prof. L. Y. Chen, and can contact Ir. J. M. Galjaard for questions.\"\n",
    "        course = 'MSGAIs 2024/2025'\n",
    "        professor = 'Prof. L. Y. Chen'\n",
    "        ta = 'Ir. J. M. Galjaard'\n",
    "        result = variables_template.render(course=course, professor=professor, ta=ta)\n",
    "        self.assertEqual(result, check_against)\n",
    "    \n",
    "    def test_2_list_template(self):\n",
    "        check_against = textwrap.dedent(\"\"\"\\\n",
    "        I need to implement:\n",
    "        * Basic prompting\n",
    "        * Few-shot Learning\n",
    "        * Fine-Tuning\n",
    "        * Bonus\"\"\")\n",
    "        result = list_template.render(exercises=self.exercises)\n",
    "        self.assertEqual(result, check_against)\n",
    "        \n",
    "    \n",
    "    def test_3_list_zipped(self):\n",
    "        check_against = textwrap.dedent(\"\"\"\\\n",
    "        I need to implement:\n",
    "        * (20) Basic prompting\n",
    "        * (20) Few-shot Learning\n",
    "        * (20) Fine-Tuning\n",
    "        * (10) Bonus\"\"\")\n",
    "        \n",
    "        result = zip_template.render(points_exercises=list(zip(self.points, self.exercises)))\n",
    "        self.assertEqual(result, check_against)\n",
    "        \n",
    "f = io.StringIO()\n",
    "with contextlib.redirect_stderr(f):\n",
    "    display(Markdown(\"### Exercise 0.1 Optional exercise result\"))\n",
    "    TextTestRunner(verbosity=-1).run(defaultTestLoader.loadTestsFromTestCase(TestJinjaNinja))\n",
    "    display(Markdown('---'))\n",
    "    print(f\"\\033[91m{f.getvalue()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1bf56e5e2bf4a",
   "metadata": {},
   "source": [
    "# Exercise 1: Prompt-based Evaluation (20 points total) \n",
    "Instead of fine-tuning a model specific to a problem, we can use the language model's capability to follow instructions to perform a specific task. In all these tasks, we will make use of the IMDB movie review sentiment dataset. Throughout this, and following exercises, we will be 'asking' the model to predict the sentiment (Positive or Negative). \n",
    "\n",
    "A naive idea, is ask the model simply: ``Has the following a Positive or Negative sentiment?''.\n",
    " \n",
    "In this exercise, you will;\n",
    "\n",
    "1. **Exercise 1.1**     (5 points) implement two 'Zero-Shot' prompts 'templates', that prompt the model to decide upon the semtiment without additional information\n",
    "2. **Exercise 1.2:**    (8 points) Perform DoE with different system- and/or hyper-parameters during generation, to evaluate how they impact the models performance (accuracy).\n",
    "3. **Exercise 1.3:**    (7 points) Analyse the result of your DoE experiments, usign ANOVA.\n",
    "\n",
    "\n",
    "The goal here is to evaluate the impact of different hyper-parameters and/or system-parameters on the classification accuracy of the model.\n",
    "\n",
    "> ❗One of the levels in your DoE, will be the input representation, i.e., a `simple_prompt` and a more contextual `detailed_prompt`. You will implement these Zero-Shot prompts. The simple prompt should be a mere short question, whereas the detailed prompt should give additional context, e.g., about the domain / task that is performed.\n",
    "\n",
    "\n",
    "> *N.B.* to guide you through the exericse, we annotate things you will need to implement. In the lab we will provide some example on how to tackle this.\n",
    "\n",
    " ```python\n",
    " # YOUR CODE GOES HERE!\n",
    "\n",
    " # END OF YOUR CODE!\n",
    " ```\n",
    "\n",
    "**⚠ FAIR Warning:**\n",
    "\n",
    "> YOU should make sure to store results to disk or other persisten storage, i.e. by writing to a file or saving a model. For example when you want to run with different models you should make sure that data is not accidentally overwritten!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37feec8b86609a95",
   "metadata": {},
   "source": [
    "## Exercise: 1.1 Prompt-Design (5 points)\n",
    "\n",
    "First, we ensure that we can represent the data to the model with our designed prompt, for this, you will need to implement the following behavior;\n",
    "\n",
    "1. A simple (yes/no)-like question for the prompt in `get_simple_prompt_template`. (2 points (left / right)).\n",
    "    * This should ask for a `positive`/`Positive` or `negative`/`Negative` as answer, i.e., asking to classify the sentiment of text.\n",
    "2. A detailed (contextual) question for the prompt in `get_detailed_prompt_template`. (3 points (left / right)).\n",
    "    * This should ask for a `positive`/`Positive` or `negative`/`Negative` as answer, i.e., asking to classify the sentiment of text.\n",
    "    * The question should provide additional context regarding the task that is performed (e.g., sentiment analysis, type of task that is peformed, etc.).\n",
    "\n",
    "\n",
    "**N.B**, we don't recommend using a library like `langchain` to do the homework, as they can become restrictive in the specifics that you want to use. You can opt to use it, but the course does not provide support on additional optional frameworks.\n",
    "\n",
    "**N.B.** we do recommend using Jinja to create templates for prompts. This allows to quickly transform input for your experiments for your execution of DoE.\n",
    "\n",
    "Additionally, make sure to use the appropriate `textwrap.dedent` option, if you use triple-quoted (multi-line) `str`ings! Otherwise, you will add (unintenional) whitespace `char`s!\n",
    "\n",
    "> If you are unsure how to do this, see the Preparation exercise above, as they provide some hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236f5b0f187306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:45.055920Z",
     "start_time": "2024-10-17T18:57:45.050361Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def get_simple_prompt_template(\n",
    "        side: str = 'left',\n",
    ") -> jinja2.Template:\n",
    "    \"\"\"Implements a simple Template retrieval function, that takes as argument `review` and renders as a simple prompt.\n",
    "    Keyword Args:\n",
    "        side (str, 'left'): Position at which to add the question for the prompt.\n",
    "        \n",
    "    Returns:\n",
    "        jinja.Template that can render an argument `review`, consisting of a string represention of a review.\n",
    "    \"\"\"\n",
    "    # TODO: Implement a simple zero-shot style yes/no style QA Template.    \n",
    "    match side:\n",
    "        case 'left':\n",
    "            # TODO: Implement question first, then `review`\n",
    "\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                ...\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "        case 'right':\n",
    "            # TODO: Implement `review` first, then question\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                ...\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "    assert set(jinja2schema.infer(PROMPT_TEMPLATE).keys()) == {'review'}, \"Your template does not use the `review` argument.\"\n",
    "    return jinja2.Template(PROMPT_TEMPLATE)\n",
    "\n",
    "\n",
    "\n",
    "simple_template_l = get_simple_prompt_template(side='left')\n",
    "\n",
    "simple_template_r = get_simple_prompt_template(side='right')\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        simple_template_l.render(review='Review would go here...').replace('\\n', '<br>')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9711e7b2bed19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:51.676793Z",
     "start_time": "2024-10-17T18:57:51.670852Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [],
   "source": [
    "# RUN EVALUATION\n",
    "# Don't change the code below.\n",
    "\n",
    "def nl_to_br(inp, br: str='<br>'):\n",
    "    return inp.replace('\\n', br)\n",
    "\n",
    "example_review = f\"{train_set[1203]['text'][:142]}...\"\n",
    "simple_prompt_l = nl_to_br(simple_template_l.render(review='Review would go here...'))\n",
    "simple_example_l = nl_to_br(simple_template_l.render(review=example_review))\n",
    "\n",
    "simple_prompt_r = nl_to_br(simple_template_r.render(review='Review would go here...'))\n",
    "simple_example_r = nl_to_br(simple_template_r.render(review=example_review))\n",
    "\n",
    "display(\n",
    "    Markdown('### Exericse 1.1.1 Result'),\n",
    "    HTML(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (left)</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (right)</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_prompt_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_prompt_r}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_example_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_example_r}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4be7333feb5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:58:25.333078Z",
     "start_time": "2024-10-17T18:58:25.325696Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_detailed_prompt_template(\n",
    "        side='left',\n",
    ") -> jinja2.Template:\n",
    "    \"\"\"Implements a detailed contextual Template retrieval function, that takes as argument `review` and renders a detailed prompt\n",
    "    with contextual information.\n",
    "    \n",
    "    Keyword Args:\n",
    "        side (str, 'left'): Position at which to add the question for the prompt.\n",
    "        \n",
    "    Returns:\n",
    "        Template that can render an argument `review`, consisting of a string representation of a review.\n",
    "    \"\"\"\n",
    "    match side:\n",
    "        case 'left':\n",
    "            # TODO: Implement Question-first, Context second template.\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                ...\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "        case 'right':\n",
    "            # TODO: Implement Context-first, Question-second template.\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                ...\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "    assert set(jinja2schema.infer(PROMPT_TEMPLATE).keys()) == {'review'}, \"Your template does not use the `review` argument.\"\n",
    "    return jinja2.Template(PROMPT_TEMPLATE)\n",
    "\n",
    "detailed_template_l = get_detailed_prompt_template(\n",
    "    side='left',\n",
    ")\n",
    "detailed_template_r = get_detailed_prompt_template(\n",
    "    side='right',\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown('### Exericse 1.1.2 Result'),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "        f\"\"\"\\\n",
    "        | **My simple prompt (left)** | **My simple prompt (right)** |\n",
    "        |-----------------------------|------------------------------|\n",
    "        | {simple_prompt_l}           | {simple_prompt_r}            |\n",
    "        | **Example**                 | **Example**                  |\n",
    "        | {simple_example_l}          | {simple_example_r}           |\n",
    "        \"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46592fc82afbeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:58:26.141192Z",
     "start_time": "2024-10-17T18:58:26.135592Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [],
   "source": [
    "# RUN EVALUATION\n",
    "# Don't change the code below.\n",
    "example_review = f\"{train_set[1203]['text'][:142]}...\"\n",
    "\n",
    "detailed_prompt_l = nl_to_br(detailed_template_l.render(review='Review would go here...'))\n",
    "detailed_example_l = nl_to_br(detailed_template_l.render(review=example_review))\n",
    "\n",
    "detailed_prompt_r = nl_to_br(detailed_template_r.render(review='Review would go here...'))\n",
    "detailed_example_r = nl_to_br(detailed_template_r.render(review=example_review))\n",
    "\n",
    "display(\n",
    "    Markdown('### Exericse 1.1.2 Result'),\n",
    "    HTML(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (left)</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (right)</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_prompt_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_prompt_r}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_example_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_example_r}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988b661f54c8242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:00:01.029080Z",
     "start_time": "2024-10-17T19:00:00.990553Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the truncated eval set.\n",
    "MAX_50_TOKENS = 50\n",
    "truncate_to_50_tokens = partial(simple_truncate_text,  max_length=MAX_50_TOKENS, tokenizer=fast_tokenizer)\n",
    "\n",
    "q1_eval_set = (\n",
    "    test_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    ")\n",
    "\n",
    "truncated_example_text, label = nl_to_br(q1_eval_set[0]['text']), q1_eval_set[0]['label']\n",
    "display(\n",
    "    Markdown(\n",
    "    \"\"\"## Example of truncated data\n",
    "Do you see how the text is abruptly terminated after `I tried to like this, I`?\n",
    "\"\"\"),\n",
    "    Markdown(textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            > | **Truncated Review**          | **Label** |\n",
    "            |-------------------------------|-----------|\n",
    "            | {truncated_example_text}      | {label}   |\n",
    "            \"\"\"\n",
    "        )\n",
    "    ),\n",
    "    Markdown('---')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75acf1a1d06bc43",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Design of Experiments (8 points)\n",
    "\n",
    "In this and the following exercise, we are interested in quantifing the effect of different configurations on the zero-shot performance of the model, you will need to select at-least 3 system- and/or hyper-parameters, with each having atleast two or more (2+) levels. Recall that for the first hyper-parameter should use the (`simple` or `detailed`) prompt.\n",
    "\n",
    "Furthermore, we suggest using one or more from the following parameters in your DoE:\n",
    "\n",
    "  * The structure of each prompt (i.e., `left` and `right`)\n",
    "  * Model size, for example (`T5-flan-small`, `T5-flan-base`, `T5-flan-large`, etc.). (only recommended with GPU)\n",
    "  * Numerical precision (`torch.float16`, `torch.float32`, `torch.bfloat16`). Make sure your hardware / `PyTorch` version supports this!\n",
    "  * Quantization (only recommended with GPU with `BitsAndBytes` packages).\n",
    "  * Structured decoding (requires implememtantation).\n",
    "\n",
    "\n",
    "In short, you will need to perform;\n",
    "\n",
    "1. (8 points) Design of Experiments in code;\n",
    "    * Selection of criteria\n",
    "    * Type of factorial experiment\n",
    "    * Creation of experimental configuration\n",
    "    * Run your experiments.\n",
    "        * Depending on your chosen variables in DoE, you might need to make some minor adaptations to our provided code.\n",
    "\n",
    "> For your convenience, we have split first DoE part,  and the Design of Experiments (which you have to implement), and the ANOVA analysis into 2 cells. We strongly recommend writing data to disk/persistent storage and loading it in the next cell to make sure you can easily re-run evaluation upon restarting the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d4b57e32365da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:04:56.099561Z",
     "start_time": "2024-10-17T19:04:56.091263Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def run_q1_evaluation(\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        model: transformers.PreTrainedModel,\n",
    "        generation_config: transformers.GenerationConfig,\n",
    "        *args,\n",
    "        **kwargs\n",
    ") -> Tuple[List[List[str]], List[List[int]]]:\n",
    "    \"\"\"Helper function to run evaluation (e.g. under different evaluations).\n",
    "    \n",
    "    Notes:\n",
    "        You likely don't need to make any changes, as likely most of your levels are;\n",
    "         * system-parameters,\n",
    "         * generation-parameters,\n",
    "         * different ways of pre-processing the review data.\n",
    "    \n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): Dataloader containing the evaluation set. \n",
    "        model (transformers.PreTrainedModel): Pre-Trained model to be evaluated.\n",
    "        generation_config: Generation configuraiton, that may contain some of your hyper-parameters for DoE.\n",
    "        *args: Any additional positional args you want to add.\n",
    "    \n",
    "    Keyword Args:\n",
    "        **kwargs: Any additional keyword args you want to add.\n",
    "\n",
    "    Returns:\n",
    "        List of list containing the `str`ing representation of the models predicition.\n",
    "        List of list containing the `int`eger representation of the ground-truth label.\n",
    "    \"\"\"\n",
    "    prediction_list, label_list = [], []\n",
    "    for idx, batch in (pbar := tqdm(enumerate(dataloader), leave=False, total=len(dataloader))):\n",
    "        pbar.set_description(f'Batch {idx}')\n",
    "        input_ids, attention_mask, label = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch[\n",
    "            'label'].to(device)\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            generation_config=generation_config,\n",
    "            max_new_tokens=5,\n",
    "        )\n",
    "        prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        prediction_list.append(prediction)\n",
    "        label_list.append(label.cpu().tolist())\n",
    "    return prediction_list, label_list\n",
    "\n",
    "\n",
    "def get_q1_sets(\n",
    "        dataset: datasets.Dataset\n",
    ") -> Tuple[datasets.Dataset, datasets.Dataset]:\n",
    "    \"\"\"Helper method to create the low and high level datasets with the `simple` and `detailed` prompt.\n",
    "    \n",
    "    Notes:\n",
    "        You likely don't need to edit this code, but feel free to extend this code, in case you want to\n",
    "        evaluate more different levels\n",
    "    \n",
    "    Args:\n",
    "        dataset (datasets.Dataset): Dataset to be mapped to a simple and detailed representation dataset.\n",
    "        \n",
    "    Returns:\n",
    "        Dataset with text mapped using the `simple_template`.\n",
    "        Dataset with text mapped using the `detailed_template`.\n",
    "    \"\"\"\n",
    "    # 1. Prepare the simple set (low level)\n",
    "    simple_set = (\n",
    "        dataset\n",
    "        .map(\n",
    "            lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "                [simple_template.render(review=row) for row in batch['text']],\n",
    "                truncation=False,\n",
    "                padding=True,\n",
    "            ),\n",
    "            batched=True,\n",
    "        )\n",
    "    )\n",
    "    # Map to input expected by the model.\n",
    "    simple_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    # 2. Prepare the detailed set (high level)\n",
    "    detailed_set = (\n",
    "        dataset\n",
    "        .map(\n",
    "            lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "                [detailed_template.render(review=row) for row in batch['text']],\n",
    "                truncation=False,\n",
    "                padding=True,\n",
    "            ),\n",
    "            batched=True,\n",
    "        )\n",
    "    )\n",
    "    # Map to input expected by the model\n",
    "    detailed_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    \n",
    "    return simple_set, detailed_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50f3347b7e6952",
   "metadata": {},
   "source": [
    "### Exericse 1.2.1 Design of Experiments\n",
    "Define your Design of Experiment configurations in the list `EXPERIMENT_CONFIGURATIONS`, you can use this list to store experiment configurations for the different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0a9dbd3bf7960",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Implement your experimental design here! Decide on hyper-parameters, levels,\n",
    "#  and type of factorial experiment you want to do.\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS: List[Dict[Any, Any]] = [\n",
    "    None\n",
    "]\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef4f0b8d3875d2",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# ONLY SET THIS TO True IFF YOU NEED TO RE-RUN EXPERIMENTS, AS IT WILL\n",
    "#  OVERWRITE YOUR RESULTS.\n",
    "ALLOW_OVERWRITING_RESULTS = False\n",
    "\"\"\"\n",
    "# If you want to experiment with the side of the prompt, you will need to make\n",
    "#  some changes here.\n",
    "\"\"\"\n",
    "simple_template = get_simple_prompt_template(side='left')\n",
    "detailed_template = get_detailed_prompt_template(side='left')\n",
    "\n",
    "# Prepare datasets\n",
    "simple_set, detailed_set = get_q1_sets(q1_eval_set)\n",
    "\n",
    "\n",
    "for configuration in (exp_bar := tqdm(EXPERIMENT_CONFIGURATIONS, leave=True)):\n",
    "    # EXAMPLE CODE HERE\n",
    "    # Determine the maximum lenght given the length of your prompts. \n",
    "    # N.B. You might want to use this, but as we propose a pre-tokenized\n",
    "    simple_overhead = len(tokenizer(simple_template.render(), add_special_tokens=False)['input_ids'])\n",
    "    detailed_overhead = len(tokenizer(detailed_template.render(), add_special_tokens=False)['input_ids'])\n",
    "    \n",
    "    \"\"\"\n",
    "    # You might need to subsample the dataset to 1000, if your hardware is too slow. Make sure to report\n",
    "    #   if and how you sub-sample\n",
    "    simple_set, detailed_set = simple_set.sample(...), detailed_set.sample(...)\n",
    "    \"\"\"\n",
    "    for split, dataset in (split_bar := tqdm(zip(['simple', 'detailed'], [simple_set, detailed_set]), leave=False, total=2)):\n",
    "        q_data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=15,  # Feel free to lower / higher this\n",
    "            shuffle=False,  # Shuffling not needed during evaluation\n",
    "            num_workers=2,\n",
    "            prefetch_factor=10,\n",
    "        )\n",
    "        \n",
    "        begin_time = time.time()\n",
    "        prediction_list, label_list = run_q1_evaluation(\n",
    "            q_data_loader,  # This you should probably not change\n",
    "            model,  # You might need to change / load a different model for model-parameter\n",
    "            configuration,  # You might need to update some kwargs int the generation config for your exp.\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        # Create a flat version to work with.\n",
    "        prediction_list, labels_list = list(chain(*prediction_list)), list(chain(*label_list))\n",
    "        # TODO: Store your results in a way such that you can load it later!\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        # Map the output if we don't recognize it to \n",
    "        label_lut = defaultdict(lambda: -1, {'positive': 1, 'negative': 0})\n",
    "        \n",
    "        predictions = list(map(lambda x: label_lut[x.split(' ')[0].lower()], prediction_list))\n",
    "        \n",
    "        accuracy = sum(map(lambda x: x[0] == x[1], zip(predictions, labels_list))) / len(predictions)\n",
    "        unknown =  sum(map(lambda x: x[0] == -1, zip(predictions, labels_list))) / len(predictions)\n",
    "\n",
    "        print(f\"Accuracy ({split}): {accuracy}, Unknown: {unknown}\")\n",
    "        experiment_description = ...\n",
    "        save_path_experiment = ...\n",
    "        \n",
    "        # Write file to disk\n",
    "        save_path = Path(save_path_experiment)\n",
    "        if not save_path.parent.exists():\n",
    "            # Recursively create directory\n",
    "            save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        if save_path.is_file() and not ALLOW_OVERWRITING_RESULTS:\n",
    "            print(\"YOU ARE TRYING TO OVERWRITE AN EXISTING EXPERIMENT FILE!\")\n",
    "            raise Exception(\"Cannot overwrite existing experiment file without `ALLOW_OVERWRITING_RESULTS` flag set.\")\n",
    "        \n",
    "        with open(save_path, 'w') as f:\n",
    "            # TODO: You might want to save some additional results.\n",
    "            json.dump({\n",
    "                \"description\": experiment_description,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"unknown\": unknown,\n",
    "                \"begin_time\": begin_time,\n",
    "                \"end_time\": end_time,\n",
    "            }, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d1596d80e9011",
   "metadata": {},
   "source": [
    "### Exercise 1.3 Report on DoE (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042f6d110648d9a",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Code for your evaluation of results and write a small report on the \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451491eece3c6a57",
   "metadata": {},
   "source": [
    "\n",
    "*TODO: Write your report here, using appropriate tables, and or $math$, to support your claim.*\n",
    "\n",
    "Make sure to clearly state (among others):\n",
    "\n",
    "1. Which hyper-parameters you are testing \n",
    "2. Which levels you are testing for each experiment\n",
    "3. How many repetitions you use\n",
    "4. Which design of experiment you use: full-factorial / fractional-factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129567b768b27df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a647c148276eaf5",
   "metadata": {},
   "source": [
    "# Exercise 2: Learning Through Examples 'In-Context Learning' (20 points total)\n",
    "\n",
    "Instead of asking the model its decision at face-value, in this exercise we will provide the model with a view examples. Although the jury is out on why this exactly works, the idea is that the examples allow to 'prime' the model, to understand the task better that it is going to perform.\n",
    "\n",
    "In short, this exercise consists of the following parts;\n",
    " 1. **Exercise 2.1.1:**  (2 points) Design and implementation a few-shot template in (`get_few_shot_prompt_template`).\n",
    " 2. **Exercise 2.1.2:**  (3 points) Implementation of Few-shot dataloader with independently randomly drawn context.\n",
    " 3. **Exercise 2.1.3:**  (BONUS 10 points) few-shot dataloader with independently drawn semantic context.\n",
    " 4. **Exercise 2.2:**:   (8 points) perform Design of Experiments.\n",
    " 5. **Exercise 2.3:**    (7 points) Analyise and write-up the DoE results.\n",
    "\n",
    "**N.B.** we recommend using Jinja to create templates for prompts. This allows to quickly transform the IMDB samples `text` `str`ings to Few-Shot samples, to be used in your DoE. Additionally, make sure to use `textwrap.dedent` to wrap around triple-quoted (multi-line) `str`ings! Otherwise, you will add (unintentional) whitespace `char`s!\n",
    "\n",
    "> If you find performing 2 and 3 difficult, you can also hard-code some review, and choose an additional system or hyper-parameter!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e65ca5cc5be5d6",
   "metadata": {},
   "source": [
    "## 2.1.2 Creating a Few-Shot Template (2 points)\n",
    "First design a template that allows to render a varying number of few shot examples.\n",
    "\n",
    "Your template should take as arguments\n",
    "\n",
    "* `question_answer_pairs` of type `List[Tuple[str, str]]`, i.e., a list of tuples containing a review and a stringified sentiment.\n",
    "* `review` of type `str` that contains the review the model should classify.\n",
    "\n",
    "Your template should render the text in a way that provides the model with examples (`question_answer_pairs`), and then provides the `review` to be classified by the model. You can use your insights from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d68485e1d025ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:26:55.168511Z",
     "start_time": "2024-10-17T19:26:55.159686Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def get_few_shot_prompt_template() -> jinja2.Template:\n",
    "    \"\"\"Function to get a few-shot template to render render Few-Shot prompts in a `dataset.map` function.\n",
    "    \n",
    "    Notes:\n",
    "        The prompt-template uses a variable `question_answer_pair` and `review` as input.\n",
    "        \n",
    "    Examples:\n",
    "        ```\n",
    "        template = get_few_shot_prompt_template()\n",
    "        template.render(question_answer_pair=[('Wow I like this movie', 'Positive'), ('I like the Sequels better...', 'Negative')], review='I like this movie')\n",
    "        ```\n",
    "\n",
    "    Returns:\n",
    "        jinja2.Template that can be rendcered \n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement a few-shot style evaluation prompt, the prompt should use a \n",
    "    #  variable `question_answer_pair`, consisting of a list of Tuples of Reviews and (textual) Labels.\n",
    "    PROMPT_TEMPLATE = textwrap.dedent(\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "    )\n",
    "    assert set(jinja2schema.infer(PROMPT_TEMPLATE).keys()) == {'question_answer_pairs', 'review'}\n",
    "    template = jinja2.Template(PROMPT_TEMPLATE)\n",
    "    return template\n",
    "\n",
    "simple_few_shot_template = get_few_shot_prompt_template()\n",
    "\n",
    "empty_pairs, empty_review = [('', ''), ('', '')], ''\n",
    "empty_template_result = simple_few_shot_template.render(question_answer_pairs=empty_pairs, review=empty_review)\n",
    "example_pairs, example_review = ([('I like the movie', 'Positive'), ('I dislike the movie', 'Negative')], \n",
    "                                 'Event the prequels were far better than this!')\n",
    "example_template_result = simple_few_shot_template.render(question_answer_pairs=example_pairs,review=example_review)\n",
    "\n",
    "display(\n",
    "    Markdown('**Your few-shot prompt looks like this.**'),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {nl_to_br(empty_template_result)}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ),\n",
    "    Markdown('**As an example, your few-shot prompt looks like this.**'),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {nl_to_br(example_template_result)}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5766737b2a26c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:26:57.911755Z",
     "start_time": "2024-10-17T19:26:57.905168Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not edit this cell\n",
    "display(\n",
    "    Markdown('### Exercise 2.1.1 output'),\n",
    "    Markdown('**Few-Shot prompt looks like this.**'),\n",
    "    HTML(\n",
    "    textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My few-shot prompt (empty)</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My few-shot prompt (example)</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{nl_to_br(empty_template_result)}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{nl_to_br(example_template_result)}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20d8a00678ba1b",
   "metadata": {},
   "source": [
    "## 2.1.2 Create a Few-Shot Dataset (3 points)\n",
    "\n",
    "Next you will complete the implementation to create a Few-Shot `Dataset` that contains the pre-processed few-shot examples, rendered with your template from `2.1.2`. Herein, we will use a `shots` parameter that dictates the size of the context that is provided to the model. Make sure that the shots are randomly drawn for each exercise, but if you find this difficult, hard-coding a set of positive and negative examples is OK as well for 1 out of 3 points.\n",
    "\n",
    "Within this exercise, points are awarded for: \n",
    "\n",
    "* Creating a Dataset with a configurable number of shots (1 point)\n",
    "* Configurable number of randomly drawn shots (2 point)\n",
    "\n",
    "\n",
    "> Note, here you can already set one of the level, by making the `K` of shots configurable, you can also think about the ratio of Positive / Negative.\n",
    "\n",
    "> If you want, and your resources allow for it, you might want to combine the Few-Shot idea with your prompt-based approach, you can use that as a variable, and choose one additional hyper- and/or system-parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe929e482037a3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:27:15.295719Z",
     "start_time": "2024-10-17T19:27:14.543531Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def draw_batched_random_shots(\n",
    "    batch: Dict[str, List[Any]],\n",
    "    positive_dataset: datasets.Dataset = None,\n",
    "    negative_dataset: datasets.Dataset = None,\n",
    "    template: transformers.PreTrainedTokenizer = None,\n",
    "    shuffle=False,\n",
    "    shots=4,\n",
    ") -> Dict[str, List[Any]]:\n",
    "    \"\"\"Method to implement drawing random shots of data.\n",
    "    Args:\n",
    "        batch (Dict[str, List[str]]): Batch of data to convert to in-context example dataset. \n",
    "        dataset (datasets.Dataset): Dataset to use for drawing random shots. \n",
    "        tokenizer (transformers.PreTrainedTokenizer): the tokenizer to use to convert shot to... \n",
    "        shots (int, 4): Number of shots to sample, defaults to 4. \n",
    "\n",
    "    Returns:\n",
    "        Transformed representation of a batch of samples with the `text` representation updated.\n",
    "    \"\"\"\n",
    "    batch_texts = batch['text']\n",
    "    \"\"\"\n",
    "    Recall that  \n",
    "    text_labels = 'Positive' if label == 0 else 'Negative'\n",
    "    \"\"\"\n",
    "   \n",
    "    # These Lists you need to construct.\n",
    "    result: List[str] = []\n",
    "    positive_shots: List[List[str]] = []\n",
    "    negative_shots: List[List[str]] = []\n",
    "    \n",
    "    # TODO: Implement code to create random contexts of positive and/or negative reviews.\n",
    "    # Hint: use the positive_dataset and negative_dataset\n",
    "    # Hint: dataset can be shuffled, and `take`n from.\n",
    "    # Hint: if you find this difficult, or as additional level you can also hard-code these lists\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    "    \n",
    "    # Merge your sampled or hard-coded shots into a rendered string.\n",
    "    for random_positives, random_negatives, review in zip(positive_shots, negative_shots, batch_texts):\n",
    "        context = random_positives + random_negatives\n",
    "        if shuffle:\n",
    "            random.shuffle(context)\n",
    "        random.shuffle(context)\n",
    "        result.append(\n",
    "            template.render(\n",
    "                question_answer_pairs=context,\n",
    "                review=review\n",
    "            )\n",
    "        )\n",
    "    batch['text'] = result\n",
    "    return batch\n",
    "\n",
    "def get_simple_few_shot_dataset(\n",
    "        train_set: datasets.Dataset,\n",
    "        test_set: datasets.Dataset,\n",
    "        *sample_args,\n",
    "        **sample_kwargs \n",
    ") -> datasets.Dataset:\n",
    "    \"\"\"Function to get a few-shot dataloader that loads random examples from the correst split.\n",
    "    \n",
    "    Args:\n",
    "        train_set (): \n",
    "        test_set (): \n",
    "        shots (int, 4): Number of shots to draw, defaults to 4. \n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    positive_set = train_set.filter(\n",
    "        lambda sample: sample['label'] == 1, batched=False\n",
    "    )\n",
    "    negative_set = train_set.filter(\n",
    "        lambda sample: sample['label'] == 0, batched=False\n",
    "    )\n",
    "    partial_draw_random_shots = partial(draw_batched_random_shots, positive_dataset=positive_set, negative_dataset=negative_set, **sample_kwargs)\n",
    "    return_set = (\n",
    "        test_set\n",
    "        .map(partial_draw_random_shots, batched=True, num_proc=1) # Map to stringified representation\n",
    "    )\n",
    "    return return_set\n",
    "\n",
    "\n",
    "truncated_train_set = (\n",
    "    train_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    ")\n",
    "truncated_test_set = (\n",
    "    test_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    ")\n",
    "\n",
    "simple_dataset = get_simple_few_shot_dataset(\n",
    "    truncated_train_set,\n",
    "    truncated_test_set,\n",
    "    template = get_few_shot_prompt_template(),\n",
    "    shots=4\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"**As an example, here is how your data looks like**\"),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {nl_to_br(simple_dataset[0]['text'])}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15d290da26bb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:27:35.473925Z",
     "start_time": "2024-10-17T19:27:35.447404Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not edit this code\n",
    "import random\n",
    "index_1, index_2 = random.randint(0, 2500), random.randint(0, 2500)\n",
    "sample_1 = nl_to_br(simple_dataset.shuffle()[index_1]['text'])\n",
    "sample_2 = nl_to_br(simple_dataset.shuffle()[index_2]['text'])\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Sample ({index_1})</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Sample ({index_2})</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{sample_1}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{sample_2}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08c46ea43477f0",
   "metadata": {},
   "source": [
    "### (BONUS) Exercise 2.1.3 I would like additional context please (BONUS 10)\n",
    "\n",
    "Instead of randomly sampling datapoints to create a Few-Shot context. However, maybe we can do better. An example of this, is to create a more semanticly relevant content, that provide more relevant information for the model to make a decision.\n",
    "\n",
    "For this bonus exericse the recipe is (roughly) as follows:\n",
    "\n",
    " 1. Creating a semantic embeddings of samples to create a context from (an embedding model).\n",
    " 2. Creating a vector database to lookup examples.\n",
    " 3. (Pre-compute) set of example to use (I.e. vector lookup).\n",
    " 4. Render the template (similar as before)\n",
    "\n",
    "We have provided some skeleton code to get started, but TAs cannot provide any assistant for this exericse (unless our template contains an error :))\n",
    "\n",
    "> N.B. that this will take some compute power, so you might want to save the (stringified) dataset that you allow to continue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac6a80fd2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "# We advice to use a small model from Sentence transformer, but feel free to use somethign\n",
    "# completey different, or use this as an additonal level!\n",
    "embedding_model = SentenceTransformer(embedding_model)\n",
    "\n",
    "# TODO: Complete and upate the functions to perfrom semantic search.\n",
    "# As a hint: Look at the imports adn see how they can be used.\n",
    "\n",
    "def create_semantic_db(\n",
    "        embedding_model: SentenceTransformer,\n",
    "        train_set: datasets.Dataset,\n",
    "        test_set: datasets.Dataset\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:  \n",
    "    \"\"\"Function to create a sematnic database.\n",
    "    \n",
    "    Args:\n",
    "        embedding_model (): \n",
    "        train_set (): \n",
    "        test_set (): \n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Load embeddings if they already exist.\n",
    "    data = None\n",
    "    if (embedding_path := Path('embeddings.pkl')).exists():\n",
    "        with open(embedding_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "    \n",
    "    if data is None:\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "    \n",
    "    with open('embeddings.pkl', \"wb\") as fOut:\n",
    "        data = {\n",
    "            'sentences': sentences,\n",
    "            'embeddings': embeddings\n",
    "        }\n",
    "        pickle.dump(data, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    positive_embeddings, negative_embedding = embeddings[:len(embeddings)//2], embeddings[len(embeddings)//2:]\n",
    "    return embeddings, positive_embeddings, negative_embedding\n",
    "\n",
    "def find_batched_semantic_search(\n",
    "        batch: Dict[str, List[str]],\n",
    "        tokenizer: transformers.PreTrainedTokenizer,\n",
    "        corpus_embeddings: torch.Tensor,\n",
    "        negative_corpus_embeddings: torch.Tensor,\n",
    "        positive_corpus_embeddings: torch.Tensor,\n",
    "        shots=4\n",
    ") -> Dict[str, List[str]]:\n",
    "    \n",
    "    # You will have to create a list of rendered string with the found context.\n",
    "    results: List[str] = []\n",
    "    # TODO: Implement a batched `semantic_search` to find relevant items.\n",
    "    \n",
    "    # 1. Perform semantic_search for each item in the batch\n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    "    # 2. Select relevant samples for each sample in the batch\n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    "    # 3. Collate the found results for the batch\n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    "    # 4. Render the results using a template.\n",
    "    # YOUR CODE GOES HERE\n",
    "    ...\n",
    "    # END OF YOUR CODE\n",
    "\n",
    "    batch['text'] = results\n",
    "    return batch\n",
    "\n",
    "def get_contextual_drawn_few_shot_dataset(\n",
    "        train_set: datasets.Dataset,\n",
    "        test_set: datasets.Dataset,\n",
    "        shots: int = 4,\n",
    "        *args,\n",
    "        **kwargs\n",
    ") -> datasets.Dataset:\n",
    "    \"\"\"Function to get a few-shot dataloader based on context.\"\"\"\n",
    "    partial_semantic_search = partial(find_batched_semantic_search, train_set=train_set, test_set=test_set, shots=shots)\n",
    "    return_set = (\n",
    "        test_set\n",
    "        .map(partial_semantic_search, batched=True, num_proc=1) # Map to stringified representation\n",
    "    )\n",
    "    return_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    return return_set\n",
    "\n",
    "# Step 1: Get embeddings\n",
    "corpus_embedding, positive_embedding, negative_embedding = create_semantic_db(\n",
    "    embedding_model=embedding_model,\n",
    "    train_set=train_set,\n",
    "    test_set=test_set\n",
    ")\n",
    "\n",
    "SHOTS = 4   # YOU MIGHT WANT TO CHANGE THIS IF YOU USE SHOTS AS A VARIABLE\n",
    "q2_complex_set = get_contextual_drawn_few_shot_dataset(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    shots=SHOTS\n",
    "    \n",
    ")\n",
    "display(\n",
    "    # TODO: Implement showing an example that shows that it works\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc932d4307f86a75",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Perform DoE (8 points)\n",
    "\n",
    "In this and the following exercise, we are interested in quantifing the effect of different configurations on the Few-Shot performance of the model, you will need to select at-least 3 system- and/or hyper-parameters, with each having at least two or more (2+) levels. Recall that you may wish to use the shots hyper-parameters (e.g. $\\texttt{shots} \\in  [2, 4, 6 ]$).\n",
    "\n",
    "Furthermore, we suggest using one or more from the following parameters in your DoE:\n",
    "\n",
    "  * Model size, for example (`T5-flan-small`, `T5-flan-base`, `T5-flan-large`, etc.). (only recommended with GPU)\n",
    "  * Numerical precision (`torch.float16`, `torch.float32`, `torch.bfloat16`). Make sure your hardware / `PyTorch` version supports this!\n",
    "  * Quantization (only recommended with GPU with `BitsAndBytes` packages).\n",
    "  * Structured decoding (requires implememtantation).\n",
    "\n",
    "\n",
    "In short, you will need to perform;\n",
    "\n",
    "1. (8 points) Design of Experiments in code;\n",
    "    * Selection of critaria.\n",
    "    * Type of factorial experiment.\n",
    "    * Creation of experimental configuration.\n",
    "    * Run your experiments.\n",
    "        * Depending on your chosen variables in DoE, you might need to make some minor adaptations to our provided code.\n",
    "\n",
    "> For your convenience, we have split first DoE part,  and the Design of Experiments (which you have to implement), and the ANOVA analysis into 2 cells. We strongly recommend writing data to disk/persistent storage and loading it in the next cell to make sure you can easily re-run evaluation upon restarting the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ed65e83382979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:35:50.685765Z",
     "start_time": "2024-10-17T19:35:50.678442Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def run_q2_evaluation(\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        model: transformers.PreTrainedModel,\n",
    "        generation_config,\n",
    "        *args,\n",
    "        **kwargs\n",
    ") -> Tuple[List[List[str]], List[List[int]]]:\n",
    "    \"\"\"Helper function to run evaluation (e.g. under different evaluations.\n",
    "    \n",
    "    Args:\n",
    "        dataloader: \n",
    "        model: \n",
    "        generation_config:\n",
    "        *args: Any additional positional args you want to add.\n",
    "    \n",
    "    Keyword Args:\n",
    "        **kwargs: Any additional keyword args you want to add.\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    prediction_list, label_list = [], []\n",
    "    for idx, batch in (pbar := tqdm(enumerate(dataloader), leave=False, total=len(dataloader))):\n",
    "        pbar.set_description(f'Batch {idx}')\n",
    "        input_ids, attention_mask, label = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "        \n",
    "        # TODO: You might need to implement something for your experiment here!\n",
    "\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "        prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        prediction_list.append(prediction)\n",
    "        label_list.append(label.cpu().tolist())\n",
    "    return prediction_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27214eb5a9589b5",
   "metadata": {},
   "source": [
    "### Exericse 2.2.1 Design of Experiments\n",
    "Define your Design of Experiment configurations in the list `EXPERIMENT_CONFIGURATIONS`, you can use this list to store experiment configurations for the different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83544b67b31afedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:39:22.346513Z",
     "start_time": "2024-10-17T19:39:22.342743Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Implement your experimental design here! Decide on hyper-parameters, levels, see Exercise 3 for how to set-this up\n",
    "#  and type of factorial experiment you want to do.\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS: List[Dict[Any, Any]] = [\n",
    "    None\n",
    "]\n",
    "# YOUR CODE GOES HERE\n",
    "...\n",
    "# END OF YOUR CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7bf53133827ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:39:22.783140Z",
     "start_time": "2024-10-17T19:39:22.781415Z"
    },
    "tags": [
     "remove-output",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform inference. See the cells of Exercise 1 and 3 as a starting point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469b309d8d406d7",
   "metadata": {},
   "source": [
    "### Exercise 1.3 Report on DoE (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e3849cecde170",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Perform your calculations for DoE HERE.\n",
    "\n",
    "# 1. Load data\n",
    "\n",
    "# 2. Create model and fit\n",
    "\n",
    "# 3. Check assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68ccacec068493",
   "metadata": {},
   "source": [
    "\n",
    "> TODO: Write your report here, using appropriate tables, and or $math$, to support your claim.\n",
    "\n",
    "Make sure to clearly state (among others):\n",
    "\n",
    " 1. Which hyper-parameters you are testing.\n",
    " 2. Which levels you are testing for each experiment.\n",
    " 3. How many repetitions you use.\n",
    " 4. Which design of experiment you use: full-factorial / fractional-factorial.\n",
    " 5. Whether the assumptions of the model hold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed6320a0a4a80b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfbc09a1c8c754",
   "metadata": {},
   "source": [
    "# Exercise 3: Fine-Tuning Based Classification (20 points total)\n",
    "\n",
    "Lastly, we will perform a fine-tuning based approach, where we will update the model weights in order to 'learn' reply with the clasification of the sentiment of the sentence.\n",
    "\n",
    "**N.B.** We provide most of the code here, as there are multiple non-trivial implementation details. However, the run-time is likely quitea bit longer, so make sure tostart in time.\n",
    "\n",
    "\n",
    "Here we would like to advise to;\n",
    "\n",
    "1. Carefully choose **which hyper-parameters** you want to evaluate, before diving into the implementation, make sure to check that you can reasonably run these experiment within reasonable time.\n",
    "   1. We strongly recommend using a LORA based approach, and focus on; different `target_modules`, `rank`, `alpha`, `drop_out`, and `epochs`.\n",
    "   2. Prefer low values for levels over higher, e.g., a level for epochs can be `1`, or for `steps=100`.\n",
    "   3. You can also try to fine-tune the model, and see whether the fine-tuned model is still capable to perform.\n",
    "   4. If your hardware / pytorch version allows, we also strongly recommend using `bitsandbytes` to further quantize the model, which will speed-up your experiments considerably.\n",
    "2. Preferably run with replication, i.e., at-least a `REPLICATION` of `2`, but if time does not permit for this, a single run is OK as well.\n",
    "3. Look into check-pointing, and recovery, and how much disk-space you need for your experiments.\n",
    "4. Check that you save models to recoverable paths, i.e., you don't overwrite models you train.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f89168d58edd3",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Perform DoE (10 points)\n",
    "\n",
    "First, you will need to complete the following code to Design your experiments.\n",
    "\n",
    "> Note, running training will take some time, so make sure to get started early!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feab3d69b11d0a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:44:16.033631Z",
     "start_time": "2024-10-17T19:44:15.880504Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "def tokenize_function(\n",
    "        batch,\n",
    "        prefix='Is the following Positive or Negative?\\n',\n",
    "        post_fix='\\nAnswer: '):\n",
    "\n",
    "    updated_text = [f\"{prefix}{review}{post_fix}\" for review in batch[\"text\"]]\n",
    "    batch['text'] = updated_text\n",
    "    # We also set the 'response', i.e., what the model should learn\n",
    "    batch['labels'] = tokenizer(['Positive' if label == 1 else 'Negative' for label in batch[\"label\"]], truncation=True, padding='max_length', return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def train_model(\n",
    "        peft_model,\n",
    "        output_dir: str,\n",
    "        peft_training_args,\n",
    "        train_set,\n",
    "        test_set = None,\n",
    "        \n",
    ") -> Tuple[transformers.Trainer, peft.PeftModel]:\n",
    "    assert output_dir is not None, \"Provide an output dir to save the model\"\n",
    "    assert not Path(output_dir).exists(), \"Provided output dir is not unique!\"\n",
    "    \n",
    "    peft_trainer = transformers.Trainer(\n",
    "        model=original_model,\n",
    "        args=peft_training_args,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=test_set,\n",
    "    )\n",
    "    # Pre-train the model\n",
    "    peft_trainer.train()\n",
    "    # Set the fine-tuned model to evaluate, to remove non-deterministic\n",
    "    #  behavior.\n",
    "    peft_model.eval()\n",
    "    return peft_model, peft_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74abca374d20ba7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:44:59.951743Z",
     "start_time": "2024-10-17T19:44:59.941272Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Example of hyper-parameters.\n",
    "RANK = 32               # Rank used in model update (lower is faster, less precise)\n",
    "ALPHA = 64              # Scaling factor for update (∆W x dy ALPHA/RANK)           \n",
    "DROPOUT = 0.05          # Regularization term\n",
    "TRAIN_BATCH_SIZE = 32   # Number of samples\n",
    "# GRADIENT_ACCUMULATION_STEPS=1 # If you have low GPU/hardware, you can increase effective batch-size through this.\n",
    "#                               # It 'sums' gradient over GRADIENT_ACCUMULATION_STEPS, to create an effective-batch-size of\n",
    "#                               # GRADIENT_ACCUMULATION_STEPS * TRAIN_BATCH_SIZE\n",
    "TRAIN_EPOCHS = 5        # Total number of trainnig steps.\n",
    "\n",
    "# If you want to save some time, you can store checkpoints, and load them, to create multiple levels\n",
    "# in a single run. Do note, that huggingface by default uses learning-rate scheduling, so this may\n",
    "# affect your results a bit.\n",
    "\n",
    "# The modules are specific to the model itself.\n",
    "MODULES =  ['o'] # Other options are for example, please read the documentation.\n",
    "                 # ['o'], ['k', 'q'], ['q'], ['k', 'q', 'v'], 'or any other identifier of weights.\n",
    "TORCH_DTYPE = torch.float16\n",
    "\n",
    "# TODO: Decide the levels for your experiment. These can be any of the \n",
    "# aforementioned parameters, or any other hyper-parameter.\n",
    "\n",
    "# Hint: Define the levels as a list of numbers for the unique count of \n",
    "#   levels for a parameter.\n",
    "levels: List[int] = ...\n",
    "# Create a list with the names to keep track of the parameters\n",
    "parameters: List[str] = ...\n",
    "# Create a list with levels for each parameter\n",
    "parameter_levels: Dict[str, List[Any]] = ...\n",
    "\n",
    "# EXAMPLE ONLY\n",
    "# Don't actually use this configuration, as this will be a 3 * 2 * 2 * 3 = 36 experiments (without replication)\n",
    "levels = [3, 2, 2, 3]\n",
    "level_names = ['rank', 'alpha', 'dtype',  'epochs']\n",
    "parameter_levels = {\n",
    "    'rank': [8, 16, 32],\n",
    "    'alpha': [16, 32],\n",
    "    'dtype': [torch.float16, torch.float32],\n",
    "    'epochs': [1, 2, 3]\n",
    "}\n",
    "# END OF EXAMPLE \n",
    "# YOUR CODE GOES HERE\n",
    "...\n",
    "# END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d24b5f911ed99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:45:05.382671Z",
     "start_time": "2024-10-17T19:45:05.375124Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Decide the type of (fractional or full) factorial experiment you want to run.\n",
    "# HINT: use the ANOVAandDOE.ipynb notebook as inspiration, and use functinos from pyDOE3\n",
    "import pyDOE3\n",
    "# EXAMPLE ONLY\n",
    "reduction = 4 # for general factorial experiment.\n",
    "experiment = pyDOE3.gsd(\n",
    "    levels, reduction=reduction\n",
    ")\n",
    "# END OF EXAMPLE\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "...\n",
    "# END OF YOUR CODE\n",
    "\n",
    "experiment_configs = pd.DataFrame(\n",
    "    experiment,\n",
    "    columns=[level_names],\n",
    "    \n",
    ")\n",
    "experiment_configs.index.name = 'Experiment ID'\n",
    "\n",
    "\n",
    "display(\n",
    "    experiment_configs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623172be5efbbf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:44:00.615201Z",
     "start_time": "2024-10-17T19:44:00.556395Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "REPETITIONS = 2\n",
    "\n",
    "# If the number of tokens is a level, you might need to change this\n",
    "train_dataset = (\n",
    "    train_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    "    .map(\n",
    "        tokenize_function, batched=True\n",
    "    )\n",
    "    .map(\n",
    "        lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "            batch['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=False,\n",
    "        ), batched=True\n",
    "    )\n",
    ")\n",
    "# Ensure we can effectively use the model\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "EXPERIMENT_CONFIGURATIONS = []\n",
    "for repetition in range(REPETITIONS):\n",
    "    for experiment_id, config_row in enumerate(experiment_configs.iterrows()):\n",
    "        experiment_config = {k[0]: parameter_levels[k[0]][v] for k, v in config_row[1].to_dict().items()}\n",
    "        \n",
    "        EXPERIMENT_CONFIGURATIONS.append(experiment_config)\n",
    "        print(f\"Running experiment: {experiment_id + 1}, repetition: {repetition + 1}\")\n",
    "        print(f\"Experiment config: {experiment_config}\")\n",
    "        \n",
    "        # BEGIN OF YOUR UPDATE TO THIS CODE\n",
    "        rank = experiment_config['rank']\n",
    "        alpha = experiment_config['alpha']\n",
    "        exp_dtype = experiment_config['dtype']\n",
    "        epochs = experiment_config['epochs']\n",
    "        \n",
    "        lora_config = LoraConfig(\n",
    "            r=rank,\n",
    "            lora_alpha=alpha,\n",
    "            target_modules=MODULES,\n",
    "            lora_dropout=DROPOUT,\n",
    "            bias='none',\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM # Specific for FLAN-T5 model.\n",
    "            # task_type=TaskType.CAUSAL_LM # Specific for Auto-regressive model\n",
    "            # task_type=TaskType.TOKEN_CLS # Specific for Token based classification\n",
    "        )\n",
    "        \n",
    "        original_model, tokenizer, tokenizer_fast = get_model(\n",
    "            model_name=model_name,\n",
    "            device=device,\n",
    "            torch_dtype=exp_dtype,\n",
    "        )\n",
    "        \n",
    "        output_dir = f'./exercise-3/exp_{repetition}_{experiment_id}_rank={rank}_alpha={alpha}_dtype={exp_dtype}_epochs={epochs}'\n",
    "\n",
    "        \n",
    "        peft_training_args = transformers.TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            auto_find_batch_size=False,\n",
    "            per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "            learning_rate=1e-4,\n",
    "            num_train_epochs=epochs,\n",
    "            logging_steps=1000,     # You might need to change this, esp. if you subsample the train set.\n",
    "            # max_steps=10000,        # You can use this instead of epochs, for more fine-grained control.\n",
    "            save_total_limit=2,     # Limit the number of checkpoints to save\n",
    "            save_strategy='steps',\n",
    "            save_steps=1000         # You might need to change this\n",
    "        )\n",
    "        # END OF YOUR UPDATE CODE\n",
    "        \n",
    "        peft_model = get_peft_model(\n",
    "            model=original_model,\n",
    "            peft_config=lora_config,\n",
    "        )\n",
    "        peft_model, peft_trainer = train_model(\n",
    "            peft_model=peft_model,\n",
    "            peft_training_args=peft_training_args,\n",
    "            output_dir=output_dir,\n",
    "            train_set=train_dataset,\n",
    "            test_set=None,\n",
    "        )\n",
    "        peft_model.save_pretrained(output_dir)\n",
    "        \n",
    "        del peft_model, peft_trainer\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print('Finished experiment!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a04bd70f05a7",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Next do the evaluation\n",
    "\n",
    "# ONLY SET THIS TO True IFF YOU NEED TO RE-RUN EXPERIMENTS, AS IT WILL\n",
    "#  OVERWRITE YOUR RESULTS.\n",
    "ALLOW_OVERWRITING_RESULTS = False\n",
    "\"\"\"\n",
    "# If you want to experiment with the side of the prompt, you will need to make\n",
    "#  some changes here.\n",
    "\"\"\"\n",
    "# If the number of tokens is a level, you might need to change this\n",
    "test_dataset = (\n",
    "    test_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    "    .map(\n",
    "        tokenize_function, batched=True\n",
    "    )\n",
    "    .map(\n",
    "        lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "            batch['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=False,\n",
    "        ), batched=True\n",
    "    )\n",
    ")\n",
    "# Ensure we can effectively use the model\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "test_datasloader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=15,  # Feel free to lower / higher this\n",
    "            shuffle=False,  # Shuffling not needed during evaluation\n",
    "            num_workers=2,\n",
    "            prefetch_factor=10,\n",
    "        )\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS = []\n",
    "for experiment_id, config_row in enumerate(experiment_configs.iterrows()):\n",
    "    experiment_config = {k[0]: parameter_levels[k[0]][v] for k, v in config_row[1].to_dict().items()}\n",
    "    \n",
    "    EXPERIMENT_CONFIGURATIONS.append(experiment_config)\n",
    "    \n",
    "original_model, tokenizer, tokenizer_fast = get_model(\n",
    "            model_name=model_name,\n",
    "            device=device,\n",
    "            torch_dtype=torch.float16, # You might need to change this.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694daaf5b0ae77fa",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "for experiment_id, experiment_config in (exp_bar := tqdm(enumerate(EXPERIMENT_CONFIGURATIONS), leave=True)):\n",
    "    # EXAMPLE CODE HERE\n",
    "    for repetition in tqdm(range(REPETITIONS), leave=False):\n",
    "    \n",
    "        # BEGIN OF YOUR UPDATE TO THIS CODE\n",
    "        rank = experiment_config['rank']\n",
    "        alpha = experiment_config['alpha']\n",
    "        exp_dtype = experiment_config['dtype']\n",
    "        epochs = experiment_config['epochs']\n",
    "        \n",
    "        # END OF YOUR UPDATE TO THIS CODE\n",
    "        # TODO: make sure that your output-dir here has the same format as during training.\n",
    "        output_dir = f'./exercise-3/exp_{repetition}_{experiment_id}_rank={rank}_alpha={alpha}_dtype={exp_dtype}_epochs={epochs}'\n",
    "        \n",
    "        peft_model = peft.PeftModel.from_pretrained(original_model, output_dir)\n",
    "        begin_time = time.time()\n",
    "\n",
    "        prediction_list, label_list = run_q1_evaluation(\n",
    "            test_dataset,  # This you should probably not change\n",
    "            peft_model,  # You might need to change / load a different model for model-parameter\n",
    "            experiment_config,  # You might need to update some kwargs int the generation config for your exp.\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        # Create a flat version to work with.\n",
    "        prediction_list, labels_list = list(chain(*prediction_list)), list(chain(*label_list))\n",
    "        # TODO: Store your results in a way such that you can load it later!\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        # Map the output if we don't recognize it to \n",
    "        label_lut = defaultdict(lambda: -1, {'positive': 1, 'negative': 0})\n",
    "        \n",
    "        predictions = list(map(lambda x: label_lut[x.split(' ')[0].lower()], prediction_list))\n",
    "        \n",
    "        accuracy = sum(map(lambda x: x[0] == x[1], zip(predictions, labels_list))) / len(predictions)\n",
    "        unknown =  sum(map(lambda x: x[0] == -1, zip(predictions, labels_list))) / len(predictions)\n",
    "\n",
    "        print(f\"Accuracy ({configuration}): {accuracy}, Unknown: {unknown}\")\n",
    "\n",
    "        \n",
    "        # Write file to disk\n",
    "        save_path = Path(output_dir) / f'result_replication={repetition}.json'\n",
    "        if not save_path.parent.exists():\n",
    "            # Recursively create directory\n",
    "            save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        if save_path.is_file() and not ALLOW_OVERWRITING_RESULTS:\n",
    "            print(\"YOU ARE TRYING TO OVERWRITE AN EXISTING EXPERIMENT FILE!\")\n",
    "            raise Exception(\"Cannot overwrite existing experiment file without `ALLOW_OVERWRITING_RESULTS` flag set.\")\n",
    "        \n",
    "        with open(save_path, 'w') as f:\n",
    "            # TODO: You might want to save some additional results.\n",
    "            json.dump({\n",
    "                \"experiment_config\": experiment_config,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"unknown\": unknown,\n",
    "                \"begin_time\": begin_time,\n",
    "                \"end_time\": end_time,\n",
    "            }, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317714c30c754bdc",
   "metadata": {},
   "source": [
    "## Excercise 3.2 Experimental Analysis (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0790513c814d1",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    " # TODO: Put your code here to perform DoE\n",
    " \n",
    " # 1. Load data\n",
    " \n",
    " # 2. Create model and fit\n",
    " \n",
    " # 3. Check assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b248e19a552f6",
   "metadata": {},
   "source": [
    "# TODO: Write your report here, using appropriate tables, and or $math$, to support your claim.\n",
    "\n",
    "Make sure to clearly state (among others):\n",
    "\n",
    "1. Which hyper-parameters you are testing \n",
    "2. Which levels you are testing for each experiment\n",
    "3. How many repetitions you use\n",
    "4. Which design of experiment you use: full-factorial / fractional-factorial.\n",
    "5. Whether the assumptionsn of hte model hold\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
