{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828e8adc02ee8908",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "# Homework Prompt Design\n",
    "\n",
    "In the last lab we saw that there are different ways to get to the goal of the homework is to apply DoE to guage the effectiveness of different approaches. I.e.,  evaluate different algorithms/approaches that perform classification, and leveraging. **Design of Experiments**. \n",
    "\n",
    "\n",
    "This homework consists the following 4 main parts, 1 facultative exercise to get to know a useful templating language, and 1 bonus exercise. Note the course staff reserves the right to provide corrections to this notebook and/or corresponding code.\n",
    "\n",
    "**N.B.**, this homework is both about using different techniques, and applying DoE. Its purpose is *not* to obtain a State-of-the-Art result, but rather to get to know different methods, understand their respective merrits, and applying them properly.\n",
    "\n",
    "## Submitting the Homework to Ilias\n",
    "**N.B.** To submit this homework, you must render this notebook as a PDF, run the following command in the commandline. Make sure to test this command;\n",
    "\n",
    "```bash\n",
    "jupyter-nbconvert --to pdfviahtml  homework-reference.ipynb --TagRemovePreprocessor.remove_input_tags='{\"hide-cell\",\"hide-student-submission\"}'  --TagRemovePreprocessor.remove_all_outputs_tags='{\"remove-output\"}'         \n",
    "```\n",
    "\n",
    "Before submitting make sure your notebook adheres to the following:\n",
    "\n",
    "1. None of the cells that are tagged as `keep-output` or `hide-cell` are deleted, these are key for the review of your code.\n",
    "2. You have verified that your submission PDF contains all your complete answers, note that;\n",
    "   * cells annotated with `hide-cell` will have their input removed,\n",
    "   * cells annotated with `remove-output` will have their output removed,\n",
    "   * cells annotated with `hide-student-submission` will have their input removed, e.g., this cell\n",
    "   \n",
    "3. Any cells you have added are either: properly annotated with `keep-output` or `hide-cell`, or are manually cleaned.\n",
    "\n",
    "> ⚠️ The course staff reserves the right to withold awarding (partial) points to any of the (sub)exercises if your submitted PDF and notebook do not adhere to these requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a4b24275176c83",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e028ac06b9be99",
   "metadata": {
    "tags": [
     "keep-output"
    ]
   },
   "source": [
    "# Homework 2 Submission\n",
    "\n",
    "| **Detail**      | **Description**  |\n",
    "|-----------------|------------------|\n",
    "| **Name**        | Chenrui Fan      |\n",
    "| **Student No.** | 23-125-818       |\n",
    "| **Year**        | 2024             |\n",
    "| **Course**      | MSGAI            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30aa0f715bb80f2",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "# Before we get started\n",
    "\n",
    "This notebook seems long, but *most of the code* provides a starting point for the objective of this homework; *basic prompt-design and DoE*.\n",
    "Read each exercise carefully, you might find some hints here and there in the provided code!\n",
    "\n",
    "## Homework Overview\n",
    "\n",
    "This homework consists of the following three parts, each consisting of some implementation, and design of experiment. We provide skeleton code to perform the experiments, but you may wish to deviate from it. We recommend doing the exercises in the provided order.\n",
    "\n",
    "1. Zero-shot / Instruction based prediction.\n",
    "2. Few-shot / Example based prediction.\n",
    "3. Fine-Tuning / Learning based prediction.\n",
    "\n",
    "Each exercise consists of;\n",
    "1. A minor implementation of the main concept (see above, except for the `Fine-Tuning / Learning exercise`).\n",
    "2. Design-of-Experiments. We provide a (mostly filled out) example in Exercise 3 that you may wish to use in Exercises 1 and 2.\n",
    "3. Analysis of the DoE results, using ANOVA analysis, herein you need to check the model assumptions.\n",
    "\n",
    "Additionally, there is ONE bonus exercise (2.1.3), worth a maximum of $10$ points, which we recommend tackling last.\n",
    "3. (Bonus) Classification based prediction / Anything you want. Note, contact the TA before starting this BONUS. This BONUS will be of max. 10 points instead of the Semantic Few-Shot Prompting bonus in exercise 2. You can use the results / insights from this also in your project work.\n",
    "\n",
    "**N.B.** You can get a maximum of $60$ points in total, **with an additional maximum of $10$ bonus points**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2112c6c3dc4ff10",
   "metadata": {
    "tags": [
     "remove-output",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Install dependencies (same as the env file, so you may wish to skip this if running locally / with persistent conda environment)\n",
    "#pip install python>=3.10,<4.0.0\n",
    "#pip install nbconvert==6.5.4        \n",
    "#pip install lxml_html_clean==0.3.1  \n",
    "#pip install notebook-as-pdf==0.5.0  \n",
    "#pip install bitsandbytes~=0.42.0\n",
    "#pip install configparser~=7.1.0\n",
    "#pip install datasets>=3.0.1,<4.0.0\n",
    "#pip install flake8-import-order~=0.18.2\n",
    "#pip install fqdn~=1.5.1\n",
    "#pip install isoduration~=20.11.0\n",
    "#pip install jinja2schema~=0.1.4\n",
    "#pip install jsonpointer~=3.0.0\n",
    "#pip install jupyter~=1.1.1,<2.0.0\n",
    "#pip install peft>=0.13.2,<1.0.0\n",
    "#pip install pretty-jupyter==2.0.7\n",
    "#pip install protobuf~=5.28.2,<6.0.0\n",
    "#pip install pyDOE3~=1.0.4\n",
    "#pip install researchpy~=0.3.6\n",
    "#pip install seaborn~=0.13.2\n",
    "#pip install sentence-transformers~=3.2.0\n",
    "#pip install sentencepiece~=0.2.0,<1.0.0\n",
    "#pip install tabulate~=0.9.0\n",
    "#pip install uri-template==1.3.0\n",
    "#pip install webcolors==24.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6016d948465358a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:39.991412Z",
     "start_time": "2024-10-17T18:57:38.272656Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Imports used in most of the exercises\n",
    "import contextlib\n",
    "import io\n",
    "import json\n",
    "\n",
    "import textwrap\n",
    "import time\n",
    "import unittest\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from importlib import metadata\n",
    "from itertools import chain\n",
    "from os import PathLike\n",
    "from functools import partial\n",
    "from typing import Dict, List, Tuple, Union, Dict, Any\n",
    "from typing import Optional, Type\n",
    "from unittest import TextTestRunner, defaultTestLoader\n",
    "\n",
    "import datasets\n",
    "import jinja2\n",
    "import jinja2schema\n",
    "import peft\n",
    "import torch\n",
    "import transformers\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4c0909905289ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:40.029695Z",
     "start_time": "2024-10-17T18:57:39.996363Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2>System Configuration</h2>\n",
       "    <table>\n",
       "        <tr><td><strong>PyTorch version:</strong></td><td>2.4.1</td></tr>\n",
       "        <tr><td><strong>Device:</strong></td><td>cuda (Backend: cuda)</td></tr>\n",
       "        <tr><td><strong>CUDA/ROCm version:</strong></td><td>12.1</td></tr>\n",
       "        <tr><td><strong>GPU count:</strong></td><td>1</td></tr>\n",
       "        <tr><td><strong>GPU name:</strong></td><td>NVIDIA GeForce RTX 4090</td></tr>\n",
       "        <tr><td><strong>Hugging Face Transformers version:</strong></td><td>4.45.2</td></tr>\n",
       "        <tr><td><strong>BitsAndBytes version:</strong></td><td>0.42.0</td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_available_device() -> Tuple[torch.device, str]:\n",
    "    \"\"\"Helper method to find best possible hardware to run\n",
    "    Returns:\n",
    "        torch.device used to run experiments.\n",
    "        str representation of backend.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\"), \"cuda\"\n",
    "\n",
    "    # Check if ROCm is available\n",
    "    if torch.version.hip is not None and torch.backends.mps.is_available():\n",
    "        return torch.device(\"rocm\"), \"rocm\"\n",
    "\n",
    "    # Check if MPS (Apple Silicon) is available\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('cpu'), \"mps\"\n",
    "\n",
    "    # Fall back to CPU\n",
    "    return torch.device(\"cpu\"), \"cpu\"\n",
    "\n",
    "\n",
    "def display_dataset_description(name: str, dataset: datasets.DatasetDict) -> None:\n",
    "    \"\"\"Helper method to display information about splits in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        name (str): Dataset name that was loaded. \n",
    "        dataset (datasets.DatasetDict): Dataset dict with different splits that were loaded \n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    split_info = []\n",
    "    for k, ds in dataset.items():\n",
    "        split_info.append(f\"<tr><td><strong>{k.capitalize()} Samples:</strong></td><td>{len(ds)}</td></tr>\")\n",
    "    html_content = f\"\"\"\n",
    "    <h2>Dataset info</h2>\n",
    "    <table>\n",
    "        <tr><td><strong>Dataset Name:</strong></td><td>{name}</td></tr>\n",
    "        {\"<br>\".join(split_info)}\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the output in the notebook\n",
    "    display(HTML(html_content))\n",
    "\n",
    "def get_installed_version(package_name) -> str:\n",
    "    with warnings.catch_warnings():\n",
    "        # Supress warnings from packages that have missing attributes that metadata will complain about.\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        distribution = metadata.Distribution()\n",
    "        try:\n",
    "            return distribution.from_name(package_name).version\n",
    "        except metadata.PackageNotFoundError:\n",
    "            return \"Not installed\"\n",
    "\n",
    "\n",
    "def display_configuration() -> None:\n",
    "    # Check device info\n",
    "    device, backend = get_available_device()\n",
    "\n",
    "    # Torch version\n",
    "    torch_version = torch.__version__\n",
    "\n",
    "    # HuggingFace Transformers version\n",
    "    transformers_ver = transformers.__version__\n",
    "\n",
    "    # BitsAndBytes version (if available)\n",
    "    bitsandbytes_version = get_installed_version(\"bitsandbytes\")\n",
    "\n",
    "    # Check for GPU-specific details if CUDA or ROCm is available\n",
    "    if device.type == \"cuda\":\n",
    "        cuda_device_count = torch.cuda.device_count()\n",
    "        cuda_device_name = torch.cuda.get_device_name(0)\n",
    "        cuda_version = torch.version.cuda\n",
    "    elif device.type == \"rocm\":\n",
    "        cuda_device_count = torch.cuda.device_count()\n",
    "        cuda_device_name = torch.cuda.get_device_name(0)\n",
    "        cuda_version = torch.version.hip\n",
    "    else:\n",
    "        cuda_device_count = 0\n",
    "        cuda_device_name = \"N/A\"\n",
    "        cuda_version = \"N/A\"\n",
    "\n",
    "    # Prepare HTML formatted output for better display in a notebook\n",
    "    html_content = f\"\"\"\n",
    "    <h2>System Configuration</h2>\n",
    "    <table>\n",
    "        <tr><td><strong>PyTorch version:</strong></td><td>{torch_version}</td></tr>\n",
    "        <tr><td><strong>Device:</strong></td><td>{device} (Backend: {backend})</td></tr>\n",
    "        <tr><td><strong>CUDA/ROCm version:</strong></td><td>{cuda_version}</td></tr>\n",
    "        <tr><td><strong>GPU count:</strong></td><td>{cuda_device_count}</td></tr>\n",
    "        <tr><td><strong>GPU name:</strong></td><td>{cuda_device_name}</td></tr>\n",
    "        <tr><td><strong>Hugging Face Transformers version:</strong></td><td>{transformers_ver}</td></tr>\n",
    "        <tr><td><strong>BitsAndBytes version:</strong></td><td>{bitsandbytes_version}</td></tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the output in the notebook\n",
    "    display(HTML(html_content))\n",
    "\n",
    "\n",
    "# Call the display_configuration() function in your Jupyter notebook to show the configuration\n",
    "display_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87474e446657d1",
   "metadata": {
    "tags": [
     "hide-student-submission"
    ]
   },
   "source": [
    "## 0. Preparation\n",
    "\n",
    "In order to prepare, we will load the model and dataset that we will be using, namely the `standfordnlp/imbd` sentiment dataset, and the `google/flan-T5-small` model.\n",
    "\n",
    "You likely only need to run these setup cells once before running your code, but you might want to use the functions we provide here for certain DoE variables concerning:\n",
    "\n",
    "* Precision (`torch.float16`, `torch.float32`, `torch.bfloat16`)\n",
    "* Quantization (E.g., `bits_and_bytes_config != None`)\n",
    "* Device (E.g., `cpu` and `cuda`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc2af99aeff350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:59:00.911995Z",
     "start_time": "2024-10-17T18:59:00.903703Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def get_model(\n",
    "        model_name: Union[str, PathLike],\n",
    "        model_type: Type[transformers.GenerationMixin] = T5ForConditionalGeneration,\n",
    "        torch_dtype: torch.dtype = torch.float16,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        bits_and_bytes_config: Optional[transformers.BitsAndBytesConfig] = None\n",
    ") -> Tuple[transformers.PreTrainedModel, transformers.PreTrainedTokenizer, Union[transformers.PreTrainedTokenizerFast, transformers.PreTrainedTokenizer]]:\n",
    "    \"\"\"Example method to instantiate a model and get a model with optional quantization (using bitsandbytes).\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Model name (huggingface name), or relative/absolute path to a pretrained model.\n",
    "        model_type (Type[transformers.PreTrainedModel]): Type of pretrained model, used to instantiate the model you wan to load.\n",
    "        torch_dtype (torch.dtype, torch.float16): Precision to load the model with. See also the BitsAndBytes documentation.\n",
    "        device (torch.device, 'cpu'): Device to run the model on.\n",
    "        bits_and_bytes_config (BitsAndBytesConfig, optional): Configuration for bitsandbytes model quantization / mixed-precisions (consider this one of your factors)\n",
    "            N.B. for fine-tuning, make sure the optimizer you want to use is available for the defined precision.\n",
    "        \n",
    "    Returns:\n",
    "        transformers.PreTrainedModel: Model instance with provided configuraiton.\n",
    "        transformers.PreTrainedTokenizer: Tokenizer instance with provided configuration.\n",
    "        transformers.PreTrainedTokenizerFast: Fast tokenizer if avilable, othersiwe a normal python based optimizer\n",
    "    \n",
    "    Notes:\n",
    "        For using the BitsAndBytes quantization configuration, an Nvidia GPU is required. For this you might want to make \n",
    "        use of the Google Collab L4 / K40 GPUs (free-tier).    \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    model: transformers.PreTrainedModel = model_type.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        quantization_config=bits_and_bytes_config,\n",
    "        device_map=device,\n",
    "        torch_dtype=torch_dtype,\n",
    "    )\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "    )\n",
    "    fast_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        use_fast=True\n",
    "    )\n",
    "     \n",
    "    return model, tokenizer, fast_tokenizer\n",
    "\n",
    "def get_dataset(\n",
    "        data_name: str,\n",
    "        splits: List[str]\n",
    ") -> Tuple[datasets.Dataset, ...]:\n",
    "    \"\"\"Helper method to load huggingface dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_name (str): Dataset name to load from huggingface. \n",
    "        splits (List[str]): List of splits to load and return. \n",
    "\n",
    "    Returns:\n",
    "        Tuple containing the dataset splits.\n",
    "    \"\"\"\n",
    "    # Load dataset, and assign splits to variables\n",
    "    dataset: datasets.DatasetDict = datasets.load_dataset(data_name)\n",
    "    return tuple(dataset[split] for split in splits)\n",
    "\n",
    "def simple_truncate_text(row, max_length=50, tokenizer: transformers.PreTrainedTokenizerFast = None):\n",
    "    \"\"\"Example of a simple truncation method text, based on token count.\n",
    "    \n",
    "    You might want to perform 'smarter' truncation / summarization as a level, instead of simply cutting of after `max_length` tokens.\n",
    "    \n",
    "    Examples:\n",
    "        You might want to partially-apply the function, to provide a different tokenizer:\n",
    "        ```python3\n",
    "        from functools import partial\n",
    "        some_other_tokenizer = transformers.AutoTokenizer.from_pretrained('your_fave_tokenizer')\n",
    "        partial_simple_truncate = partial(simple_truncate_text, tokenizer=some_other_tokenizer)\n",
    "        ```\n",
    "    Args:\n",
    "        row (datasets....): Single instance or row of dataset.\n",
    "    \n",
    "    Keyword Args:\n",
    "        max_length (int, 150): the maximum length of text to be processed. Defaults to 150.\n",
    "        tokenizer (transformers.PreTrainedTokenizer, `fast_tokenizer`): the tokenizer to use. Defaults to `fast_tokenizer`.\n",
    "    \n",
    "    Notes:\n",
    "        This function requires all cells above to be run.\n",
    "    \"\"\"\n",
    "    token_representation = tokenizer.batch_encode_plus(row['text'], max_length=max_length, truncation=True)['input_ids']\n",
    "    text_representation = tokenizer.batch_decode(token_representation, skip_special_tokens=True)\n",
    "    row['text'] = text_representation\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259cdbad45c06320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:41.586814Z",
     "start_time": "2024-10-17T18:57:40.060042Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tokenizer for flan family\n",
    "family: str = \"google/flan-t5\"\n",
    "# For the Lab we will use a small model, just to provide some insight into usability.\n",
    "model: str = f\"small\"\n",
    "model_name: str = f\"{family}-{model}\"\n",
    "\n",
    "tokenizer: T5Tokenizer\n",
    "fast_tokenizer: T5TokenizerFast\n",
    "model: T5ForConditionalGeneration\n",
    "\n",
    "# NOTE, you might need to change this for different model Families\n",
    "#   as T5 family specifically is a encoder-decoder whereas most text gen. models are\n",
    "#   of type AutoModelForCausalLM.\n",
    "model_type: Type[transformers.GenerationMixin] = transformers.AutoModelForSeq2SeqLM\n",
    "# model_type: Type[transformers.GenerationMixin] = transformers.AutoModelForCausalLM\n",
    "device, backend = get_available_device()\n",
    "model, tokenizer, fast_tokenizer = get_model(\n",
    "    model_name=model_name,\n",
    "    model_type=model_type,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=device,\n",
    ")\n",
    "# Set the model to Evaluation to prevent creating a computational graph\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99fc8a578e46a5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.796132Z",
     "start_time": "2024-10-17T18:57:41.603123Z"
    },
    "tags": [
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Text  | Label   |\n",
       "|:-----:|:-------:|\n",
       "|i completely agree with jamrom4.. this w... | 0 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_name: str = 'stanfordnlp/imdb'\n",
    "splits = ['train', 'test', 'unsupervised']\n",
    "train_set, test_set, *_ = get_dataset(data_name, splits=splits)\n",
    "text, label = f\"{train_set[1239]['text'][:40]}...\", train_set[0]['label']\n",
    "display(\n",
    "    Markdown(\n",
    "f\"\"\"\n",
    "| Text  | Label   |\n",
    "|:-----:|:-------:|\n",
    "|{text} | {label} |\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292f54f98fcec96",
   "metadata": {},
   "source": [
    "## (Optional) Becoming a Jinja Ninja!\n",
    "\n",
    "As a starting point for data-manipulation, here are some exercises to get used with Jinja! We recommend looking into Jinja templating, with variables and for loops.\n",
    "As you will see, Jinja is a very flexible templating engine, that allows you to wrangle the IMDb dataset that we will use into the correct format for your experiments.\n",
    "\n",
    "In the following exercises you can see how you can:\n",
    "\n",
    "1. Render parameters in a Jinja Template\n",
    "2. Render lists in a Jinja Template\n",
    "3. Render `zip`ped list in a Jinja Template\n",
    "\n",
    "> N.B. use the test methods to see what is expected / the expected return statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1838a551c4edde2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.862812Z",
     "start_time": "2024-10-17T18:57:44.857041Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is: Your name :)\n",
      "I follow MSGAIS taught by Lydia, and can contact Jeroen for questions.\n"
     ]
    }
   ],
   "source": [
    "example_template = jinja2.Template(\n",
    "    textwrap.dedent(\n",
    "        \"\"\"\\\n",
    "        Hello my name is: {{ MY_NAME }}\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "print(example_template.render(MY_NAME=\"Your name :)\"))\n",
    "\n",
    "# Implement a template that uses variables `course` `professor` and `ta`\n",
    "# Would render `I follow MSGAIs 2024/2025 taught by Prof. L. Y. Chen, and can contact Ir. J. M. Galjaard for questions.`\n",
    "VAR_TEMPLATE = textwrap.dedent(\n",
    "    # YOUR CODE GOES HERE\n",
    "    \"\"\"\\\n",
    "    I follow {{ course }} taught by {{ professor }}, and can contact {{ ta }} for questions.\n",
    "    \"\"\"\n",
    "    # END OF YOUR CODE\n",
    ")\n",
    "variables_template = jinja2.Template(\n",
    "    VAR_TEMPLATE   \n",
    ")\n",
    "variables = jinja2schema.infer(VAR_TEMPLATE)\n",
    "assert set(variables.keys()) == {'course', 'professor', 'ta'}, 'Not all variables are used'\n",
    "\n",
    "# As example\n",
    "print(variables_template.render(course ='MSGAIS', professor='Lydia', ta='Jeroen'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb1eca7a2b70333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.909692Z",
     "start_time": "2024-10-17T18:57:44.905181Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to implement:\n",
      "* Basic prompting\n",
      "* Few-shot Learning\n",
      "* Fine-Tuning\n",
      "* Bonus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Implement a template that uses a variable `exercises` that contains a list of strings.\n",
    "#  it should render as a Markdown list\n",
    "# HINT: use a jinja for-loop\n",
    "list_expected = \"\"\"I need to implement:\n",
    " * Basic prompting\n",
    " * Few-shot Learning\n",
    " * Fine-Tuning\n",
    " * Bonus\"\"\"\n",
    "LIST_TEMPLATE = textwrap.dedent(\n",
    "    \"\"\"\\\n",
    "    I need to implement:{% for exercise in exercises %}\n",
    "    * {{ exercise }}{% endfor %}\n",
    "    \"\"\"\n",
    ")\n",
    "list_template = jinja2.Template(\n",
    "    LIST_TEMPLATE\n",
    ")\n",
    "variables = jinja2schema.infer(LIST_TEMPLATE)\n",
    "assert 'exercises' in set(variables.keys()), 'Exercise variables is not used!'\n",
    "print(list_template.render(exercises=['Basic prompting', 'Few-shot Learning', 'Fine-Tuning', 'Bonus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bef041258f923cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:44.957926Z",
     "start_time": "2024-10-17T18:57:44.954115Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to implement:\n",
      "* (20) Basic prompting\n",
      "* (20) Few-shot Learning\n",
      "* (20) Fine-Tuning\n",
      "* (10) Bonus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Implement a template that uses a variable `points_exercises` that contains a list of tuples.\n",
    "# HINT: use a jinja for-loop and variable unrolling\n",
    "zip_expected = \"\"\"I need to implement:\n",
    "* (20) Basic prompting\n",
    "* (20) Few-shot Learning\n",
    "* (20) Fine-Tuning\n",
    "* (10) Bonus\"\"\"\n",
    "\n",
    "ZIP_TEMPLATE = textwrap.dedent(\n",
    "    # YOUR CODE GOES HERE\n",
    "    \"\"\"\\\n",
    "    I need to implement:{% for points, exercise in points_exercises %}\n",
    "    * ({{ points }}) {{ exercise }}{% endfor %}\n",
    "    \"\"\"\n",
    "    # END OF YOUR CODE\n",
    ")\n",
    "zip_template = jinja2.Template(\n",
    "    ZIP_TEMPLATE\n",
    ")\n",
    "variables = jinja2schema.infer(ZIP_TEMPLATE)\n",
    "assert set(variables.keys()) == {'points_exercises'}, 'Exercise variables is not used!'\n",
    "print(zip_template.render(points_exercises=[(20, 'Basic prompting'), ( 20, 'Few-shot Learning'), (20, 'Fine-Tuning'), (10, 'Bonus')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83315bec1160669c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:45.016502Z",
     "start_time": "2024-10-17T18:57:45.010507Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exercise 0.1 Optional exercise result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do not edit the following code.\n",
    "class TestJinjaNinja(unittest.TestCase):\n",
    "    exercises = ['Basic prompting', 'Few-shot Learning', 'Fine-Tuning', 'Bonus']\n",
    "    points = [20, 20, 20, 10]\n",
    "    def test_1_variable(self):\n",
    "        \n",
    "        check_against = \"I follow MSGAIs 2024/2025 taught by Prof. L. Y. Chen, and can contact Ir. J. M. Galjaard for questions.\"\n",
    "        course = 'MSGAIs 2024/2025'\n",
    "        professor = 'Prof. L. Y. Chen'\n",
    "        ta = 'Ir. J. M. Galjaard'\n",
    "        result = variables_template.render(course=course, professor=professor, ta=ta)\n",
    "        self.assertEqual(result, check_against)\n",
    "    \n",
    "    def test_2_list_template(self):\n",
    "        check_against = textwrap.dedent(\"\"\"\\\n",
    "        I need to implement:\n",
    "        * Basic prompting\n",
    "        * Few-shot Learning\n",
    "        * Fine-Tuning\n",
    "        * Bonus\"\"\")\n",
    "        result = list_template.render(exercises=self.exercises)\n",
    "        self.assertEqual(result, check_against)\n",
    "        \n",
    "    \n",
    "    def test_3_list_zipped(self):\n",
    "        check_against = textwrap.dedent(\"\"\"\\\n",
    "        I need to implement:\n",
    "        * (20) Basic prompting\n",
    "        * (20) Few-shot Learning\n",
    "        * (20) Fine-Tuning\n",
    "        * (10) Bonus\"\"\")\n",
    "        \n",
    "        result = zip_template.render(points_exercises=list(zip(self.points, self.exercises)))\n",
    "        self.assertEqual(result, check_against)\n",
    "        \n",
    "f = io.StringIO()\n",
    "with contextlib.redirect_stderr(f):\n",
    "    display(Markdown(\"### Exercise 0.1 Optional exercise result\"))\n",
    "    TextTestRunner(verbosity=-1).run(defaultTestLoader.loadTestsFromTestCase(TestJinjaNinja))\n",
    "    display(Markdown('---'))\n",
    "    print(f\"\\033[91m{f.getvalue()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1bf56e5e2bf4a",
   "metadata": {},
   "source": [
    "# Exercise 1: Prompt-based Evaluation (20 points total) \n",
    "Instead of fine-tuning a model specific to a problem, we can use the language model's capability to follow instructions to perform a specific task. In all these tasks, we will make use of the IMDB movie review sentiment dataset. Throughout this, and following exercises, we will be 'asking' the model to predict the sentiment (Positive or Negative). \n",
    "\n",
    "A naive idea, is ask the model simply: ``Has the following a Positive or Negative sentiment?''.\n",
    " \n",
    "In this exercise, you will;\n",
    "\n",
    "1. **Exercise 1.1**     (5 points) implement two 'Zero-Shot' prompts 'templates', that prompt the model to decide upon the semtiment without additional information\n",
    "2. **Exercise 1.2:**    (8 points) Perform DoE with different system- and/or hyper-parameters during generation, to evaluate how they impact the models performance (accuracy).\n",
    "3. **Exercise 1.3:**    (7 points) Analyse the result of your DoE experiments, usign ANOVA.\n",
    "\n",
    "\n",
    "The goal here is to evaluate the impact of different hyper-parameters and/or system-parameters on the classification accuracy of the model.\n",
    "\n",
    "> ❗One of the levels in your DoE, will be the input representation, i.e., a `simple_prompt` and a more contextual `detailed_prompt`. You will implement these Zero-Shot prompts. The simple prompt should be a mere short question, whereas the detailed prompt should give additional context, e.g., about the domain / task that is performed.\n",
    "\n",
    "\n",
    "> *N.B.* to guide you through the exericse, we annotate things you will need to implement. In the lab we will provide some example on how to tackle this.\n",
    "\n",
    " ```python\n",
    " # YOUR CODE GOES HERE!\n",
    "\n",
    " # END OF YOUR CODE!\n",
    " ```\n",
    "\n",
    "**⚠ FAIR Warning:**\n",
    "\n",
    "> YOU should make sure to store results to disk or other persisten storage, i.e. by writing to a file or saving a model. For example when you want to run with different models you should make sure that data is not accidentally overwritten!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37feec8b86609a95",
   "metadata": {},
   "source": [
    "## Exercise: 1.1 Prompt-Design (5 points)\n",
    "\n",
    "First, we ensure that we can represent the data to the model with our designed prompt, for this, you will need to implement the following behavior;\n",
    "\n",
    "1. A simple (yes/no)-like question for the prompt in `get_simple_prompt_template`. (2 points (left / right)).\n",
    "    * This should ask for a `positive`/`Positive` or `negative`/`Negative` as answer, i.e., asking to classify the sentiment of text.\n",
    "2. A detailed (contextual) question for the prompt in `get_detailed_prompt_template`. (3 points (left / right)).\n",
    "    * This should ask for a `positive`/`Positive` or `negative`/`Negative` as answer, i.e., asking to classify the sentiment of text.\n",
    "    * The question should provide additional context regarding the task that is performed (e.g., sentiment analysis, type of task that is peformed, etc.).\n",
    "\n",
    "\n",
    "**N.B**, we don't recommend using a library like `langchain` to do the homework, as they can become restrictive in the specifics that you want to use. You can opt to use it, but the course does not provide support on additional optional frameworks.\n",
    "\n",
    "**N.B.** we do recommend using Jinja to create templates for prompts. This allows to quickly transform input for your experiments for your execution of DoE.\n",
    "\n",
    "Additionally, make sure to use the appropriate `textwrap.dedent` option, if you use triple-quoted (multi-line) `str`ings! Otherwise, you will add (unintenional) whitespace `char`s!\n",
    "\n",
    "> If you are unsure how to do this, see the Preparation exercise above, as they provide some hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9236f5b0f187306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:45.055920Z",
     "start_time": "2024-10-17T18:57:45.050361Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Is the sentiment of this review positive or negative? Review: Review would go here..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_simple_prompt_template(\n",
    "        side: str = 'left',\n",
    ") -> jinja2.Template:\n",
    "    \"\"\"Implements a simple Template retrieval function, that takes as argument `review` and renders as a simple prompt.\n",
    "    Keyword Args:\n",
    "        side (str, 'left'): Position at which to add the question for the prompt.\n",
    "        \n",
    "    Returns:\n",
    "        jinja.Template that can render an argument `review`, consisting of a string represention of a review.\n",
    "    \"\"\"\n",
    "    # TODO: Implement a simple zero-shot style yes/no style QA Template.    \n",
    "    match side:\n",
    "        case 'left':\n",
    "            # TODO: Implement question first, then `review`\n",
    "\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                \"\"\"\\\n",
    "                Is the sentiment of this review positive or negative? Review: {{ review }}\n",
    "                \"\"\"\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "        case 'right':\n",
    "            # TODO: Implement `review` first, then question\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                \"\"\"\\\n",
    "                {{ review }} Is the sentiment of this review positive or negative?\n",
    "                \"\"\"\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "    assert set(jinja2schema.infer(PROMPT_TEMPLATE).keys()) == {'review'}, \"Your template does not use the `review` argument.\"\n",
    "    return jinja2.Template(PROMPT_TEMPLATE)\n",
    "\n",
    "simple_template_l = get_simple_prompt_template(side='left')\n",
    "\n",
    "simple_template_r = get_simple_prompt_template(side='right')\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        simple_template_l.render(review='Review would go here...').replace('\\n', '<br>')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb9711e7b2bed19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:57:51.676793Z",
     "start_time": "2024-10-17T18:57:51.670852Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exericse 1.1.1 Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse; width: 100%;\">\n",
       "    <tr>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (left)</th>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (right)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">Is the sentiment of this review positive or negative? Review: Review would go here...</td>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">Review would go here... Is the sentiment of this review positive or negative?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">Is the sentiment of this review positive or negative? Review: Wow. Rarely have I felt the need to comment on movies lately, but this one especially is begging for a beatdown. Let's start at the beginning....</td>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">Wow. Rarely have I felt the need to comment on movies lately, but this one especially is begging for a beatdown. Let's start at the beginning.... Is the sentiment of this review positive or negative?</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN EVALUATION\n",
    "# Don't change the code below.\n",
    "\n",
    "def nl_to_br(inp, br: str='<br>'):\n",
    "    return inp.replace('\\n', br)\n",
    "\n",
    "example_review = f\"{train_set[1203]['text'][:142]}...\"\n",
    "simple_prompt_l = nl_to_br(simple_template_l.render(review='Review would go here...'))\n",
    "simple_example_l = nl_to_br(simple_template_l.render(review=example_review))\n",
    "\n",
    "simple_prompt_r = nl_to_br(simple_template_r.render(review='Review would go here...'))\n",
    "simple_example_r = nl_to_br(simple_template_r.render(review=example_review))\n",
    "\n",
    "display(\n",
    "    Markdown('### Exericse 1.1.1 Result'),\n",
    "    HTML(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (left)</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (right)</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_prompt_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_prompt_r}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_example_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{simple_example_r}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c4be7333feb5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:58:25.333078Z",
     "start_time": "2024-10-17T18:58:25.325696Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exericse 1.1.2 Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| **My simple prompt (left)** | **My simple prompt (right)** |\n",
       "|-----------------------------|------------------------------|\n",
       "| Is the sentiment of this review positive or negative? Review: Review would go here...           | Review would go here... Is the sentiment of this review positive or negative?            |\n",
       "| **Example**                 | **Example**                  |\n",
       "| Is the sentiment of this review positive or negative? Review: Wow. Rarely have I felt the need to comment on movies lately, but this one especially is begging for a beatdown. Let's start at the beginning....          | Wow. Rarely have I felt the need to comment on movies lately, but this one especially is begging for a beatdown. Let's start at the beginning.... Is the sentiment of this review positive or negative?           |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def get_detailed_prompt_template(\n",
    "        side='left',\n",
    ") -> jinja2.Template:\n",
    "    \"\"\"Implements a detailed contextual Template retrieval function, that takes as argument `review` and renders a detailed prompt\n",
    "    with contextual information.\n",
    "    \n",
    "    Keyword Args:\n",
    "        side (str, 'left'): Position at which to add the question for the prompt.\n",
    "        \n",
    "    Returns:\n",
    "        Template that can render an argument `review`, consisting of a string representation of a review.\n",
    "    \"\"\"\n",
    "    match side:\n",
    "        case 'left':\n",
    "            # TODO: Implement Question-first, Context second template.\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                \"\"\"\\\n",
    "                Is the sentiment of the following movie review positive or negative? This is a sentiment analysis task. Review: {{ review }}\n",
    "                \"\"\"\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "        case 'right':\n",
    "            # TODO: Implement Context-first, Question-second template.\n",
    "            PROMPT_TEMPLATE = textwrap.dedent(\n",
    "                # YOUR CODE GOES HERE\n",
    "                \"\"\"\\\n",
    "                This is a sentiment analysis task. Review: {{ review }} Is the sentiment of this review positive or negative?\n",
    "                \"\"\"\n",
    "                # END OF YOUR CODE\n",
    "            )\n",
    "    assert set(jinja2schema.infer(PROMPT_TEMPLATE).keys()) == {'review'}, \"Your template does not use the `review` argument.\"\n",
    "    return jinja2.Template(PROMPT_TEMPLATE)\n",
    "\n",
    "detailed_template_l = get_detailed_prompt_template(\n",
    "    side='left',\n",
    ")\n",
    "detailed_template_r = get_detailed_prompt_template(\n",
    "    side='right',\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown('### Exericse 1.1.2 Result'),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "        f\"\"\"\\\n",
    "        | **My simple prompt (left)** | **My simple prompt (right)** |\n",
    "        |-----------------------------|------------------------------|\n",
    "        | {simple_prompt_l}           | {simple_prompt_r}            |\n",
    "        | **Example**                 | **Example**                  |\n",
    "        | {simple_example_l}          | {simple_example_r}           |\n",
    "        \"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46592fc82afbeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T18:58:26.141192Z",
     "start_time": "2024-10-17T18:58:26.135592Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exericse 1.1.2 Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse; width: 100%;\">\n",
       "    <tr>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (left)</th>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (right)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">Is the sentiment of the following movie review positive or negative? This is a sentiment analysis task. Review: Review would go here...</td>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">This is a sentiment analysis task. Review: Review would go here... Is the sentiment of this review positive or negative?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">Is the sentiment of the following movie review positive or negative? This is a sentiment analysis task. Review: Wow. Rarely have I felt the need to comment on movies lately, but this one especially is begging for a beatdown. Let's start at the beginning....</td>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\">This is a sentiment analysis task. Review: Wow. Rarely have I felt the need to comment on movies lately, but this one especially is begging for a beatdown. Let's start at the beginning.... Is the sentiment of this review positive or negative?</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN EVALUATION\n",
    "# Don't change the code below.\n",
    "example_review = f\"{train_set[1203]['text'][:142]}...\"\n",
    "\n",
    "detailed_prompt_l = nl_to_br(detailed_template_l.render(review='Review would go here...'))\n",
    "detailed_example_l = nl_to_br(detailed_template_l.render(review=example_review))\n",
    "\n",
    "detailed_prompt_r = nl_to_br(detailed_template_r.render(review='Review would go here...'))\n",
    "detailed_example_r = nl_to_br(detailed_template_r.render(review=example_review))\n",
    "\n",
    "display(\n",
    "    Markdown('### Exericse 1.1.2 Result'),\n",
    "    HTML(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (left)</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My simple prompt (right)</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_prompt_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_prompt_r}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Example</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_example_l}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{detailed_example_r}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e988b661f54c8242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:00:01.029080Z",
     "start_time": "2024-10-17T19:00:00.990553Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Example of truncated data\n",
       "Do you see how the text is abruptly terminated after `I tried to like this, I`?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> | **Truncated Review**        | **Label** |\n",
       "|-------------------------------|-----------|\n",
       "| I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I      | 0   |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the truncated eval set.\n",
    "MAX_50_TOKENS = 50\n",
    "truncate_to_50_tokens = partial(simple_truncate_text,  max_length=MAX_50_TOKENS, tokenizer=fast_tokenizer)\n",
    "\n",
    "q1_eval_set = (\n",
    "    test_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    ")\n",
    "\n",
    "truncated_example_text, label = nl_to_br(q1_eval_set[0]['text']), q1_eval_set[0]['label']\n",
    "display(\n",
    "    Markdown(\n",
    "    \"\"\"## Example of truncated data\n",
    "Do you see how the text is abruptly terminated after `I tried to like this, I`?\n",
    "\"\"\"),\n",
    "    Markdown(textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            > | **Truncated Review**        | **Label** |\n",
    "            |-------------------------------|-----------|\n",
    "            | {truncated_example_text}      | {label}   |\n",
    "            \"\"\"\n",
    "        )\n",
    "    ),\n",
    "    Markdown('---')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75acf1a1d06bc43",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Design of Experiments (8 points)\n",
    "\n",
    "In this and the following exercise, we are interested in quantifing the effect of different configurations on the zero-shot performance of the model, you will need to select at-least 3 system- and/or hyper-parameters, with each having atleast two or more (2+) levels. Recall that for the first hyper-parameter should use the (`simple` or `detailed`) prompt.\n",
    "\n",
    "Furthermore, we suggest using one or more from the following parameters in your DoE:\n",
    "\n",
    "  * The structure of each prompt (i.e., `left` and `right`)\n",
    "  * Model size, for example (`T5-flan-small`, `T5-flan-base`, `T5-flan-large`, etc.). (only recommended with GPU)\n",
    "  * Numerical precision (`torch.float16`, `torch.float32`, `torch.bfloat16`). Make sure your hardware / `PyTorch` version supports this!\n",
    "  * Quantization (only recommended with GPU with `BitsAndBytes` packages).\n",
    "  * Structured decoding (requires implememtantation).\n",
    "\n",
    "\n",
    "In short, you will need to perform;\n",
    "\n",
    "1. (8 points) Design of Experiments in code;\n",
    "    * Selection of criteria\n",
    "    * Type of factorial experiment\n",
    "    * Creation of experimental configuration\n",
    "    * Run your experiments.\n",
    "        * Depending on your chosen variables in DoE, you might need to make some minor adaptations to our provided code.\n",
    "\n",
    "> For your convenience, we have split first DoE part,  and the Design of Experiments (which you have to implement), and the ANOVA analysis into 2 cells. We strongly recommend writing data to disk/persistent storage and loading it in the next cell to make sure you can easily re-run evaluation upon restarting the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f3d4b57e32365da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:04:56.099561Z",
     "start_time": "2024-10-17T19:04:56.091263Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def run_q1_evaluation(\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        model: transformers.PreTrainedModel,\n",
    "        generation_config: transformers.GenerationConfig,\n",
    "        *args,\n",
    "        **kwargs\n",
    ") -> Tuple[List[List[str]], List[List[int]]]:\n",
    "    \"\"\"Helper function to run evaluation (e.g. under different evaluations).\n",
    "    \n",
    "    Notes:\n",
    "        You likely don't need to make any changes, as likely most of your levels are;\n",
    "         * system-parameters,\n",
    "         * generation-parameters,\n",
    "         * different ways of pre-processing the review data.\n",
    "    \n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): Dataloader containing the evaluation set. \n",
    "        model (transformers.PreTrainedModel): Pre-Trained model to be evaluated.\n",
    "        generation_config: Generation configuraiton, that may contain some of your hyper-parameters for DoE.\n",
    "        *args: Any additional positional args you want to add.\n",
    "    \n",
    "    Keyword Args:\n",
    "        **kwargs: Any additional keyword args you want to add.\n",
    "\n",
    "    Returns:\n",
    "        List of list containing the `str`ing representation of the models predicition.\n",
    "        List of list containing the `int`eger representation of the ground-truth label.\n",
    "    \"\"\"\n",
    "    prediction_list, label_list = [], []\n",
    "    for idx, batch in (pbar := tqdm(enumerate(dataloader), leave=False, total=len(dataloader))):\n",
    "        pbar.set_description(f'Batch {idx}')\n",
    "        input_ids, attention_mask, label = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch[\n",
    "            'label'].to(device)\n",
    "        # YOUR CODE GOES HERE\n",
    "        ...\n",
    "        # END OF YOUR CODE\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            generation_config=generation_config,\n",
    "            max_new_tokens=5,\n",
    "        )\n",
    "        prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        prediction_list.append(prediction)\n",
    "        label_list.append(label.cpu().tolist())\n",
    "    return prediction_list, label_list\n",
    "\n",
    "\n",
    "def get_q1_sets(\n",
    "        dataset: datasets.Dataset,\n",
    "        side: str = 'left'\n",
    ") -> Tuple[datasets.Dataset, datasets.Dataset]:\n",
    "    \"\"\"Helper method to create the low and high level datasets with the `simple` and `detailed` prompt.\n",
    "    \n",
    "    Notes:\n",
    "        You likely don't need to edit this code, but feel free to extend this code, in case you want to\n",
    "        evaluate more different levels\n",
    "    \n",
    "    Args:\n",
    "        dataset (datasets.Dataset): Dataset to be mapped to a simple and detailed representation dataset.\n",
    "        side (str): The side on which the prompt should appear (e.g., 'left' or 'right').\n",
    "        \n",
    "    Returns:\n",
    "        Dataset with text mapped using the `simple_template`.\n",
    "        Dataset with text mapped using the `detailed_template`.\n",
    "    \"\"\"\n",
    "    \n",
    "    simple_template = get_simple_prompt_template(side=side)\n",
    "    detailed_template = get_detailed_prompt_template(side=side)\n",
    "\n",
    "    # 1. Prepare the simple set (low level)\n",
    "    simple_set = (\n",
    "        dataset\n",
    "        .map(\n",
    "            lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "                [simple_template.render(review=row) for row in batch['text']],\n",
    "                truncation=False,\n",
    "                padding=True,\n",
    "            ),\n",
    "            batched=True,\n",
    "        )\n",
    "    )\n",
    "    # Map to input expected by the model.\n",
    "    simple_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    # 2. Prepare the detailed set (high level)\n",
    "    detailed_set = (\n",
    "        dataset\n",
    "        .map(\n",
    "            lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "                [detailed_template.render(review=row) for row in batch['text']],\n",
    "                truncation=False,\n",
    "                padding=True,\n",
    "            ),\n",
    "            batched=True,\n",
    "        )\n",
    "    )\n",
    "    # Map to input expected by the model\n",
    "    detailed_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    \n",
    "    return simple_set, detailed_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50f3347b7e6952",
   "metadata": {},
   "source": [
    "### Exericse 1.2.1 Design of Experiments\n",
    "Define your Design of Experiment configurations in the list `EXPERIMENT_CONFIGURATIONS`, you can use this list to store experiment configurations for the different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff0a9dbd3bf7960",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiment configurations: 36\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement your experimental design here! Decide on hyper-parameters, levels,\n",
    "#  and type of factorial experiment you want to do.\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS: List[Dict[Any, Any]] = [\n",
    "    None\n",
    "]\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "prompt_types = [\"simple\", \"detailed\"]\n",
    "structures = [\"left\", \"right\"]\n",
    "precisions = [torch.float16, torch.float32, torch.bfloat16]\n",
    "model_sizes = [\"flan-t5-small\", \"flan-t5-base\", \"flan-t5-large\"]\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS: List[Dict[str, Any]] = [\n",
    "    {\n",
    "        \"prompt_type\": prompt_type,\n",
    "        \"structure\": structure,\n",
    "        \"precision\": precision,\n",
    "        \"model_size\": model_size,\n",
    "    }\n",
    "    for prompt_type, structure, precision, model_size in product(prompt_types, structures, precisions, model_sizes)\n",
    "]\n",
    "\n",
    "print(f\"Total experiment configurations: {len(EXPERIMENT_CONFIGURATIONS)}\")\n",
    "for config in EXPERIMENT_CONFIGURATIONS:\n",
    "    print(config)\n",
    "\n",
    "# END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef4f0b8d3875d2",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "ALLOW_OVERWRITING_RESULTS = True\n",
    "\n",
    "for configuration in tqdm(EXPERIMENT_CONFIGURATIONS, desc=\"Experiment Configurations\"):\n",
    "    prompt_type = configuration['prompt_type']\n",
    "    structure = configuration['structure']\n",
    "    precision = configuration['precision']\n",
    "    model_size = configuration['model_size']\n",
    "\n",
    "    simple_set, detailed_set = get_q1_sets(q1_eval_set, side=structure)\n",
    "\n",
    "    if prompt_type == 'simple':\n",
    "        template = get_simple_prompt_template(side=structure)\n",
    "        dataset = simple_set\n",
    "    else:\n",
    "        template = get_detailed_prompt_template(side=structure)\n",
    "        dataset = detailed_set\n",
    "\n",
    "    model_name = f\"google/{model_size}\"\n",
    "    model, tokenizer, fast_tokenizer = get_model(\n",
    "        model_name=model_name,\n",
    "        model_type=transformers.AutoModelForSeq2SeqLM,\n",
    "        torch_dtype=precision,\n",
    "        device=device\n",
    "    )\n",
    "    model.eval()\n",
    "    \n",
    "    generation_config = GenerationConfig()\n",
    "\n",
    "    overhead = len(tokenizer(template.render(), add_special_tokens=False)['input_ids'])\n",
    "\n",
    "    for repetition in range(1, 6):\n",
    "        q_data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=512,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            prefetch_factor=10,\n",
    "        )\n",
    "\n",
    "        begin_time = time.time()\n",
    "        prediction_list, label_list = run_q1_evaluation(\n",
    "            q_data_loader,\n",
    "            model,\n",
    "            generation_config,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        prediction_list, labels_list = list(chain(*prediction_list)), list(chain(*label_list))\n",
    "\n",
    "        experiment_description = (\n",
    "            f\"Prompt Type: {prompt_type}, Structure: {structure}, \"\n",
    "            f\"Precision: {precision}, Model Size: {model_size}, \"\n",
    "            f\"Repetition: {repetition}\"\n",
    "        )\n",
    "        save_path_experiment = (\n",
    "            f\"results_zero-shot/{model_size}/\"\n",
    "            f\"{prompt_type}_{structure}_{precision}_{repetition}.json\"\n",
    "        )\n",
    "\n",
    "        label_lut = defaultdict(lambda: -1, {'positive': 1, 'negative': 0})\n",
    "        predictions = list(map(lambda x: label_lut[x.split(' ')[0].lower()], prediction_list))\n",
    "\n",
    "        accuracy = sum(map(lambda x: x[0] == x[1], zip(predictions, labels_list))) / len(predictions)\n",
    "        unknown = sum(map(lambda x: x[0] == -1, zip(predictions, labels_list))) / len(predictions)\n",
    "\n",
    "        save_path = Path(save_path_experiment)\n",
    "        if not save_path.parent.exists():\n",
    "            save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        if save_path.is_file() and not ALLOW_OVERWRITING_RESULTS:\n",
    "            print(\"Cannot overwrite existing experiment file without `ALLOW_OVERWRITING_RESULTS` flag set.\")\n",
    "            continue\n",
    "        \n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump({\n",
    "                \"description\": experiment_description,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"unknown\": unknown,\n",
    "                \"begin_time\": begin_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"configuration\": {k: str(v) if isinstance(v, torch.dtype) else v for k, v in configuration.items()}\n",
    "            }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d1596d80e9011",
   "metadata": {},
   "source": [
    "### Exercise 1.3 Report on DoE (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042f6d110648d9a",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Experiment Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>structure</th>\n",
       "      <th>precision</th>\n",
       "      <th>model_size</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>accuracy_max</th>\n",
       "      <th>accuracy_min</th>\n",
       "      <th>begin_time_avg</th>\n",
       "      <th>begin_time_max</th>\n",
       "      <th>begin_time_min</th>\n",
       "      <th>end_time_avg</th>\n",
       "      <th>end_time_max</th>\n",
       "      <th>end_time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82804</td>\n",
       "      <td>0.82804</td>\n",
       "      <td>0.82804</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82804</td>\n",
       "      <td>0.82804</td>\n",
       "      <td>0.82804</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82796</td>\n",
       "      <td>0.82796</td>\n",
       "      <td>0.82796</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82708</td>\n",
       "      <td>0.82708</td>\n",
       "      <td>0.82708</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82696</td>\n",
       "      <td>0.82696</td>\n",
       "      <td>0.82696</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82692</td>\n",
       "      <td>0.82692</td>\n",
       "      <td>0.82692</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82600</td>\n",
       "      <td>0.82600</td>\n",
       "      <td>0.82600</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82596</td>\n",
       "      <td>0.82596</td>\n",
       "      <td>0.82596</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82592</td>\n",
       "      <td>0.82592</td>\n",
       "      <td>0.82592</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82576</td>\n",
       "      <td>0.82576</td>\n",
       "      <td>0.82576</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82560</td>\n",
       "      <td>0.82560</td>\n",
       "      <td>0.82560</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.82548</td>\n",
       "      <td>0.82548</td>\n",
       "      <td>0.82548</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78884</td>\n",
       "      <td>0.78884</td>\n",
       "      <td>0.78884</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78884</td>\n",
       "      <td>0.78884</td>\n",
       "      <td>0.78884</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78864</td>\n",
       "      <td>0.78864</td>\n",
       "      <td>0.78864</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78832</td>\n",
       "      <td>0.78832</td>\n",
       "      <td>0.78832</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78828</td>\n",
       "      <td>0.78828</td>\n",
       "      <td>0.78828</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78768</td>\n",
       "      <td>0.78768</td>\n",
       "      <td>0.78768</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78404</td>\n",
       "      <td>0.78404</td>\n",
       "      <td>0.78404</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78356</td>\n",
       "      <td>0.78356</td>\n",
       "      <td>0.78356</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78296</td>\n",
       "      <td>0.78296</td>\n",
       "      <td>0.78296</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78276</td>\n",
       "      <td>0.78276</td>\n",
       "      <td>0.78276</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.78272</td>\n",
       "      <td>0.78272</td>\n",
       "      <td>0.78272</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75616</td>\n",
       "      <td>0.75616</td>\n",
       "      <td>0.75616</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "      <td>1.731425e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>0.75612</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>detailed</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75596</td>\n",
       "      <td>0.75596</td>\n",
       "      <td>0.75596</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75596</td>\n",
       "      <td>0.75596</td>\n",
       "      <td>0.75596</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75536</td>\n",
       "      <td>0.75536</td>\n",
       "      <td>0.75536</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75532</td>\n",
       "      <td>0.75532</td>\n",
       "      <td>0.75532</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75528</td>\n",
       "      <td>0.75528</td>\n",
       "      <td>0.75528</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "      <td>1.731426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75484</td>\n",
       "      <td>0.75484</td>\n",
       "      <td>0.75484</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "      <td>1.731427e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75340</td>\n",
       "      <td>0.75340</td>\n",
       "      <td>0.75340</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75340</td>\n",
       "      <td>0.75340</td>\n",
       "      <td>0.75340</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "      <td>1.731429e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>detailed</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.75332</td>\n",
       "      <td>0.75332</td>\n",
       "      <td>0.75332</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "      <td>1.731428e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_type structure       precision     model_size  accuracy_avg  \\\n",
       "29    detailed     right   torch.float16  flan-t5-large       0.82804   \n",
       "32    detailed     right   torch.float32  flan-t5-large       0.82804   \n",
       "35    detailed     right  torch.bfloat16  flan-t5-large       0.82796   \n",
       "11      simple     right   torch.float16  flan-t5-large       0.82708   \n",
       "17      simple     right  torch.bfloat16  flan-t5-large       0.82696   \n",
       "14      simple     right   torch.float32  flan-t5-large       0.82692   \n",
       "2       simple      left   torch.float16  flan-t5-large       0.82600   \n",
       "8       simple      left  torch.bfloat16  flan-t5-large       0.82596   \n",
       "5       simple      left   torch.float32  flan-t5-large       0.82592   \n",
       "23    detailed      left   torch.float32  flan-t5-large       0.82576   \n",
       "20    detailed      left   torch.float16  flan-t5-large       0.82560   \n",
       "26    detailed      left  torch.bfloat16  flan-t5-large       0.82548   \n",
       "4       simple      left   torch.float32   flan-t5-base       0.78884   \n",
       "1       simple      left   torch.float16   flan-t5-base       0.78884   \n",
       "7       simple      left  torch.bfloat16   flan-t5-base       0.78864   \n",
       "19    detailed      left   torch.float16   flan-t5-base       0.78832   \n",
       "22    detailed      left   torch.float32   flan-t5-base       0.78828   \n",
       "25    detailed      left  torch.bfloat16   flan-t5-base       0.78768   \n",
       "34    detailed     right  torch.bfloat16   flan-t5-base       0.78404   \n",
       "31    detailed     right   torch.float32   flan-t5-base       0.78376   \n",
       "28    detailed     right   torch.float16   flan-t5-base       0.78356   \n",
       "10      simple     right   torch.float16   flan-t5-base       0.78296   \n",
       "13      simple     right   torch.float32   flan-t5-base       0.78276   \n",
       "16      simple     right  torch.bfloat16   flan-t5-base       0.78272   \n",
       "21    detailed      left   torch.float32  flan-t5-small       0.75616   \n",
       "0       simple      left   torch.float16  flan-t5-small       0.75612   \n",
       "18    detailed      left   torch.float16  flan-t5-small       0.75612   \n",
       "24    detailed      left  torch.bfloat16  flan-t5-small       0.75596   \n",
       "3       simple      left   torch.float32  flan-t5-small       0.75596   \n",
       "12      simple     right   torch.float32  flan-t5-small       0.75536   \n",
       "6       simple      left  torch.bfloat16  flan-t5-small       0.75532   \n",
       "9       simple     right   torch.float16  flan-t5-small       0.75528   \n",
       "15      simple     right  torch.bfloat16  flan-t5-small       0.75484   \n",
       "30    detailed     right   torch.float32  flan-t5-small       0.75340   \n",
       "33    detailed     right  torch.bfloat16  flan-t5-small       0.75340   \n",
       "27    detailed     right   torch.float16  flan-t5-small       0.75332   \n",
       "\n",
       "    accuracy_max  accuracy_min  begin_time_avg  begin_time_max  \\\n",
       "29       0.82804       0.82804    1.731428e+09    1.731428e+09   \n",
       "32       0.82804       0.82804    1.731428e+09    1.731429e+09   \n",
       "35       0.82796       0.82796    1.731429e+09    1.731429e+09   \n",
       "11       0.82708       0.82708    1.731426e+09    1.731426e+09   \n",
       "17       0.82696       0.82696    1.731427e+09    1.731427e+09   \n",
       "14       0.82692       0.82692    1.731427e+09    1.731427e+09   \n",
       "2        0.82600       0.82600    1.731426e+09    1.731426e+09   \n",
       "8        0.82596       0.82596    1.731426e+09    1.731426e+09   \n",
       "5        0.82592       0.82592    1.731426e+09    1.731426e+09   \n",
       "23       0.82576       0.82576    1.731428e+09    1.731428e+09   \n",
       "20       0.82560       0.82560    1.731427e+09    1.731427e+09   \n",
       "26       0.82548       0.82548    1.731428e+09    1.731428e+09   \n",
       "4        0.78884       0.78884    1.731426e+09    1.731426e+09   \n",
       "1        0.78884       0.78884    1.731425e+09    1.731426e+09   \n",
       "7        0.78864       0.78864    1.731426e+09    1.731426e+09   \n",
       "19       0.78832       0.78832    1.731427e+09    1.731427e+09   \n",
       "22       0.78828       0.78828    1.731427e+09    1.731427e+09   \n",
       "25       0.78768       0.78768    1.731428e+09    1.731428e+09   \n",
       "34       0.78404       0.78404    1.731429e+09    1.731429e+09   \n",
       "31       0.78376       0.78376    1.731428e+09    1.731428e+09   \n",
       "28       0.78356       0.78356    1.731428e+09    1.731428e+09   \n",
       "10       0.78296       0.78296    1.731426e+09    1.731426e+09   \n",
       "13       0.78276       0.78276    1.731427e+09    1.731427e+09   \n",
       "16       0.78272       0.78272    1.731427e+09    1.731427e+09   \n",
       "21       0.75616       0.75616    1.731427e+09    1.731427e+09   \n",
       "0        0.75612       0.75612    1.731425e+09    1.731425e+09   \n",
       "18       0.75612       0.75612    1.731427e+09    1.731427e+09   \n",
       "24       0.75596       0.75596    1.731428e+09    1.731428e+09   \n",
       "3        0.75596       0.75596    1.731426e+09    1.731426e+09   \n",
       "12       0.75536       0.75536    1.731427e+09    1.731427e+09   \n",
       "6        0.75532       0.75532    1.731426e+09    1.731426e+09   \n",
       "9        0.75528       0.75528    1.731426e+09    1.731426e+09   \n",
       "15       0.75484       0.75484    1.731427e+09    1.731427e+09   \n",
       "30       0.75340       0.75340    1.731428e+09    1.731428e+09   \n",
       "33       0.75340       0.75340    1.731429e+09    1.731429e+09   \n",
       "27       0.75332       0.75332    1.731428e+09    1.731428e+09   \n",
       "\n",
       "    begin_time_min  end_time_avg  end_time_max  end_time_min  \n",
       "29    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "32    1.731428e+09  1.731429e+09  1.731429e+09  1.731428e+09  \n",
       "35    1.731429e+09  1.731429e+09  1.731429e+09  1.731429e+09  \n",
       "11    1.731426e+09  1.731426e+09  1.731427e+09  1.731426e+09  \n",
       "17    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "14    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "2     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "8     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "5     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "23    1.731427e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "20    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "26    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "4     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "1     1.731425e+09  1.731425e+09  1.731426e+09  1.731425e+09  \n",
       "7     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "19    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "22    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "25    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "34    1.731429e+09  1.731429e+09  1.731429e+09  1.731429e+09  \n",
       "31    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "28    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "10    1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "13    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "16    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "21    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "0     1.731425e+09  1.731425e+09  1.731425e+09  1.731425e+09  \n",
       "18    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "24    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "3     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "12    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "6     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "9     1.731426e+09  1.731426e+09  1.731426e+09  1.731426e+09  \n",
       "15    1.731427e+09  1.731427e+09  1.731427e+09  1.731427e+09  \n",
       "30    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  \n",
       "33    1.731429e+09  1.731429e+09  1.731429e+09  1.731429e+09  \n",
       "27    1.731428e+09  1.731428e+09  1.731428e+09  1.731428e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Code for your evaluation of results and write a small report on the \n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "experiment_results = []\n",
    "for config in EXPERIMENT_CONFIGURATIONS:\n",
    "    precision_str = str(config['precision'])\n",
    "    \n",
    "    accuracies = []\n",
    "    begin_times = []\n",
    "    end_times = []\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        file_path = f\"results_zero-shot/{config['model_size']}/{config['prompt_type']}_{config['structure']}_{precision_str}_{i}.json\"\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                result = json.load(f)\n",
    "                accuracies.append(result['accuracy'])\n",
    "                begin_times.append(result['begin_time'])\n",
    "                end_times.append(result['end_time'])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "    if accuracies:\n",
    "        experiment_results.append({\n",
    "            'prompt_type': config['prompt_type'],\n",
    "            'structure': config['structure'],\n",
    "            'precision': precision_str,\n",
    "            'model_size': config['model_size'],\n",
    "            'accuracy_avg': sum(accuracies) / len(accuracies),\n",
    "            'accuracy_max': max(accuracies),\n",
    "            'accuracy_min': min(accuracies),\n",
    "            'begin_time_avg': sum(begin_times) / len(begin_times),\n",
    "            'begin_time_max': max(begin_times),\n",
    "            'begin_time_min': min(begin_times),\n",
    "            'end_time_avg': sum(end_times) / len(end_times),\n",
    "            'end_time_max': max(end_times),\n",
    "            'end_time_min': min(end_times),\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(experiment_results)[[\n",
    "    'prompt_type', 'structure', 'precision', 'model_size', \n",
    "    'accuracy_avg', 'accuracy_max', 'accuracy_min',\n",
    "    'begin_time_avg', 'begin_time_max', 'begin_time_min',\n",
    "    'end_time_avg', 'end_time_max', 'end_time_min'\n",
    "]].sort_values(by='accuracy_avg', ascending=False)\n",
    "\n",
    "print(\"Aggregated Experiment Results:\")\n",
    "display(df_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451491eece3c6a57",
   "metadata": {},
   "source": [
    "\n",
    "*TODO: Write your report here, using appropriate tables, and or $math$, to support your claim.*\n",
    "\n",
    "Make sure to clearly state (among others):\n",
    "\n",
    "1. Which hyper-parameters you are testing \n",
    "2. Which levels you are testing for each experiment\n",
    "3. How many repetitions you use\n",
    "4. Which design of experiment you use: full-factorial / fractional-factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bdeee",
   "metadata": {},
   "source": [
    "### Experiment Report on Zero-Shot Prompting for Sentiment Analysis\n",
    "\n",
    "#### 1. Hyper-parameters Tested\n",
    "\n",
    "This experiment evaluated the following hyper-parameters and their effects on model performance in a zero-shot sentiment classification task:\n",
    "\n",
    "- **Prompt Type**: Two types of prompts were tested (`simple` and `detailed`), with the detailed prompt providing additional task context.\n",
    "- **Structure**: The question position was varied, appearing either to the `left` (before) or `right` (after) of the review text.\n",
    "- **Precision**: We tested three levels of numerical precision (`torch.float16`, `torch.float32`, and `torch.bfloat16`).\n",
    "- **Model Size**: We tested three model sizes (`T5-flan-small`, `T5-flan-base`, and `T5-flan-large`).\n",
    "\n",
    "#### 2. Levels for Each Hyper-parameter\n",
    "\n",
    "The levels tested for each hyper-parameter were as follows:\n",
    "\n",
    "- **Prompt Type**: `simple`, `detailed`\n",
    "- **Structure**: `left`, `right`\n",
    "- **Precision**: `torch.float16`, `torch.float32`, `torch.bfloat16`\n",
    "- **Model Size**: `T5-flan-small`, `T5-flan-base`, `T5-flan-large`\n",
    "\n",
    "#### 3. Number of Repetitions\n",
    "\n",
    "EEach configuration was run **five times** to ensure reliability of the results. The average, maximum, and minimum values for accuracy, begin_time, and end_time are reported for each configuration.\n",
    "\n",
    "#### 4. Design of Experiment\n",
    "\n",
    "This study used a **full-factorial design**, covering all combinations of hyper-parameters. With four hyper-parameters and their respective levels (2 x 2 x 3 x 3), this resulted in a total of **36 unique configurations**.\n",
    "\n",
    "#### Results Summary\n",
    "\n",
    "The experiment results (as shown above) reveal the following key insights:\n",
    "\n",
    "The aggregated results from the experiment are as follows:\n",
    "\n",
    "- **Model Size**: The model size (`model_size`) emerged as the most significant factor influencing accuracy. As the model size increased from `T5-flan-small` to `T5-flan-large`, there was a noticeable improvement in average accuracy (`accuracy_avg`). This indicates that larger models perform better in the zero-shot sentiment classification task, likely due to their increased capacity to capture complex patterns in the data.\n",
    "\n",
    "- **Prompt Structure**: The position of the prompt (`structure`) showed some influence on performance in the `T5-flan-large` model, where prompts positioned on the `right` led to slightly higher accuracy than those on the `left`. This effect was not observed in the smaller models, suggesting that the impact of prompt structure may be more pronounced in larger models.\n",
    "\n",
    "- **Prompt Type** and **Precision**: The type of prompt (`prompt_type`) and numerical precision (`precision`) had minimal impact on accuracy. Although there were slight variations, no consistent pattern emerged to indicate that one level was superior to the others in these categories.\n",
    "\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The findings indicate that **model size** is the primary driver of accuracy in this zero-shot sentiment classification task. Larger models consistently outperformed smaller ones. The prompt structure also appeared to have a minor effect on performance in the largest model configuration, with prompts positioned on the `right` yielding slightly better results. However, prompt type and precision had minimal influence on model performance.\n",
    "\n",
    "The experiment's results were consistent across five repetitions for each configuration, demonstrating a high degree of reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129567b768b27df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a647c148276eaf5",
   "metadata": {},
   "source": [
    "# Exercise 2: Learning Through Examples 'In-Context Learning' (20 points total)\n",
    "\n",
    "Instead of asking the model its decision at face-value, in this exercise we will provide the model with a view examples. Although the jury is out on why this exactly works, the idea is that the examples allow to 'prime' the model, to understand the task better that it is going to perform.\n",
    "\n",
    "In short, this exercise consists of the following parts;\n",
    " 1. **Exercise 2.1.1:**  (2 points) Design and implementation a few-shot template in (`get_few_shot_prompt_template`).\n",
    " 2. **Exercise 2.1.2:**  (3 points) Implementation of Few-shot dataloader with independently randomly drawn context.\n",
    " 3. **Exercise 2.1.3:**  (BONUS 10 points) few-shot dataloader with independently drawn semantic context.\n",
    " 4. **Exercise 2.2:**:   (8 points) perform Design of Experiments.\n",
    " 5. **Exercise 2.3:**    (7 points) Analyise and write-up the DoE results.\n",
    "\n",
    "**N.B.** we recommend using Jinja to create templates for prompts. This allows to quickly transform the IMDB samples `text` `str`ings to Few-Shot samples, to be used in your DoE. Additionally, make sure to use `textwrap.dedent` to wrap around triple-quoted (multi-line) `str`ings! Otherwise, you will add (unintentional) whitespace `char`s!\n",
    "\n",
    "> If you find performing 2 and 3 difficult, you can also hard-code some review, and choose an additional system or hyper-parameter!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e65ca5cc5be5d6",
   "metadata": {},
   "source": [
    "## 2.1.2 Creating a Few-Shot Template (2 points)\n",
    "First design a template that allows to render a varying number of few shot examples.\n",
    "\n",
    "Your template should take as arguments\n",
    "\n",
    "* `question_answer_pairs` of type `List[Tuple[str, str]]`, i.e., a list of tuples containing a review and a stringified sentiment.\n",
    "* `review` of type `str` that contains the review the model should classify.\n",
    "\n",
    "Your template should render the text in a way that provides the model with examples (`question_answer_pairs`), and then provides the `review` to be classified by the model. You can use your insights from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55d68485e1d025ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:26:55.168511Z",
     "start_time": "2024-10-17T19:26:55.159686Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Your few-shot prompt looks like this.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<br>Here are some example reviews and their sentiments:<br><br>- Review: \"\"<br>  Sentiment: \"\"<br><br>- Review: \"\"<br>  Sentiment: \"\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"\"<br>Sentiment:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**As an example, your few-shot prompt looks like this.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<br>Here are some example reviews and their sentiments:<br><br>- Review: \"I like the movie\"<br>  Sentiment: \"Positive\"<br><br>- Review: \"I dislike the movie\"<br>  Sentiment: \"Negative\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"Event the prequels were far better than this!\"<br>Sentiment:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_few_shot_prompt_template() -> jinja2.Template:\n",
    "    \"\"\"Function to get a few-shot template to render render Few-Shot prompts in a `dataset.map` function.\n",
    "    \n",
    "    Notes:\n",
    "        The prompt-template uses a variable `question_answer_pair` and `review` as input.\n",
    "        \n",
    "    Examples:\n",
    "        ```\n",
    "        template = get_few_shot_prompt_template()\n",
    "        template.render(question_answer_pair=[('Wow I like this movie', 'Positive'), ('I like the Sequels better...', 'Negative')], review='I like this movie')\n",
    "        ```\n",
    "\n",
    "    Returns:\n",
    "        jinja2.Template that can be rendcered \n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement a few-shot style evaluation prompt, the prompt should use a \n",
    "    #  variable `question_answer_pair`, consisting of a list of Tuples of Reviews and (textual) Labels.\n",
    "    PROMPT_TEMPLATE = textwrap.dedent(\n",
    "        # YOUR CODE GOES HERE\n",
    "        \n",
    "        \"\"\"\n",
    "        Here are some example reviews and their sentiments:\n",
    "        {% for text, sentiment in question_answer_pairs %}\n",
    "        - Review: \"{{ text }}\"\n",
    "          Sentiment: \"{{ sentiment }}\"\n",
    "        {% endfor %}\n",
    "\n",
    "        Now, please classify the sentiment of the following review:\n",
    "        - Review: \"{{ review }}\"\n",
    "        Sentiment:\n",
    "        \"\"\"\n",
    "\n",
    "        # END OF YOUR CODE\n",
    "    )\n",
    "    assert set(jinja2schema.infer(PROMPT_TEMPLATE).keys()) == {'question_answer_pairs', 'review'}\n",
    "    template = jinja2.Template(PROMPT_TEMPLATE)\n",
    "    return template\n",
    "\n",
    "simple_few_shot_template = get_few_shot_prompt_template()\n",
    "\n",
    "empty_pairs, empty_review = [('', ''), ('', '')], ''\n",
    "empty_template_result = simple_few_shot_template.render(question_answer_pairs=empty_pairs, review=empty_review)\n",
    "example_pairs, example_review = ([('I like the movie', 'Positive'), ('I dislike the movie', 'Negative')], \n",
    "                                 'Event the prequels were far better than this!')\n",
    "example_template_result = simple_few_shot_template.render(question_answer_pairs=example_pairs,review=example_review)\n",
    "\n",
    "display(\n",
    "    Markdown('**Your few-shot prompt looks like this.**'),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {nl_to_br(empty_template_result)}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ),\n",
    "    Markdown('**As an example, your few-shot prompt looks like this.**'),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {nl_to_br(example_template_result)}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee5766737b2a26c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:26:57.911755Z",
     "start_time": "2024-10-17T19:26:57.905168Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exercise 2.1.1 output"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Few-Shot prompt looks like this.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse; width: 100%;\">\n",
       "    <tr>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">My few-shot prompt (empty)</th>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">My few-shot prompt (example)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\"><br>Here are some example reviews and their sentiments:<br><br>- Review: \"\"<br>  Sentiment: \"\"<br><br>- Review: \"\"<br>  Sentiment: \"\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"\"<br>Sentiment:</td>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\"><br>Here are some example reviews and their sentiments:<br><br>- Review: \"I like the movie\"<br>  Sentiment: \"Positive\"<br><br>- Review: \"I dislike the movie\"<br>  Sentiment: \"Negative\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"Event the prequels were far better than this!\"<br>Sentiment:</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not edit this cell\n",
    "display(\n",
    "    Markdown('### Exercise 2.1.1 output'),\n",
    "    Markdown('**Few-Shot prompt looks like this.**'),\n",
    "    HTML(\n",
    "    textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My few-shot prompt (empty)</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">My few-shot prompt (example)</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{nl_to_br(empty_template_result)}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{nl_to_br(example_template_result)}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20d8a00678ba1b",
   "metadata": {},
   "source": [
    "## 2.1.2 Create a Few-Shot Dataset (3 points)\n",
    "\n",
    "Next you will complete the implementation to create a Few-Shot `Dataset` that contains the pre-processed few-shot examples, rendered with your template from `2.1.2`. Herein, we will use a `shots` parameter that dictates the size of the context that is provided to the model. Make sure that the shots are randomly drawn for each exercise, but if you find this difficult, hard-coding a set of positive and negative examples is OK as well for 1 out of 3 points.\n",
    "\n",
    "Within this exercise, points are awarded for: \n",
    "\n",
    "* Creating a Dataset with a configurable number of shots (1 point)\n",
    "* Configurable number of randomly drawn shots (2 point)\n",
    "\n",
    "\n",
    "> Note, here you can already set one of the level, by making the `K` of shots configurable, you can also think about the ratio of Positive / Negative.\n",
    "\n",
    "> If you want, and your resources allow for it, you might want to combine the Few-Shot idea with your prompt-based approach, you can use that as a variable, and choose one additional hyper- and/or system-parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe929e482037a3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:27:15.295719Z",
     "start_time": "2024-10-17T19:27:14.543531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**As an example, here is how your data looks like**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<br>Here are some example reviews and their sentiments:<br><br>- Review: \"Throughout this film, you might think this film is just for kids. Well, it is mainly pointed towards them, but it's also well-rounded enough with the jokes pointed also at the adults in the audience. This time\"<br>  Sentiment: \"Positive\"<br><br>- Review: \"I saw an interview with Rob Schneider (who plays the lead character, Marvin Mange, in this film.) He said in it that he wanted to emphasize physical comedy here so much that even if you had the volume turned off\"<br>  Sentiment: \"Negative\"<br><br>- Review: \"I love B movies..but come on....this wasn't even worth a grade...The ending was dumb...b/c THERE WAS NO REAL ENDING!!!..not to mention that it comes to life on\"<br>  Sentiment: \"Negative\"<br><br>- Review: \"I read thru most of the comments posted here & all I can say it that most of these posters have major problems in life. This show, unlike most game show, was fun. Mr. Shatner, whose brill\"<br>  Sentiment: \"Positive\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I\"<br>Sentiment:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def draw_batched_random_shots(\n",
    "    batch: Dict[str, List[Any]],\n",
    "    positive_dataset: datasets.Dataset = None,\n",
    "    negative_dataset: datasets.Dataset = None,\n",
    "    template: transformers.PreTrainedTokenizer = None,\n",
    "    shuffle=False,\n",
    "    shots=4,\n",
    ") -> Dict[str, List[Any]]:\n",
    "    \"\"\"Method to implement drawing random shots of data.\n",
    "    Args:\n",
    "        batch (Dict[str, List[str]]): Batch of data to convert to in-context example dataset. \n",
    "        dataset (datasets.Dataset): Dataset to use for drawing random shots. \n",
    "        tokenizer (transformers.PreTrainedTokenizer): the tokenizer to use to convert shot to... \n",
    "        shots (int, 4): Number of shots to sample, defaults to 4. \n",
    "\n",
    "    Returns:\n",
    "        Transformed representation of a batch of samples with the `text` representation updated.\n",
    "    \"\"\"\n",
    "    batch_texts = batch['text']\n",
    "    \"\"\"\n",
    "    Recall that  \n",
    "    text_labels = 'Positive' if label == 0 else 'Negative'\n",
    "    \"\"\"\n",
    "   \n",
    "    # These Lists you need to construct.\n",
    "    result: List[str] = []\n",
    "    positive_shots: List[List[str]] = []\n",
    "    negative_shots: List[List[str]] = []\n",
    "    \n",
    "    # TODO: Implement code to create random contexts of positive and/or negative reviews.\n",
    "    # Hint: use the positive_dataset and negative_dataset\n",
    "    # Hint: dataset can be shuffled, and `take`n from.\n",
    "    # Hint: if you find this difficult, or as additional level you can also hard-code these lists\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    positive_samples_list = list(positive_dataset)\n",
    "    negative_samples_list = list(negative_dataset)\n",
    "\n",
    "    for _ in range(len(batch_texts)):\n",
    "        random_positive_samples = random.sample(positive_samples_list, shots // 2)\n",
    "        random_negative_samples = random.sample(negative_samples_list, shots // 2)\n",
    "        \n",
    "        random_positives = [(sample['text'], 'Positive') for sample in random_positive_samples]\n",
    "        random_negatives = [(sample['text'], 'Negative') for sample in random_negative_samples]\n",
    "        \n",
    "        positive_shots.append(random_positives)\n",
    "        negative_shots.append(random_negatives)\n",
    "\n",
    "    # END OF YOUR CODE\n",
    "    \n",
    "    # Merge your sampled or hard-coded shots into a rendered string.\n",
    "    for random_positives, random_negatives, review in zip(positive_shots, negative_shots, batch_texts):\n",
    "        context = random_positives + random_negatives\n",
    "        if shuffle:\n",
    "            random.shuffle(context)\n",
    "        random.shuffle(context)\n",
    "        result.append(\n",
    "            template.render(\n",
    "                question_answer_pairs=context,\n",
    "                review=review\n",
    "            )\n",
    "        )\n",
    "    batch['text'] = result\n",
    "    return batch\n",
    "\n",
    "def get_simple_few_shot_dataset(\n",
    "        train_set: datasets.Dataset,\n",
    "        test_set: datasets.Dataset,\n",
    "        *sample_args,\n",
    "        **sample_kwargs \n",
    ") -> datasets.Dataset:\n",
    "    \"\"\"Function to get a few-shot dataloader that loads random examples from the correst split.\n",
    "    \n",
    "    Args:\n",
    "        train_set (): \n",
    "        test_set (): \n",
    "        shots (int, 4): Number of shots to draw, defaults to 4. \n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    positive_set = train_set.filter(\n",
    "        lambda sample: sample['label'] == 1, batched=False\n",
    "    )\n",
    "    negative_set = train_set.filter(\n",
    "        lambda sample: sample['label'] == 0, batched=False\n",
    "    )\n",
    "    partial_draw_random_shots = partial(draw_batched_random_shots, positive_dataset=positive_set, negative_dataset=negative_set, **sample_kwargs)\n",
    "    return_set = (\n",
    "        test_set\n",
    "        .map(partial_draw_random_shots, batched=True, num_proc=1) # Map to stringified representation\n",
    "    )\n",
    "\n",
    "    return_set = return_set.map(\n",
    "        lambda batch: tokenizer(\n",
    "            batch['text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=50,\n",
    "            return_tensors=\"pt\"\n",
    "        ),\n",
    "        batched=True\n",
    "    )\n",
    "    return_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label', 'text'])\n",
    "\n",
    "    return return_set\n",
    "\n",
    "\n",
    "truncated_train_set = (\n",
    "    train_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    ")\n",
    "truncated_test_set = (\n",
    "    test_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    ")\n",
    "\n",
    "simple_dataset = get_simple_few_shot_dataset(\n",
    "    truncated_train_set,\n",
    "    truncated_test_set,\n",
    "    template = get_few_shot_prompt_template(),\n",
    "    shots=4\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\"**As an example, here is how your data looks like**\"),\n",
    "    Markdown(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            {nl_to_br(simple_dataset[0]['text'])}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e15d290da26bb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:27:35.473925Z",
     "start_time": "2024-10-17T19:27:35.447404Z"
    },
    "tags": [
     "hide-cell",
     "keep-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse; width: 100%;\">\n",
       "    <tr>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">Sample (1126)</th>\n",
       "        <th style=\"text-align: left; border: 1px solid black;\">Sample (1172)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\"><br>Here are some example reviews and their sentiments:<br><br>- Review: \"This movie was advertised on radio, television, magazines, etc. Almost every hour or every issue. So when we went to the Kinnepolis multiplex our expectations were very high. But oh boy, how sad this movie is\"<br>  Sentiment: \"Negative\"<br><br>- Review: \"The most satisfying element about \"Dan in Real Life\" is that the relationship between Dan (Steve Carell) and Marie (Juliette Binoche) makes sense and is beautifully realistic. The casting of Oscar-winner\"<br>  Sentiment: \"Positive\"<br><br>- Review: \"I've never been a fan of Farrah Fawcett...Until now. She was truly amazing in this movie. The emotion she must have gone through shooting re-take after re-take doesn't \"<br>  Sentiment: \"Positive\"<br><br>- Review: \"The director states in the Behind-the-Scenes feature that he loves horror movies. He loves them so much that he dedicated the movie to Dario Argento, as well as other notable directors such as George A.\"<br>  Sentiment: \"Negative\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"First things first, how can someone with his creativity on the right side believe in a movie like this. I saw this movie and after end of couple of hours was left scratching my head, what exactly is director trying to say.\"<br>Sentiment:</td>\n",
       "        <td style=\"text-align: left; border: 1px solid black;\"><br>Here are some example reviews and their sentiments:<br><br>- Review: \"The Lack of content in this movie amazed me the most. First i though that people was going to compare this to Rock On! but i'm really surprised myself to say that this was worst than Rock On! So-so\"<br>  Sentiment: \"Negative\"<br><br>- Review: \"First of all I need to say that I'm Portuguese and it's not usual to me spend my time watching Portuguese movies, probably one each year or even none...br />br />...And\"<br>  Sentiment: \"Positive\"<br><br>- Review: \"When I first got my N64 when I was five or six,I fell in love with it,and my first game was Super Mario 64.And I LOVED IT!The graphics were great for it's time,a good plot\"<br>  Sentiment: \"Positive\"<br><br>- Review: \"I've probably been spoilt by having firstly seen the 1973 version with Michael Jayston and Sorcha Cusack so the 1983 adaptation is such a disappointment. I just didn't get any chemistry between the 2 main stars\"<br>  Sentiment: \"Negative\"<br><br><br>Now, please classify the sentiment of the following review:<br>- Review: \"just watched this \"film\" and it actually made me want to write my first comment on IMDb.com, even though i've been a user for more than 9 years. the reason that i watched this, is\"<br>Sentiment:</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not edit this code\n",
    "import random\n",
    "index_1, index_2 = random.randint(0, 2500), random.randint(0, 2500)\n",
    "sample_1 = nl_to_br(simple_dataset.shuffle()[index_1]['text'])\n",
    "sample_2 = nl_to_br(simple_dataset.shuffle()[index_2]['text'])\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        textwrap.dedent(\n",
    "            f\"\"\"\\\n",
    "            <table style=\"border-collapse: collapse; width: 100%;\">\n",
    "                <tr>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Sample ({index_1})</th>\n",
    "                    <th style=\"text-align: left; border: 1px solid black;\">Sample ({index_2})</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{sample_1}</td>\n",
    "                    <td style=\"text-align: left; border: 1px solid black;\">{sample_2}</td>\n",
    "                </tr>\n",
    "            </table>\"\"\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08c46ea43477f0",
   "metadata": {},
   "source": [
    "### (BONUS) Exercise 2.1.3 I would like additional context please (BONUS 10)\n",
    "\n",
    "Instead of randomly sampling datapoints to create a Few-Shot context. However, maybe we can do better. An example of this, is to create a more semanticly relevant content, that provide more relevant information for the model to make a decision.\n",
    "\n",
    "For this bonus exericse the recipe is (roughly) as follows:\n",
    "\n",
    " 1. Creating a semantic embeddings of samples to create a context from (an embedding model).\n",
    " 2. Creating a vector database to lookup examples.\n",
    " 3. (Pre-compute) set of example to use (I.e. vector lookup).\n",
    " 4. Render the template (similar as before)\n",
    "\n",
    "We have provided some skeleton code to get started, but TAs cannot provide any assistant for this exericse (unless our template contains an error :))\n",
    "\n",
    "> N.B. that this will take some compute power, so you might want to save the (stringified) dataset that you allow to continue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7ac6a80fd2e9027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Example of Contextual Few-Shot Dataset Entry"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Generated Prompt:**\n",
       "\n",
       "\n",
       "Here are some example reviews and their sentiments:\n",
       "\n",
       "- Review: \"I cannot believe how popular this show is. I consider myself an avid sci-fi fan. I have read countless sci-fi novels and have enjoyed many sci-fi movies and TV shows. I really wouldn't even consider this true sci-fi. Every episode I have sat through was like a lame, watered down version of a Star Trek episode, minus anything that might make it interesting or exciting.<br /><br />It's basically a bunch of people standing around in ARMY fatigues, talking about something boring, who occasionally go through the Stargate and end up on a planet that looks just like Earth, with people who look and sound just like Humans! It seemed extremely low budget. The characters are all forgettable one dimensional cutouts, and the many attempts at humor fall flat. It reminds me when you see a commercial with a famous athlete in it, trying to be funny, but he is not. It is just sad.<br /><br />The movie was terrible as well. There is so much you can do with a portal through space, yet every place the ARMY people go is BORING! This shows no imagination! I actually thought the TV series \"Alien Nation\" from a few years back (based on the movie Alien Nation) was much better. That show actually had good story lines and decent characters. I wasn't crazy about \"Alien Nation\", but compared to this overrated crap, it was great!<br /><br />Also, unlike the great new \"Battlestar Galactica\" series, \"Stargate\" copied the look and feel of the lame movie too closely! They should have at least updated the cheesy \"toilet flushing\" special effect of whenever somebody goes through the Stargate.\"\n",
       "  Sentiment: \"Negative\"\n",
       "\n",
       "- Review: \"When I was younger I really enjoyed watching bad television. We've all been guilty of it at some time or another, but my excuse for watching things like \"Buck Rogers in the 25th Century\" and \"Silver Spoons\" is this: I was young and naive; ignorant of what makes a show really worthwhile.<br /><br />Thankfully, I now appreciate the good stuff. Stargate SG-1 is not good. The 12 year-old me would love every hackneyed bit of it, every line of stilted dialogue, every bit of needless technobabble. The writing is beyond insipid; so bland and uninspired it makes one miss Star Trek: Voyager. If your show makes me long for the worst Trek show ever, you're in trouble.<br /><br />The film Stargate is a wonderful guilty pleasure, anchored by two solid performances by James Spader and Kurt Russell, full of fascinating Egyptian architecture and culture, a wonderful musical score, and cool sci-fi ideas. With the exception of a little of the original music, none of what made the film fun appears in this show. Even Richard Dean Anderson, who made MacGyver watchable and Legend interesting, seems like he's half asleep most episodes.<br /><br />The budget must have been very low because the sets sometimes look like somebody's basement. The cinematography isn't much better, as vanilla and dull as the scripts. It amazes me that shows with a lot more style (like Farscape) and substance (like the reimagined Battlestar Galactica) have smaller, less rabid fanbases than this pap. It just doesn't deserve it.\"\n",
       "  Sentiment: \"Negative\"\n",
       "\n",
       "- Review: \"I loved this show from it's first airing, and I always looked forward to watching each episode every week. The plot, characters, writing, special affects were outstanding! Then the sci-fi channel screwed up yet again and canceled a very entertaining, well written show. I say bring it back, I know all of the actors would come back. I would suggest buying the DVD's, I am. I hope the sci-fi channels executives get word of these comments, and realize that they need to be more involved with their viewers. I only watch one show on that channel now, (Ghost Hunters), but I am fairly sure that shortly they will cancel that too.\"\n",
       "  Sentiment: \"Positive\"\n",
       "\n",
       "- Review: \"I nominate this and BABYLON 5 as the best television sci-fi series made. Both stand out in my mind because unlike early STAR TREK series, there is a consistent evolution of plots and characters. If you look at the original STAR TREK and STAR TREK:TNG, they were fine shows, but there was no overall theme or plot that connected all the episodes. In many ways, you could usually watch the shows totally out of sequence with no difficulty understanding what is occurring. This was less the case with DEEP SPACE 9 (with its giant battles that took up all of the final season) and the other TREK shows, as there was more of a larger story that unified them. This coherence seems to have developed as a concept with BABYLON 5 and saw this to an even greater extent with SG-1. The bottom line is that in many ways this series was like watching a family or a long novel slowly take form. Sure, there were a few \"throwaway\" episodes that were not connected to the rest, but these were very few and far between and were also usually pretty funny.<br /><br />And speaking of funny, I loved that SG-1 kept the mood light from time to time and wasn't so dreadfully serious. In this way, I actually enjoyed it more than BABYLON 5. Jack O'Neill was a great character with his sarcasm and love of Homer Simpson--it's really too bad he slowly faded from the series in later seasons.<br /><br />To truly appreciate SG-1, you should watch it from the beginning and see how intricately the plots work. This coherence gives the show exceptional staying power. And, if you don't like SG-1 after giving it a fair chance, then sci-fi is probably NOT the genre for you.\"\n",
       "  Sentiment: \"Positive\"\n",
       "\n",
       "\n",
       "Now, please classify the sentiment of the following review:\n",
       "- Review: \"I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \"Gene Roddenberry's Earth...\" otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\"\n",
       "Sentiment:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "# We advice to use a small model from Sentence transformer, but feel free to use somethign\n",
    "# completey different, or use this as an additonal level!\n",
    "embedding_model = SentenceTransformer(embedding_model)\n",
    "\n",
    "# TODO: Complete and upate the functions to perfrom semantic search.\n",
    "# As a hint: Look at the imports adn see how they can be used.\n",
    "\n",
    "def create_semantic_db(\n",
    "        embedding_model: SentenceTransformer,\n",
    "        train_set: datasets.Dataset,\n",
    "        test_set: datasets.Dataset\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:  \n",
    "    \"\"\"Function to create a sematnic database.\n",
    "    \n",
    "    Args:\n",
    "        embedding_model (): \n",
    "        train_set (): \n",
    "        test_set (): \n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    embedding_path = Path('embeddings.pkl')\n",
    "    data = None\n",
    "    \n",
    "    if embedding_path.exists():\n",
    "        try:\n",
    "            with open(embedding_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                return data['embeddings'], data['positive_embeddings'], data['negative_embeddings'], data['positive_samples'], data['negative_samples']\n",
    "        except (EOFError, pickle.UnpicklingError):\n",
    "            print(\"Corrupted embeddings.pkl file detected. Recreating the file.\")\n",
    "            embedding_path.unlink()  # Delete the corrupted file\n",
    "\n",
    "    positive_samples = [sample['text'] for sample in train_set if sample['label'] == 1]\n",
    "    negative_samples = [sample['text'] for sample in train_set if sample['label'] == 0]\n",
    "    \n",
    "    positive_embeddings = embedding_model.encode(positive_samples, convert_to_tensor=True)\n",
    "    negative_embeddings = embedding_model.encode(negative_samples, convert_to_tensor=True)\n",
    "    embeddings = torch.cat([positive_embeddings, negative_embeddings], dim=0)\n",
    "    \n",
    "    with open(embedding_path, \"wb\") as fOut:\n",
    "        pickle.dump({\n",
    "        'embeddings': embeddings,\n",
    "        'positive_embeddings': positive_embeddings,\n",
    "        'negative_embeddings': negative_embeddings,\n",
    "        'positive_samples': positive_samples,\n",
    "        'negative_samples': negative_samples\n",
    "        }, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return embeddings, positive_embeddings, negative_embeddings, positive_samples, negative_samples\n",
    "\n",
    "def find_batched_semantic_search(\n",
    "        batch: Dict[str, List[str]],\n",
    "        tokenizer: transformers.PreTrainedTokenizer,\n",
    "        corpus_embeddings: torch.Tensor,\n",
    "        negative_corpus_embeddings: torch.Tensor,\n",
    "        positive_corpus_embeddings: torch.Tensor,\n",
    "        positive_samples: List[str],\n",
    "        negative_samples: List[str],\n",
    "        shots=4\n",
    ") -> Dict[str, List[str]]:\n",
    "    \n",
    "    # You will have to create a list of rendered string with the found context.\n",
    "    results: List[str] = []\n",
    "    # TODO: Implement a batched `semantic_search` to find relevant items.\n",
    "    \n",
    "    # Perform semantic search for each item in the batch\n",
    "    batch_texts = batch['text']\n",
    "    batch_embeddings = embedding_model.encode(batch_texts, convert_to_tensor=True)\n",
    "    \n",
    "    positive_results = sentence_transformers.util.semantic_search(\n",
    "        batch_embeddings, positive_corpus_embeddings, top_k=shots // 2\n",
    "    )\n",
    "    negative_results = sentence_transformers.util.semantic_search(\n",
    "        batch_embeddings, negative_corpus_embeddings, top_k=shots // 2\n",
    "    )\n",
    "    template = get_few_shot_prompt_template()\n",
    "\n",
    "    # Select relevant samples for each sample in the batch\n",
    "    for i in range(len(batch_texts)):\n",
    "        pos_samples = [(positive_samples[res['corpus_id']], 'Positive') for res in positive_results[i]]\n",
    "        neg_samples = [(negative_samples[res['corpus_id']], 'Negative') for res in negative_results[i]]\n",
    "        context_samples = pos_samples + neg_samples\n",
    "        \n",
    "        # Collate the found results for the batch\n",
    "        if shots > 1:\n",
    "            random.shuffle(context_samples)\n",
    "\n",
    "        # Render the results using a template\n",
    "        rendered_text = template.render(\n",
    "            question_answer_pairs=context_samples,\n",
    "            review=batch_texts[i]\n",
    "        )\n",
    "        results.append(rendered_text)\n",
    "\n",
    "    batch['text'] = results\n",
    "\n",
    "    tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    batch['input_ids'] = tokenized_batch['input_ids']\n",
    "    batch['attention_mask'] = tokenized_batch['attention_mask']\n",
    "\n",
    "    return batch\n",
    "\n",
    "def get_contextual_drawn_few_shot_dataset(\n",
    "        train_set: datasets.Dataset,\n",
    "        test_set: datasets.Dataset,\n",
    "        tokenizer: transformers.PreTrainedTokenizer,\n",
    "        corpus_embeddings: torch.Tensor,\n",
    "        negative_corpus_embeddings: torch.Tensor,\n",
    "        positive_corpus_embeddings: torch.Tensor,\n",
    "        positive_samples: List[str],\n",
    "        negative_samples: List[str],\n",
    "        shots: int = 4,\n",
    "        *args,\n",
    "        **kwargs\n",
    ") -> datasets.Dataset:\n",
    "    \"\"\"Function to get a few-shot dataloader based on context.\"\"\"\n",
    "    partial_semantic_search = partial(\n",
    "        find_batched_semantic_search,\n",
    "        tokenizer=tokenizer,\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        negative_corpus_embeddings=negative_corpus_embeddings,\n",
    "        positive_corpus_embeddings=positive_corpus_embeddings,\n",
    "        positive_samples=positive_samples,\n",
    "        negative_samples=negative_samples,\n",
    "        shots=shots\n",
    "    )\n",
    "    \n",
    "    return_set = (\n",
    "        test_set\n",
    "        .map(partial_semantic_search, batched=True, num_proc=1)\n",
    "    )\n",
    "\n",
    "    return_set = return_set.map(\n",
    "        lambda batch: tokenizer(\n",
    "            batch['text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=50,\n",
    "            return_tensors=\"pt\"\n",
    "        ),\n",
    "        batched=True\n",
    "    )\n",
    "    \n",
    "    return_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label', 'text'])\n",
    "    \n",
    "    return return_set\n",
    "\n",
    "# Step 1: Get embeddings\n",
    "corpus_embedding, positive_embedding, negative_embedding, positive_samples, negative_samples = create_semantic_db(\n",
    "    embedding_model=embedding_model,\n",
    "    train_set=train_set,\n",
    "    test_set=test_set\n",
    ")\n",
    "\n",
    "SHOTS = 4   # YOU MIGHT WANT TO CHANGE THIS IF YOU USE SHOTS AS A VARIABLE\n",
    "q2_complex_set = get_contextual_drawn_few_shot_dataset(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    tokenizer=tokenizer,\n",
    "    corpus_embeddings=corpus_embedding,\n",
    "    negative_corpus_embeddings=negative_embedding,\n",
    "    positive_corpus_embeddings=positive_embedding,\n",
    "    positive_samples=positive_samples,\n",
    "    negative_samples=negative_samples,\n",
    "    shots=SHOTS\n",
    ")\n",
    "\n",
    "random_sample = q2_complex_set[0]\n",
    "display(\n",
    "    # TODO: Implement showing an example that shows that it works\n",
    "    Markdown(\"### Example of Contextual Few-Shot Dataset Entry\"),\n",
    "    Markdown(f\"**Generated Prompt:**\\n\\n{random_sample['text']}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc932d4307f86a75",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Perform DoE (8 points)\n",
    "\n",
    "In this and the following exercise, we are interested in quantifing the effect of different configurations on the Few-Shot performance of the model, you will need to select at-least 3 system- and/or hyper-parameters, with each having at least two or more (2+) levels. Recall that you may wish to use the shots hyper-parameters (e.g. $\\texttt{shots} \\in  [2, 4, 6 ]$).\n",
    "\n",
    "Furthermore, we suggest using one or more from the following parameters in your DoE:\n",
    "\n",
    "  * Model size, for example (`T5-flan-small`, `T5-flan-base`, `T5-flan-large`, etc.). (only recommended with GPU)\n",
    "  * Numerical precision (`torch.float16`, `torch.float32`, `torch.bfloat16`). Make sure your hardware / `PyTorch` version supports this!\n",
    "  * Quantization (only recommended with GPU with `BitsAndBytes` packages).\n",
    "  * Structured decoding (requires implememtantation).\n",
    "\n",
    "\n",
    "In short, you will need to perform;\n",
    "\n",
    "1. (8 points) Design of Experiments in code;\n",
    "    * Selection of critaria.\n",
    "    * Type of factorial experiment.\n",
    "    * Creation of experimental configuration.\n",
    "    * Run your experiments.\n",
    "        * Depending on your chosen variables in DoE, you might need to make some minor adaptations to our provided code.\n",
    "\n",
    "> For your convenience, we have split first DoE part,  and the Design of Experiments (which you have to implement), and the ANOVA analysis into 2 cells. We strongly recommend writing data to disk/persistent storage and loading it in the next cell to make sure you can easily re-run evaluation upon restarting the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b1ed65e83382979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:35:50.685765Z",
     "start_time": "2024-10-17T19:35:50.678442Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def run_q2_evaluation(\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        model: transformers.PreTrainedModel,\n",
    "        generation_config,\n",
    "        *args,\n",
    "        **kwargs\n",
    ") -> Tuple[List[List[str]], List[List[int]]]:\n",
    "    \"\"\"Helper function to run evaluation (e.g. under different evaluations.\n",
    "    \n",
    "    Args:\n",
    "        dataloader: \n",
    "        model: \n",
    "        generation_config:\n",
    "        *args: Any additional positional args you want to add.\n",
    "    \n",
    "    Keyword Args:\n",
    "        **kwargs: Any additional keyword args you want to add.\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    prediction_list, label_list = [], []\n",
    "    for idx, batch in (pbar := tqdm(enumerate(dataloader), leave=False, total=len(dataloader))):\n",
    "        pbar.set_description(f'Batch {idx}')\n",
    "        input_ids, attention_mask, label = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "        \n",
    "        \n",
    "        # TODO: You might need to implement something for your experiment here!\n",
    "\n",
    "        # YOUR CODE GOES HERE\n",
    "        \n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "        prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        prediction_list.append(prediction)\n",
    "        label_list.append(label.cpu().tolist())\n",
    "\n",
    "        if idx%100==0:\n",
    "            print('idx: ', idx)\n",
    "            print(\"input_ids: \", input_ids)\n",
    "            print(\"prediction: \", prediction)\n",
    "            print(\"label: \", label)\n",
    "            print(\"batch['text']: \", batch['text'])\n",
    "            \n",
    "    return prediction_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27214eb5a9589b5",
   "metadata": {},
   "source": [
    "### Exericse 2.2.1 Design of Experiments\n",
    "Define your Design of Experiment configurations in the list `EXPERIMENT_CONFIGURATIONS`, you can use this list to store experiment configurations for the different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83544b67b31afedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:39:22.346513Z",
     "start_time": "2024-10-17T19:39:22.342743Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiment configurations: 36\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'simple', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'left', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float16, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.float32, 'model_size': 'flan-t5-large'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-small'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-base'}\n",
      "{'prompt_type': 'detailed', 'structure': 'right', 'precision': torch.bfloat16, 'model_size': 'flan-t5-large'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement your experimental design here! Decide on hyper-parameters, levels, see Exercise 3 for how to set-this up\n",
    "#  and type of factorial experiment you want to do.\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS: List[Dict[Any, Any]] = [\n",
    "    None\n",
    "]\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "prompt_types = [\"simple\", \"detailed\"]\n",
    "structures = [\"left\", \"right\"]\n",
    "precisions = [torch.float16, torch.float32, torch.bfloat16]\n",
    "model_sizes = [\"flan-t5-small\", \"flan-t5-base\", \"flan-t5-large\"]\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS: List[Dict[str, Any]] = [\n",
    "    {\n",
    "        \"prompt_type\": prompt_type,\n",
    "        \"structure\": structure,\n",
    "        \"precision\": precision,\n",
    "        \"model_size\": model_size,\n",
    "    }\n",
    "    for prompt_type, structure, precision, model_size in product(prompt_types, structures, precisions, model_sizes)\n",
    "]\n",
    "\n",
    "print(f\"Total experiment configurations: {len(EXPERIMENT_CONFIGURATIONS)}\")\n",
    "for config in EXPERIMENT_CONFIGURATIONS:\n",
    "    print(config)\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7bf53133827ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:39:22.783140Z",
     "start_time": "2024-10-17T19:39:22.781415Z"
    },
    "tags": [
     "remove-output",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Perform inference. See the cells of Exercise 1 and 3 as a starting point\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "ALLOW_OVERWRITING_RESULTS = True\n",
    "\n",
    "SHOTS = 4\n",
    "\n",
    "for configuration in tqdm(EXPERIMENT_CONFIGURATIONS, desc=\"Experiment Configurations\"):\n",
    "    prompt_type = configuration['prompt_type']\n",
    "    structure = configuration['structure']\n",
    "    precision = configuration['precision']\n",
    "    model_size = configuration['model_size']\n",
    "\n",
    "    simple_few_shot_set = get_simple_few_shot_dataset(\n",
    "        truncated_train_set,\n",
    "        truncated_test_set,\n",
    "        template=get_few_shot_prompt_template(),\n",
    "        shots=SHOTS\n",
    "    )\n",
    "\n",
    "    if prompt_type == 'simple':\n",
    "        dataset = simple_few_shot_set\n",
    "    else:\n",
    "        corpus_embedding, positive_embedding, negative_embedding, positive_samples, negative_samples = create_semantic_db(\n",
    "            embedding_model=embedding_model,\n",
    "            train_set=truncated_train_set,\n",
    "            test_set=truncated_test_set\n",
    "        )\n",
    "        dataset = get_contextual_drawn_few_shot_dataset(\n",
    "            train_set=truncated_train_set,\n",
    "            test_set=truncated_test_set,\n",
    "            tokenizer=tokenizer,\n",
    "            corpus_embeddings=corpus_embedding,\n",
    "            negative_corpus_embeddings=negative_embedding,\n",
    "            positive_corpus_embeddings=positive_embedding,\n",
    "            positive_samples=positive_samples,\n",
    "            negative_samples=negative_samples,\n",
    "            shots=SHOTS\n",
    "        )\n",
    "\n",
    "    model_name = f\"google/{model_size}\"\n",
    "    model, tokenizer, fast_tokenizer = get_model(\n",
    "        model_name=model_name,\n",
    "        model_type=transformers.AutoModelForSeq2SeqLM,\n",
    "        torch_dtype=precision,\n",
    "        device=device\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    generation_config = GenerationConfig()\n",
    "\n",
    "    for repetition in range(1, 2):\n",
    "        q_data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            prefetch_factor=10,\n",
    "        )\n",
    "\n",
    "        begin_time = time.time()\n",
    "        prediction_list, label_list = run_q2_evaluation(\n",
    "            q_data_loader,\n",
    "            model,\n",
    "            generation_config,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        prediction_list, labels_list = list(chain(*prediction_list)), list(chain(*label_list))\n",
    "\n",
    "        experiment_description = (\n",
    "            f\"Prompt Type: {prompt_type}, Structure: {structure}, \"\n",
    "            f\"Precision: {precision}, Model Size: {model_size}, \"\n",
    "            f\"Repetition: {repetition}\"\n",
    "        )\n",
    "        save_path_experiment = (\n",
    "            f\"results_few-shot/{model_size}/\"\n",
    "            f\"{prompt_type}_{structure}_{precision}_{repetition}.json\"\n",
    "        )\n",
    "\n",
    "        label_lut = defaultdict(lambda: -1, {'positive': 1, 'negative': 0})\n",
    "        predictions = list(map(lambda x: label_lut[x.split(' ')[0].lower()], prediction_list))\n",
    "\n",
    "        accuracy = sum(map(lambda x: x[0] == x[1], zip(predictions, labels_list))) / len(predictions)\n",
    "        unknown = sum(map(lambda x: x[0] == -1, zip(predictions, labels_list))) / len(predictions)\n",
    "\n",
    "        save_path = Path(save_path_experiment)\n",
    "        if not save_path.parent.exists():\n",
    "            save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        if save_path.is_file() and not ALLOW_OVERWRITING_RESULTS:\n",
    "            print(\"Cannot overwrite existing experiment file without `ALLOW_OVERWRITING_RESULTS` flag set.\")\n",
    "            continue\n",
    "\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump({\n",
    "                \"description\": experiment_description,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"unknown\": unknown,\n",
    "                \"begin_time\": begin_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"configuration\": {k: str(v) if isinstance(v, torch.dtype) else v for k, v in configuration.items()}\n",
    "            }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469b309d8d406d7",
   "metadata": {},
   "source": [
    "### Exercise 1.3 Report on DoE (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f51be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Experiment Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>structure</th>\n",
       "      <th>precision</th>\n",
       "      <th>model_size</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>accuracy_max</th>\n",
       "      <th>accuracy_min</th>\n",
       "      <th>begin_time_avg</th>\n",
       "      <th>begin_time_max</th>\n",
       "      <th>begin_time_min</th>\n",
       "      <th>end_time_avg</th>\n",
       "      <th>end_time_max</th>\n",
       "      <th>end_time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.78274</td>\n",
       "      <td>0.82708</td>\n",
       "      <td>0.73840</td>\n",
       "      <td>1.731445e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731438e+09</td>\n",
       "      <td>1.731447e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731443e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.74108</td>\n",
       "      <td>0.78060</td>\n",
       "      <td>0.70156</td>\n",
       "      <td>1.731447e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731443e+09</td>\n",
       "      <td>1.731448e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731444e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.73864</td>\n",
       "      <td>0.73864</td>\n",
       "      <td>0.73864</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.73856</td>\n",
       "      <td>0.73856</td>\n",
       "      <td>0.73856</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>0.73840</td>\n",
       "      <td>0.73840</td>\n",
       "      <td>0.73840</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731452e+09</td>\n",
       "      <td>1.731452e+09</td>\n",
       "      <td>1.731452e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.71536</td>\n",
       "      <td>0.75332</td>\n",
       "      <td>0.67740</td>\n",
       "      <td>1.731447e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731443e+09</td>\n",
       "      <td>1.731447e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731443e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.70172</td>\n",
       "      <td>0.70172</td>\n",
       "      <td>0.70172</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.70104</td>\n",
       "      <td>0.70104</td>\n",
       "      <td>0.70104</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.67792</td>\n",
       "      <td>0.67792</td>\n",
       "      <td>0.67792</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>simple</td>\n",
       "      <td>right</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.67748</td>\n",
       "      <td>0.67748</td>\n",
       "      <td>0.67748</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "      <td>1.731451e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>0.55268</td>\n",
       "      <td>0.75344</td>\n",
       "      <td>0.35192</td>\n",
       "      <td>1.731443e+09</td>\n",
       "      <td>1.731453e+09</td>\n",
       "      <td>1.731433e+09</td>\n",
       "      <td>1.731444e+09</td>\n",
       "      <td>1.731454e+09</td>\n",
       "      <td>1.731433e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple</td>\n",
       "      <td>left</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>0.39056</td>\n",
       "      <td>0.78072</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>1.731444e+09</td>\n",
       "      <td>1.731454e+09</td>\n",
       "      <td>1.731433e+09</td>\n",
       "      <td>1.731446e+09</td>\n",
       "      <td>1.731459e+09</td>\n",
       "      <td>1.731433e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_type structure       precision     model_size  accuracy_avg  \\\n",
       "2       simple      left   torch.float16  flan-t5-large       0.78274   \n",
       "4       simple      left   torch.float32   flan-t5-base       0.74108   \n",
       "5       simple      left   torch.float32  flan-t5-large       0.73864   \n",
       "8       simple      left  torch.bfloat16  flan-t5-large       0.73856   \n",
       "11      simple     right   torch.float16  flan-t5-large       0.73840   \n",
       "3       simple      left   torch.float32  flan-t5-small       0.71536   \n",
       "10      simple     right   torch.float16   flan-t5-base       0.70172   \n",
       "7       simple      left  torch.bfloat16   flan-t5-base       0.70104   \n",
       "6       simple      left  torch.bfloat16  flan-t5-small       0.67792   \n",
       "9       simple     right   torch.float16  flan-t5-small       0.67748   \n",
       "0       simple      left   torch.float16  flan-t5-small       0.55268   \n",
       "1       simple      left   torch.float16   flan-t5-base       0.39056   \n",
       "\n",
       "    accuracy_max  accuracy_min  begin_time_avg  begin_time_max  \\\n",
       "2        0.82708       0.73840    1.731445e+09    1.731451e+09   \n",
       "4        0.78060       0.70156    1.731447e+09    1.731451e+09   \n",
       "5        0.73864       0.73864    1.731451e+09    1.731451e+09   \n",
       "8        0.73856       0.73856    1.731451e+09    1.731451e+09   \n",
       "11       0.73840       0.73840    1.731451e+09    1.731451e+09   \n",
       "3        0.75332       0.67740    1.731447e+09    1.731451e+09   \n",
       "10       0.70172       0.70172    1.731451e+09    1.731451e+09   \n",
       "7        0.70104       0.70104    1.731451e+09    1.731451e+09   \n",
       "6        0.67792       0.67792    1.731451e+09    1.731451e+09   \n",
       "9        0.67748       0.67748    1.731451e+09    1.731451e+09   \n",
       "0        0.75344       0.35192    1.731443e+09    1.731453e+09   \n",
       "1        0.78072       0.00040    1.731444e+09    1.731454e+09   \n",
       "\n",
       "    begin_time_min  end_time_avg  end_time_max  end_time_min  \n",
       "2     1.731438e+09  1.731447e+09  1.731451e+09  1.731443e+09  \n",
       "4     1.731443e+09  1.731448e+09  1.731451e+09  1.731444e+09  \n",
       "5     1.731451e+09  1.731451e+09  1.731451e+09  1.731451e+09  \n",
       "8     1.731451e+09  1.731451e+09  1.731451e+09  1.731451e+09  \n",
       "11    1.731451e+09  1.731452e+09  1.731452e+09  1.731452e+09  \n",
       "3     1.731443e+09  1.731447e+09  1.731451e+09  1.731443e+09  \n",
       "10    1.731451e+09  1.731451e+09  1.731451e+09  1.731451e+09  \n",
       "7     1.731451e+09  1.731451e+09  1.731451e+09  1.731451e+09  \n",
       "6     1.731451e+09  1.731451e+09  1.731451e+09  1.731451e+09  \n",
       "9     1.731451e+09  1.731451e+09  1.731451e+09  1.731451e+09  \n",
       "0     1.731433e+09  1.731444e+09  1.731454e+09  1.731433e+09  \n",
       "1     1.731433e+09  1.731446e+09  1.731459e+09  1.731433e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Code for your evaluation of results and write a small report on the \n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "experiment_results = []\n",
    "for config in EXPERIMENT_CONFIGURATIONS:\n",
    "    precision_str = str(config['precision'])\n",
    "    \n",
    "    accuracies = []\n",
    "    begin_times = []\n",
    "    end_times = []\n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        file_path = f\"results_few-shot/{config['model_size']}/{config['prompt_type']}_{config['structure']}_{precision_str}_{i}.json\"\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                result = json.load(f)\n",
    "                accuracies.append(result['accuracy'])\n",
    "                begin_times.append(result['begin_time'])\n",
    "                end_times.append(result['end_time'])\n",
    "        except FileNotFoundError:\n",
    "            # print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "    if accuracies:\n",
    "        experiment_results.append({\n",
    "            'prompt_type': config['prompt_type'],\n",
    "            'structure': config['structure'],\n",
    "            'precision': precision_str,\n",
    "            'model_size': config['model_size'],\n",
    "            'accuracy_avg': sum(accuracies) / len(accuracies),\n",
    "            'accuracy_max': max(accuracies),\n",
    "            'accuracy_min': min(accuracies),\n",
    "            'begin_time_avg': sum(begin_times) / len(begin_times),\n",
    "            'begin_time_max': max(begin_times),\n",
    "            'begin_time_min': min(begin_times),\n",
    "            'end_time_avg': sum(end_times) / len(end_times),\n",
    "            'end_time_max': max(end_times),\n",
    "            'end_time_min': min(end_times),\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(experiment_results)[[\n",
    "    'prompt_type', 'structure', 'precision', 'model_size', \n",
    "    'accuracy_avg', 'accuracy_max', 'accuracy_min',\n",
    "    'begin_time_avg', 'begin_time_max', 'begin_time_min',\n",
    "    'end_time_avg', 'end_time_max', 'end_time_min'\n",
    "]].sort_values(by='accuracy_avg', ascending=False)\n",
    "\n",
    "print(\"Aggregated Experiment Results:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68ccacec068493",
   "metadata": {},
   "source": [
    "\n",
    "> TODO: Write your report here, using appropriate tables, and or $math$, to support your claim.\n",
    "\n",
    "Make sure to clearly state (among others):\n",
    "\n",
    " 1. Which hyper-parameters you are testing.\n",
    " 2. Which levels you are testing for each experiment.\n",
    " 3. How many repetitions you use.\n",
    " 4. Which design of experiment you use: full-factorial / fractional-factorial.\n",
    " 5. Whether the assumptions of the model hold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a035f",
   "metadata": {},
   "source": [
    "### Experiment Report on Few-Shot Prompting for Sentiment Analysis\n",
    "\n",
    "#### 1. Hyper-parameters Tested\n",
    "\n",
    "This experiment evaluated the following hyper-parameters and their effects on model performance in a few-shot sentiment classification task:\n",
    "\n",
    "- **Prompt Type**: Two types of prompts were tested:\n",
    "  - `simple`: Contains a minimal setup with a straightforward query.\n",
    "  - `detailed`: Corresponds to **contextual prompting**, where few-shot examples are provided in the prompt for additional context.\n",
    "- **Structure**: The position of the examples and query in the prompt was varied, appearing either to the `left` (before) or `right` (after) of the review text.\n",
    "- **Precision**: We tested three levels of numerical precision (`torch.float16`, `torch.float32`, and `torch.bfloat16`).\n",
    "- **Model Size**: Three model sizes (`T5-flan-small`, `T5-flan-base`, and `T5-flan-large`) were evaluated.\n",
    "\n",
    "#### 2. Levels for Each Hyper-parameter\n",
    "\n",
    "The levels tested for each hyper-parameter were as follows:\n",
    "\n",
    "- **Prompt Type**: `simple`, `detailed` (contextual)\n",
    "- **Structure**: `left`, `right`\n",
    "- **Precision**: `torch.float16`, `torch.float32`, `torch.bfloat16`\n",
    "- **Model Size**: `T5-flan-small`, `T5-flan-base`, `T5-flan-large`\n",
    "\n",
    "#### 3. Number of Repetitions\n",
    "\n",
    "Each configuration was run **two times** to ensure reliability of the results. The average, maximum, and minimum values for accuracy and duration (begin-to-end time) are reported for each configuration.\n",
    "\n",
    "#### 4. Design of Experiment\n",
    "\n",
    "This study used a **full-factorial design**, covering all combinations of hyper-parameters. With four hyper-parameters and their respective levels (2 x 2 x 3 x 3), this resulted in a total of **36 unique configurations**.\n",
    "\n",
    "#### Results Summary\n",
    "\n",
    "The experiment results reveal the following key insights:\n",
    "\n",
    "- **Model Size**: Similar to the zero-shot analysis, model size (`model_size`) was the most significant factor influencing accuracy. Larger models, such as `T5-flan-large`, consistently outperformed smaller models like `T5-flan-small`, demonstrating better capacity for learning from few-shot examples.\n",
    "\n",
    "- **Prompt Structure**: The prompt structure (`structure`) had a slight impact, particularly in the `T5-flan-large` configuration, where examples presented on the `left` performed slightly better than those on the `right`. This effect was less pronounced in smaller models.\n",
    "\n",
    "- **Prompt Type**: Contrary to expectations, the `detailed` (contextual) prompt type did not consistently outperform the `simple` prompt type. This suggests that the models might not have effectively utilized the additional examples in the detailed prompts, potentially due to limited reasoning capability or poor understanding of task examples.\n",
    "\n",
    "- **Precision**: The precision levels had negligible impact on model performance. Both `torch.float16` and `torch.float32` provided comparable accuracy, while `torch.bfloat16` exhibited slightly lower but still consistent performance.\n",
    "\n",
    "- **Unexpected Output**: A notable observation was the generation of irrelevant or nonsensical outputs, such as “sexy sexy sexy empty cat” or verbose sentences like “I'm not sure whether this is positive or negative.” This suggests that the model might not have effectively learned to use the provided few-shot examples for accurate classification.\n",
    "\n",
    "#### Observations and Conclusions\n",
    "\n",
    "1. **Few-shot vs. Zero-shot**: Surprisingly, the few-shot results were slightly worse than zero-shot results in terms of accuracy. This discrepancy could be attributed to the model’s inability to learn effectively from the provided few-shot examples, as evidenced by the nonsensical outputs.\n",
    "\n",
    "2. **Model Size**: Larger models demonstrated better performance, confirming their superior capacity for more complex reasoning and understanding.\n",
    "\n",
    "3. **Prompt Utilization**: The lack of significant improvement with `detailed` (contextual) prompts suggests that the models struggled to extract meaningful patterns from few-shot examples.\n",
    "\n",
    "4. **Future Improvements**: Addressing the limitations of the current prompting approach may involve exploring better formatting of examples, experimenting with task-specific fine-tuning, or leveraging enhanced models with improved reasoning capabilities.\n",
    "\n",
    "Overall, while few-shot learning remains a promising paradigm, its effectiveness in this task was limited by the model’s suboptimal use of prompt examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed6320a0a4a80b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfbc09a1c8c754",
   "metadata": {},
   "source": [
    "# Exercise 3: Fine-Tuning Based Classification (20 points total)\n",
    "\n",
    "Lastly, we will perform a fine-tuning based approach, where we will update the model weights in order to 'learn' reply with the clasification of the sentiment of the sentence.\n",
    "\n",
    "**N.B.** We provide most of the code here, as there are multiple non-trivial implementation details. However, the run-time is likely quitea bit longer, so make sure tostart in time.\n",
    "\n",
    "\n",
    "Here we would like to advise to;\n",
    "\n",
    "1. Carefully choose **which hyper-parameters** you want to evaluate, before diving into the implementation, make sure to check that you can reasonably run these experiment within reasonable time.\n",
    "   1. We strongly recommend using a LORA based approach, and focus on; different `target_modules`, `rank`, `alpha`, `drop_out`, and `epochs`.\n",
    "   2. Prefer low values for levels over higher, e.g., a level for epochs can be `1`, or for `steps=100`.\n",
    "   3. You can also try to fine-tune the model, and see whether the fine-tuned model is still capable to perform.\n",
    "   4. If your hardware / pytorch version allows, we also strongly recommend using `bitsandbytes` to further quantize the model, which will speed-up your experiments considerably.\n",
    "2. Preferably run with replication, i.e., at-least a `REPLICATION` of `2`, but if time does not permit for this, a single run is OK as well.\n",
    "3. Look into check-pointing, and recovery, and how much disk-space you need for your experiments.\n",
    "4. Check that you save models to recoverable paths, i.e., you don't overwrite models you train.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f89168d58edd3",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Perform DoE (10 points)\n",
    "\n",
    "First, you will need to complete the following code to Design your experiments.\n",
    "\n",
    "> Note, running training will take some time, so make sure to get started early!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9feab3d69b11d0a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:44:16.033631Z",
     "start_time": "2024-10-17T19:44:15.880504Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "def tokenize_function(\n",
    "        batch,\n",
    "        prefix='Is the following Positive or Negative?\\n',\n",
    "        post_fix='\\nAnswer: '):\n",
    "\n",
    "    updated_text = [f\"{prefix}{review}{post_fix}\" for review in batch[\"text\"]]\n",
    "    batch['text'] = updated_text\n",
    "    # We also set the 'response', i.e., what the model should learn\n",
    "    batch['labels'] = tokenizer(['Positive' if label == 1 else 'Negative' for label in batch[\"label\"]], truncation=True, padding='max_length', return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def train_model(\n",
    "        # original_model,\n",
    "        peft_model,\n",
    "        output_dir: str,\n",
    "        peft_training_args,\n",
    "        train_set,\n",
    "        test_set = None,\n",
    "        \n",
    ") -> Tuple[transformers.Trainer, peft.PeftModel]:\n",
    "    assert output_dir is not None, \"Provide an output dir to save the model\"\n",
    "    assert not Path(output_dir).exists(), \"Provided output dir is not unique!\"\n",
    "    \n",
    "    peft_trainer = transformers.Trainer(\n",
    "        model=original_model,\n",
    "        args=peft_training_args,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=test_set,\n",
    "    )\n",
    "    # Pre-train the model\n",
    "    peft_trainer.train()\n",
    "    # Set the fine-tuned model to evaluate, to remove non-deterministic\n",
    "    #  behavior.\n",
    "    peft_model.eval()\n",
    "    return peft_model, peft_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d74abca374d20ba7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:44:59.951743Z",
     "start_time": "2024-10-17T19:44:59.941272Z"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Design:\n",
      "rank: [8, 16, 32]\n",
      "alpha: [16, 32]\n",
      "dtype: [torch.float16, torch.float32]\n",
      "epochs: [1, 2, 3]\n",
      "Total number of experiments: 36\n"
     ]
    }
   ],
   "source": [
    "# Example of hyper-parameters.\n",
    "RANK = 32               # Rank used in model update (lower is faster, less precise)\n",
    "ALPHA = 64              # Scaling factor for update (∆W x dy ALPHA/RANK)           \n",
    "DROPOUT = 0.05          # Regularization term\n",
    "TRAIN_BATCH_SIZE = 32   # Number of samples\n",
    "# GRADIENT_ACCUMULATION_STEPS=1 # If you have low GPU/hardware, you can increase effective batch-size through this.\n",
    "#                               # It 'sums' gradient over GRADIENT_ACCUMULATION_STEPS, to create an effective-batch-size of\n",
    "#                               # GRADIENT_ACCUMULATION_STEPS * TRAIN_BATCH_SIZE\n",
    "TRAIN_EPOCHS = 5        # Total number of trainnig steps.\n",
    "\n",
    "# If you want to save some time, you can store checkpoints, and load them, to create multiple levels\n",
    "# in a single run. Do note, that huggingface by default uses learning-rate scheduling, so this may\n",
    "# affect your results a bit.\n",
    "\n",
    "# The modules are specific to the model itself.\n",
    "MODULES =  ['o'] # Other options are for example, please read the documentation.\n",
    "                 # ['o'], ['k', 'q'], ['q'], ['k', 'q', 'v'], 'or any other identifier of weights.\n",
    "TORCH_DTYPE = torch.float16\n",
    "\n",
    "# TODO: Decide the levels for your experiment. These can be any of the \n",
    "# aforementioned parameters, or any other hyper-parameter.\n",
    "\n",
    "# Hint: Define the levels as a list of numbers for the unique count of \n",
    "#   levels for a parameter.\n",
    "levels: List[int] = ...\n",
    "# Create a list with the names to keep track of the parameters\n",
    "parameters: List[str] = ...\n",
    "# Create a list with levels for each parameter\n",
    "parameter_levels: Dict[str, List[Any]] = ...\n",
    "\n",
    "# EXAMPLE ONLY\n",
    "# Don't actually use this configuration, as this will be a 3 * 2 * 2 * 3 = 36 experiments (without replication)\n",
    "levels = [3, 2, 2, 3]\n",
    "level_names = ['rank', 'alpha', 'dtype',  'epochs']\n",
    "parameter_levels = {\n",
    "    'rank': [8, 16, 32],\n",
    "    'alpha': [16, 32],\n",
    "    'dtype': [torch.float16, torch.float32],\n",
    "    'epochs': [1, 2, 3]\n",
    "}\n",
    "# END OF EXAMPLE \n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "levels = [3, 2, 2, 3]\n",
    "level_names = ['rank', 'alpha', 'dtype',  'epochs']\n",
    "parameter_levels = {\n",
    "    'rank': [8, 16, 32],\n",
    "    'alpha': [16, 32],\n",
    "    'dtype': [torch.float16, torch.float32],\n",
    "    'epochs': [1, 2, 3]\n",
    "}\n",
    "\n",
    "print(\"Experiment Design:\")\n",
    "for param, values in parameter_levels.items():\n",
    "    print(f\"{param}: {values}\")\n",
    "\n",
    "total_experiments = 1\n",
    "for level in levels:\n",
    "    total_experiments *= level\n",
    "\n",
    "print(f\"Total number of experiments: {total_experiments}\")\n",
    "\n",
    "# END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b89d24b5f911ed99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:45:05.382671Z",
     "start_time": "2024-10-17T19:45:05.375124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>alpha</th>\n",
       "      <th>dtype</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank alpha dtype epochs\n",
       "Experiment ID                        \n",
       "0              0.0   0.0   0.0    0.0\n",
       "1              1.0   0.0   0.0    0.0\n",
       "2              2.0   0.0   0.0    0.0\n",
       "3              0.0   1.0   0.0    0.0\n",
       "4              1.0   1.0   0.0    0.0\n",
       "5              2.0   1.0   0.0    0.0\n",
       "6              0.0   0.0   1.0    0.0\n",
       "7              1.0   0.0   1.0    0.0\n",
       "8              2.0   0.0   1.0    0.0\n",
       "9              0.0   1.0   1.0    0.0\n",
       "10             1.0   1.0   1.0    0.0\n",
       "11             2.0   1.0   1.0    0.0\n",
       "12             0.0   0.0   0.0    1.0\n",
       "13             1.0   0.0   0.0    1.0\n",
       "14             2.0   0.0   0.0    1.0\n",
       "15             0.0   1.0   0.0    1.0\n",
       "16             1.0   1.0   0.0    1.0\n",
       "17             2.0   1.0   0.0    1.0\n",
       "18             0.0   0.0   1.0    1.0\n",
       "19             1.0   0.0   1.0    1.0\n",
       "20             2.0   0.0   1.0    1.0\n",
       "21             0.0   1.0   1.0    1.0\n",
       "22             1.0   1.0   1.0    1.0\n",
       "23             2.0   1.0   1.0    1.0\n",
       "24             0.0   0.0   0.0    2.0\n",
       "25             1.0   0.0   0.0    2.0\n",
       "26             2.0   0.0   0.0    2.0\n",
       "27             0.0   1.0   0.0    2.0\n",
       "28             1.0   1.0   0.0    2.0\n",
       "29             2.0   1.0   0.0    2.0\n",
       "30             0.0   0.0   1.0    2.0\n",
       "31             1.0   0.0   1.0    2.0\n",
       "32             2.0   0.0   1.0    2.0\n",
       "33             0.0   1.0   1.0    2.0\n",
       "34             1.0   1.0   1.0    2.0\n",
       "35             2.0   1.0   1.0    2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Decide the type of (fractional or full) factorial experiment you want to run.\n",
    "# HINT: use the ANOVAandDOE.ipynb notebook as inspiration, and use functinos from pyDOE3\n",
    "import pyDOE3\n",
    "# EXAMPLE ONLY\n",
    "reduction = 4 # for general factorial experiment.\n",
    "experiment = pyDOE3.gsd(\n",
    "    levels, reduction=reduction\n",
    ")\n",
    "# END OF EXAMPLE\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "experiment = pyDOE3.fullfact(levels)\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n",
    "experiment_configs = pd.DataFrame(\n",
    "    experiment,\n",
    "    columns=[level_names],\n",
    "    \n",
    ")\n",
    "experiment_configs.index.name = 'Experiment ID'\n",
    "\n",
    "\n",
    "display(\n",
    "    experiment_configs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9623172be5efbbf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:44:00.615201Z",
     "start_time": "2024-10-17T19:44:00.556395Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: 1, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 2, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 3, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 4, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 5, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 6, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 7, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 8, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 9, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 10, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 11, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 12, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 13, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.244100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 14, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.123900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 15, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.986400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 16, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.310600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 17, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.301300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 18, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.330400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 19, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.022400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 20, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.984200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 21, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.874100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 22, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.850600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 23, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.922300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 24, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.032100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages/peft/utils/other.py:689: UserWarning: Unable to fetch remote file due to the following error (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 86050583-1205-42f1-a0b3-103435ee9828)') - silently ignoring the lookup for the file config.json in google/flan-t5-small.\n",
      "  warnings.warn(\n",
      "/home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages/peft/utils/save_and_load.py:243: UserWarning: Could not find a config file in google/flan-t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 25, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.856100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 26, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.707600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.890100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 27, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.545200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.916000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 28, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.787700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 29, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.813200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 30, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.841800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 31, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.645500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 32, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.904500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 33, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.178900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 34, repetition: 1\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.674900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 35, repetition: 1\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.883000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages/peft/utils/other.py:689: UserWarning: Unable to fetch remote file due to the following error (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 93546114-791b-419a-b66e-b3038ccaffed)') - silently ignoring the lookup for the file config.json in google/flan-t5-small.\n",
      "  warnings.warn(\n",
      "/home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages/peft/utils/save_and_load.py:243: UserWarning: Could not find a config file in google/flan-t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 36, repetition: 1\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.773100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.174200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 1, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 2, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 3, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 4, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 5, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 6, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float16, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 7, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 8, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 9, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 10, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 11, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 12, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float32, 'epochs': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 02:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 13, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.244100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 14, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.123900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 15, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.986400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 16, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.310600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 17, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.301300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 18, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float16, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 03:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.330400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 19, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.022400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 20, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.984200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 21, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.874100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 22, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.850600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 23, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.922300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 24, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float32, 'epochs': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1564/1564 05:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.032100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 25, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.856100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 26, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.707600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.890100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 27, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.545200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.916000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 28, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.787700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 29, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.813200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages/peft/utils/other.py:689: UserWarning: Unable to fetch remote file due to the following error (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: e10c104c-b057-4dce-b7f1-00ca1842a694)') - silently ignoring the lookup for the file config.json in google/flan-t5-small.\n",
      "  warnings.warn(\n",
      "/home/fcr/anaconda3/envs/msgai/lib/python3.10/site-packages/peft/utils/save_and_load.py:243: UserWarning: Could not find a config file in google/flan-t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 30, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float16, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 05:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>13.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.841800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 31, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 16, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.645500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 32, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 16, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.904500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 33, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 16, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>16.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.178900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 34, repetition: 2\n",
      "Experiment config: {'rank': 8, 'alpha': 32, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.674900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 35, repetition: 2\n",
      "Experiment config: {'rank': 16, 'alpha': 32, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.883000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n",
      "Running experiment: 36, repetition: 2\n",
      "Experiment config: {'rank': 32, 'alpha': 32, 'dtype': torch.float32, 'epochs': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 08:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>12.773100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.174200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiment!\n"
     ]
    }
   ],
   "source": [
    "REPETITIONS = 2\n",
    "\n",
    "# If the number of tokens is a level, you might need to change this\n",
    "train_dataset = (\n",
    "    train_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    "    .map(\n",
    "        tokenize_function, batched=True\n",
    "    )\n",
    "    .map(\n",
    "        lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "            batch['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=False,\n",
    "        ), batched=True\n",
    "    )\n",
    ")\n",
    "# Ensure we can effectively use the model\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "EXPERIMENT_CONFIGURATIONS = []\n",
    "for repetition in range(REPETITIONS):\n",
    "    for experiment_id, config_row in enumerate(experiment_configs.iterrows()):\n",
    "        # experiment_config = {k[0]: parameter_levels[k[0]][v] for k, v in config_row[1].to_dict().items()}\n",
    "        experiment_config = {k[0]: parameter_levels[k[0]][int(v)] for k, v in config_row[1].to_dict().items()}\n",
    "        \n",
    "        EXPERIMENT_CONFIGURATIONS.append(experiment_config)\n",
    "        print(f\"Running experiment: {experiment_id + 1}, repetition: {repetition + 1}\")\n",
    "        print(f\"Experiment config: {experiment_config}\")\n",
    "        \n",
    "        # BEGIN OF YOUR UPDATE TO THIS CODE\n",
    "        rank = experiment_config['rank']\n",
    "        alpha = experiment_config['alpha']\n",
    "        exp_dtype = experiment_config['dtype']\n",
    "        epochs = experiment_config['epochs']\n",
    "        \n",
    "        lora_config = LoraConfig(\n",
    "            r=rank,\n",
    "            lora_alpha=alpha,\n",
    "            target_modules=MODULES,\n",
    "            lora_dropout=DROPOUT,\n",
    "            bias='none',\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM # Specific for FLAN-T5 model.\n",
    "            # task_type=TaskType.CAUSAL_LM # Specific for Auto-regressive model\n",
    "            # task_type=TaskType.TOKEN_CLS # Specific for Token based classification\n",
    "        )\n",
    "        \n",
    "        original_model, tokenizer, tokenizer_fast = get_model(\n",
    "            model_name=model_name,\n",
    "            device=device,\n",
    "            torch_dtype=exp_dtype,\n",
    "        )\n",
    "        \n",
    "        output_dir = f'./exercise-3/exp_{repetition}_{experiment_id}_rank={rank}_alpha={alpha}_dtype={exp_dtype}_epochs={epochs}'\n",
    "\n",
    "        \n",
    "        peft_training_args = transformers.TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            auto_find_batch_size=False,\n",
    "            per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "            learning_rate=1e-4,\n",
    "            num_train_epochs=epochs,\n",
    "            logging_steps=1000,     # You might need to change this, esp. if you subsample the train set.\n",
    "            # max_steps=10000,        # You can use this instead of epochs, for more fine-grained control.\n",
    "            save_total_limit=2,     # Limit the number of checkpoints to save\n",
    "            save_strategy='steps',\n",
    "            save_steps=1000         # You might need to change this\n",
    "        )\n",
    "        # END OF YOUR UPDATE CODE\n",
    "        \n",
    "        peft_model = get_peft_model(\n",
    "            model=original_model,\n",
    "            peft_config=lora_config,\n",
    "        )\n",
    "        peft_model, peft_trainer = train_model(\n",
    "            peft_model=peft_model,\n",
    "            peft_training_args=peft_training_args,\n",
    "            output_dir=output_dir,\n",
    "            train_set=train_dataset,\n",
    "            test_set=None,\n",
    "        )\n",
    "        peft_model.save_pretrained(output_dir)\n",
    "        \n",
    "        del peft_model, peft_trainer\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print('Finished experiment!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba1a04bd70f05a7",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Next do the evaluation\n",
    "\n",
    "# ONLY SET THIS TO True IFF YOU NEED TO RE-RUN EXPERIMENTS, AS IT WILL\n",
    "#  OVERWRITE YOUR RESULTS.\n",
    "ALLOW_OVERWRITING_RESULTS = True\n",
    "\"\"\"\n",
    "# If you want to experiment with the side of the prompt, you will need to make\n",
    "#  some changes here.\n",
    "\"\"\"\n",
    "# If the number of tokens is a level, you might need to change this\n",
    "test_dataset = (\n",
    "    test_set\n",
    "    .map(truncate_to_50_tokens, batched=True)\n",
    "    .map(\n",
    "        tokenize_function, batched=True\n",
    "    )\n",
    "    .map(\n",
    "        lambda batch: fast_tokenizer.batch_encode_plus(\n",
    "            batch['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ), batched=True\n",
    "    )\n",
    ")\n",
    "# Ensure we can effectively use the model\n",
    "# test_dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "max_batches = 10\n",
    "subset_size = max_batches * 128\n",
    "test_dataset_subset = Subset(test_dataset, range(min(len(test_dataset), subset_size)))\n",
    "test_datasloader = torch.utils.data.DataLoader(\n",
    "            dataset=test_dataset_subset,\n",
    "            batch_size=128,  # Feel free to lower / higher this\n",
    "            shuffle=False,  # Shuffling not needed during evaluation\n",
    "            num_workers=1,\n",
    "            prefetch_factor=10,\n",
    "        )\n",
    "\n",
    "EXPERIMENT_CONFIGURATIONS = []\n",
    "for experiment_id, config_row in enumerate(experiment_configs.iterrows()):\n",
    "    # experiment_config = {k[0]: parameter_levels[k[0]][v] for k, v in config_row[1].to_dict().items()}\n",
    "    experiment_config = {k[0]: parameter_levels[k[0]][int(v)] for k, v in config_row[1].to_dict().items()}\n",
    "    \n",
    "    EXPERIMENT_CONFIGURATIONS.append(experiment_config)\n",
    "    \n",
    "original_model, tokenizer, tokenizer_fast = get_model(\n",
    "            model_name=model_name,\n",
    "            device=device,\n",
    "            torch_dtype=torch.float16, # You might need to change this.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694daaf5b0ae77fa",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The current process just got forked, after parallelism has already been used.\")\n",
    "\n",
    "for experiment_id, experiment_config in (exp_bar := tqdm(enumerate(EXPERIMENT_CONFIGURATIONS), leave=True)):\n",
    "    # EXAMPLE CODE HERE\n",
    "    for repetition in tqdm(range(REPETITIONS), leave=False):\n",
    "    \n",
    "        # BEGIN OF YOUR UPDATE TO THIS CODE\n",
    "        rank = experiment_config['rank']\n",
    "        alpha = experiment_config['alpha']\n",
    "        exp_dtype = experiment_config['dtype']\n",
    "        epochs = experiment_config['epochs']\n",
    "        \n",
    "        # END OF YOUR UPDATE TO THIS CODE\n",
    "        # TODO: make sure that your output-dir here has the same format as during training.\n",
    "        output_dir = f'./exercise-3/exp_{repetition}_{experiment_id}_rank={rank}_alpha={alpha}_dtype={exp_dtype}_epochs={epochs}'\n",
    "        \n",
    "        peft_model = peft.PeftModel.from_pretrained(original_model, output_dir)\n",
    "        begin_time = time.time()\n",
    "\n",
    "        generation_config = GenerationConfig(\n",
    "            max_new_tokens=50,\n",
    "            num_beams=5,\n",
    "            bos_token_id=tokenizer.bos_token_id or 0,\n",
    "            eos_token_id=tokenizer.eos_token_id or 1,\n",
    "            pad_token_id=tokenizer.pad_token_id or 2,\n",
    "        )\n",
    "        prediction_list, label_list = run_q1_evaluation(\n",
    "            dataloader=test_datasloader,  # This you should probably not change\n",
    "            model=peft_model,  # You might need to change / load a different model for model-parameter\n",
    "            generation_config=generation_config,  # You might need to update some kwargs int the generation config for your exp.\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        # Create a flat version to work with.\n",
    "        prediction_list, labels_list = list(chain(*prediction_list)), list(chain(*label_list))\n",
    "        \n",
    "        # Map the output if we don't recognize it to \n",
    "        label_lut = defaultdict(lambda: -1, {'positive': 1, 'negative': 0})\n",
    "        \n",
    "        predictions = list(map(lambda x: label_lut[x.split(' ')[0].lower()], prediction_list))\n",
    "        \n",
    "        accuracy = sum(map(lambda x: x[0] == x[1], zip(predictions, labels_list))) / len(predictions)\n",
    "        unknown =  sum(map(lambda x: x[0] == -1, zip(predictions, labels_list))) / len(predictions)\n",
    "\n",
    "        # print(f\"Accuracy ({configuration}): {accuracy}, Unknown: {unknown}\")\n",
    "        print(f\"Accuracy ({experiment_id}): {accuracy:.4f}, Unknown: {unknown:.4f}\")\n",
    "        \n",
    "        # Write file to disk\n",
    "        save_path = Path(output_dir) / f'result_replication={repetition}.json'\n",
    "        if not save_path.parent.exists():\n",
    "            # Recursively create directory\n",
    "            save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        if save_path.is_file() and not ALLOW_OVERWRITING_RESULTS:\n",
    "            print(\"YOU ARE TRYING TO OVERWRITE AN EXISTING EXPERIMENT FILE!\")\n",
    "            raise Exception(\"Cannot overwrite existing experiment file without `ALLOW_OVERWRITING_RESULTS` flag set.\")\n",
    "        \n",
    "        experiment_config_serializable = {\n",
    "            key: str(value) if isinstance(value, torch.dtype) else value\n",
    "            for key, value in experiment_config.items()\n",
    "        }\n",
    "\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump({\n",
    "                \"experiment_config\": experiment_config_serializable,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"unknown\": unknown,\n",
    "                \"begin_time\": begin_time,\n",
    "                \"end_time\": end_time,\n",
    "            }, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317714c30c754bdc",
   "metadata": {},
   "source": [
    "## Excercise 3.2 Experimental Analysis (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ce0790513c814d1",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
<<<<<<< Updated upstream
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Experiment Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rank</th>\n",
       "      <th>alpha</th>\n",
       "      <th>dtype</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>unknown</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.576562</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.576562</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.497656</td>\n",
       "      <td>0.489844</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.497656</td>\n",
       "      <td>0.489844</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.189062</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.731910e+09</td>\n",
       "      <td>1.731910e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id repetition  rank  alpha          dtype  epochs  accuracy  \\\n",
       "62           N/A        N/A     8     32  torch.float32       3  0.576562   \n",
       "26           N/A        N/A     8     32  torch.float32       3  0.576562   \n",
       "55           N/A        N/A     8     32  torch.float16       3  0.497656   \n",
       "19           N/A        N/A     8     32  torch.float16       3  0.497656   \n",
       "63           N/A        N/A    16     32  torch.float32       3  0.104688   \n",
       "..           ...        ...   ...    ...            ...     ...       ...   \n",
       "39           N/A        N/A     8     16  torch.float16       2  0.000000   \n",
       "40           N/A        N/A    16     16  torch.float16       2  0.000000   \n",
       "41           N/A        N/A    32     16  torch.float16       2  0.000000   \n",
       "43           N/A        N/A    16     32  torch.float16       2  0.000000   \n",
       "71           N/A        N/A     8     32  torch.float32       1  0.000000   \n",
       "\n",
       "     unknown    begin_time      end_time  \n",
       "62  0.003906  1.731910e+09  1.731910e+09  \n",
       "26  0.003906  1.731910e+09  1.731910e+09  \n",
       "55  0.489844  1.731910e+09  1.731910e+09  \n",
       "19  0.489844  1.731910e+09  1.731910e+09  \n",
       "63  0.189062  1.731910e+09  1.731910e+09  \n",
       "..       ...           ...           ...  \n",
       "39  1.000000  1.731910e+09  1.731910e+09  \n",
       "40  1.000000  1.731910e+09  1.731910e+09  \n",
       "41  1.000000  1.731910e+09  1.731910e+09  \n",
       "43  1.000000  1.731910e+09  1.731910e+09  \n",
       "71  1.000000  1.731910e+09  1.731910e+09  \n",
       "\n",
       "[72 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "experiment_results = []\n",
    "\n",
    "# Adjust this based on your experiment configurations and directory structure\n",
    "base_dir = Path('./exercise-3')  # Base directory where JSON files are stored\n",
    "\n",
    "for experiment_dir in base_dir.glob('exp_*'):  # Iterate through each experiment directory\n",
    "    for results_file in experiment_dir.glob('result_replication=*.json'):  # Locate all result JSON files\n",
    "        try:\n",
    "            with open(results_file, 'r') as f:\n",
    "                result = json.load(f)\n",
    "\n",
    "            # Extract the necessary fields from each result file\n",
    "            experiment_results.append({\n",
    "                'experiment_id': result.get('experiment_id', 'N/A'),\n",
    "                'repetition': result.get('repetition', 'N/A'),\n",
    "                'rank': result['experiment_config']['rank'],\n",
    "                'alpha': result['experiment_config']['alpha'],\n",
    "                'dtype': str(result['experiment_config']['dtype']),\n",
    "                'epochs': result['experiment_config']['epochs'],\n",
    "                'accuracy': result['accuracy'],\n",
    "                'unknown': result['unknown'],\n",
    "                'begin_time': result['begin_time'],\n",
    "                'end_time': result['end_time'],\n",
    "                # 'duration': result['duration'],\n",
    "            })\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {results_file}\")\n",
    "            continue\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from file: {results_file}\")\n",
    "            continue\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df_results = pd.DataFrame(experiment_results)\n",
    "\n",
    "# Perform any additional analysis or sort by specific columns\n",
    "df_results = df_results.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "# Display the aggregated results\n",
    "print(\"Aggregated Experiment Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b248e19a552f6",
   "metadata": {},
   "source": [
    "# TODO: Write your report here, using appropriate tables, and or $math$, to support your claim.\n",
    "\n",
    "Make sure to clearly state (among others):\n",
    "\n",
    "1. Which hyper-parameters you are testing \n",
    "2. Which levels you are testing for each experiment\n",
    "3. How many repetitions you use\n",
    "4. Which design of experiment you use: full-factorial / fractional-factorial.\n",
    "5. Whether the assumptionsn of hte model hold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c9fa9",
   "metadata": {},
   "source": [
    "### Experiment Report on Fine-Tuning and LoRA for Sentiment Analysis\n",
    "\n",
    "#### Overview\n",
    "\n",
    "This experiment evaluated the performance of LoRA-based fine-tuning for sentiment classification. The following hyper-parameters were tested:\n",
    "\n",
    "- **Rank**: `8`, `16`, `32`\n",
    "- **Alpha**: `16`, `32`\n",
    "- **Precision**: `torch.float16`, `torch.float32`\n",
    "- **Epochs**: `1`, `2`, `3`\n",
    "\n",
    "#### Observations\n",
    "\n",
    "1. **Top Configurations**:\n",
    "   - Higher ranks (`32`) and `torch.float32` precision consistently achieved better accuracy.\n",
    "   - The best configuration (rank=`8`, alpha=`32`, precision=`torch.float32`, epochs=`3`) achieved **57.66% accuracy**.\n",
    "\n",
    "2. **Failure Cases**:\n",
    "   - Some configurations produced `0%` accuracy with `100%` unknown rates, suggesting potential issues with data loading or preprocessing.\n",
    "   - Additionally, due to time constraints, only a subset of the test data was used for evaluation. This may have contributed to poorer results for some configurations, as the subset might not fully represent the test distribution.\n",
    "\n",
    "3. **LoRA Efficiency**:\n",
    "   - LoRA-based fine-tuning demonstrated promising results in balancing performance and parameter efficiency.\n",
    "   - However, certain configurations (e.g., low ranks) failed to generalize well, indicating a need for more careful hyper-parameter tuning.\n",
    "\n",
    "#### Key Results\n",
    "\n",
    "| **Rank** | **Alpha** | **Precision**    | **Epochs** | **Accuracy** | **Unknown** |\n",
    "|----------|-----------|------------------|------------|--------------|-------------|\n",
    "| 8        | 32        | `torch.float32`  | 3          | 0.5766       | 0.0039      |\n",
    "| 8        | 32        | `torch.float16`  | 3          | 0.4977       | 0.4898      |\n",
    "| 16       | 32        | `torch.float32`  | 3          | 0.1047       | 0.1891      |\n",
    "| 32       | 16        | `torch.float16`  | 2          | 0.0000       | 1.0000      |\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The results highlight the potential of LoRA for fine-tuning, but they also underscore the importance of ensuring data consistency. While the top configurations performed well, unresolved issues with data loading and the use of only a subset of test data likely impacted the reliability of some results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
